{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib tk\n",
    "from kusanagi.shell import cartpole\n",
    "from kusanagi.ghost import control\n",
    "from kusanagi.ghost import regression\n",
    "from kusanagi.base import apply_controller, train_dynamics, ExperienceDataset\n",
    "from kusanagi.ghost.optimizers import ScipyOptimizer, SGDOptimizer\n",
    "from kusanagi.ghost.algorithms import pilco_, mc_pilco_\n",
    "from kusanagi import utils\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "params = cartpole.default_params()\n",
    "angle_dims = params['angle_dims']\n",
    "n_random = 4\n",
    "n_polopt = 20\n",
    "max_steps = 40\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kusanagi.ghost.control.NNPolicy.NNPolicy'> True\n",
      "[2017-07-12 10:26:01.678367] Experience > Initialising new experience dataset\n"
     ]
    }
   ],
   "source": [
    "# environment\n",
    "env = cartpole.Cartpole(**params['plant'])\n",
    "\n",
    "# policy\n",
    "policy = control.NNPolicy(p0.mean, **params['policy'])\n",
    "randpol = control.RandPolicy(maxU=policy.maxU, random_walk=True)\n",
    "\n",
    "# dynamics model, inputs are state + action, outputs are changes in state\n",
    "dynmodel = regression.BNN(**params['dynamics_model'])\n",
    "\n",
    "# cost function model\n",
    "cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# experience dataset\n",
    "exp = ExperienceDataset()\n",
    "\n",
    "# optimizers\n",
    "dynopt = SGDOptimizer(**params['optimizer'])\n",
    "polopt = ScipyOptimizer(**params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-12 10:26:01.750406] apply_controller > Starting run\n",
      "[2017-07-12 10:26:01.751344] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-12 10:26:01.752990] NNPolicy > Initialising expression graph for prediction\n",
      "[2017-07-12 10:26:01.754572] NNPolicy > Building network\n",
      "InputLayer {'shape': [None, 5], 'name': 'NNPolicy_input'}\n",
      "DenseLayer {'num_units': 50, 'nonlinearity': <function selu at 0x7f0ca4dc1378>, 'W': <lasagne.init.HeNormal object at 0x7f0ce572ce10>, 'name': 'NNPolicy_fc0'}\n",
      "DenseLayer {'num_units': 1, 'nonlinearity': <function linear at 0x7f0cb8b86268>, 'W': <lasagne.init.HeUniform object at 0x7f0caabdaef0>, 'name': 'NNPolicy_output'}\n",
      "[2017-07-12 10:26:01.771485] NNPolicy > Compiling mean and variance of prediction\n",
      "[2017-07-12 10:26:01.873897] NNPolicy > Done compiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/lib/Lasagne/lasagne/layers/helper.py:209: UserWarning: get_output() was called with unused kwargs:\n",
      "\tfixed_dropout_masks\n",
      "  % \"\\n\\t\".join(suggestions))\n",
      "/home/juancamilog/miniconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py:2453: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-12 10:26:04.231036] apply_controller > Done. Stopping robot. Value of run [39.997108]\n",
      "[2017-07-12 10:26:04.233418] Cartpole > Stopping robot\n",
      "[2017-07-12 10:26:04.236168] apply_controller > Starting run\n",
      "[2017-07-12 10:26:04.238839] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-12 10:26:06.301606] apply_controller > Done. Stopping robot. Value of run [39.999891]\n",
      "[2017-07-12 10:26:06.318671] Cartpole > Stopping robot\n",
      "[2017-07-12 10:26:06.321728] apply_controller > Starting run\n",
      "[2017-07-12 10:26:06.324566] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-12 10:26:08.476400] apply_controller > Done. Stopping robot. Value of run [39.994798]\n",
      "[2017-07-12 10:26:08.477186] Cartpole > Stopping robot\n",
      "[2017-07-12 10:26:08.482604] apply_controller > Starting run\n",
      "[2017-07-12 10:26:08.484637] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-12 10:26:10.572178] apply_controller > Done. Stopping robot. Value of run [39.998278]\n",
      "[2017-07-12 10:26:10.572953] Cartpole > Stopping robot\n"
     ]
    }
   ],
   "source": [
    "# callback executed after every call to env.step\n",
    "def step_cb(state, action, cost, info):\n",
    "    exp.add_sample(state, action, cost, info)\n",
    "    env.render()\n",
    "    \n",
    "# function to execute before applying policy\n",
    "def gTrig(state):\n",
    "    return utils.gTrig_np(state, angle_dims).flatten()\n",
    "\n",
    "# initial data collection runs with random controls\n",
    "for i in range(n_random):\n",
    "    exp.new_episode()\n",
    "    states, actions, costs, infos = apply_controller(env, policy, max_steps,\n",
    "                                                     preprocess=gTrig, callback=step_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-12 10:26:10.661516] Iteration 1, total experience: 160 steps\n",
      "[2017-07-12 10:26:10.665997] train_dynamics > Training dynamics model\n",
      "[2017-07-12 10:26:10.669865] train_dynamics > Dataset size:: Inputs: [ (156, 6) ], Targets: [ (156, 4) ]  \n",
      "[2017-07-12 10:26:10.672193] BNN > Building network\n",
      "InputLayer {'shape': (None, 6), 'name': 'BNN_input'}\n",
      "DenseLayer {'num_units': 200, 'nonlinearity': <function sigmoid at 0x7f0cb8be8950>, 'name': 'BNN_fc0'}\n",
      "DropoutLayer {'p': 0.05, 'rescale': False, 'name': 'BNN_drop0', 'dropout_samples': array(25, dtype=int32)}\n",
      "DenseLayer {'num_units': 200, 'nonlinearity': <function sigmoid at 0x7f0cb8be8950>, 'name': 'BNN_fc1'}\n",
      "DropoutLayer {'p': 0.05, 'rescale': False, 'name': 'BNN_drop1', 'dropout_samples': array(25, dtype=int32)}\n",
      "DenseLayer {'num_units': 4, 'nonlinearity': <function linear at 0x7f0cb8b86268>, 'name': 'BNN_output'}\n",
      "[2017-07-12 10:26:10.678767] BNN > Initialising loss function\n",
      "[2017-07-12 10:26:10.797675] BNN_opt > Building computation graph for gradients\n",
      "[2017-07-12 10:26:10.860240] BNN_opt > Computing parameter update rules\n",
      "[2017-07-12 10:26:10.890271] BNN_opt > Compiling function for loss\n",
      "[2017-07-12 10:26:11.170820] BNN_opt > Compiling parameter updates\n",
      "[2017-07-12 10:26:12.086177] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-07-12 10:26:12.089553] BNN_opt > Initial loss [2034.3374476603926]\n",
      "\u001b[2K[2017-07-12 10:26:25.140380] BNN_opt > Current value: 6.297332E+00, Total evaluations: 1000, Avg. time per updt: 0.006220\n",
      "[2017-07-12 10:26:25.150895] train_dynamics > Done training dynamics model\n",
      "[2017-07-12 10:26:25.401179] mc_pilco.rollout > Building computation graph for state particles propagation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/lib/Lasagne/lasagne/layers/helper.py:209: UserWarning: get_output() was called with unused kwargs:\n",
      "\tfixed_dropout_masks\n",
      "  % \"\\n\\t\".join(suggestions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-12 10:26:25.693684] ScipyOptimizer > Building computation graph for gradients\n",
      "[2017-07-12 10:26:26.467329] ScipyOptimizer > Compiling function for loss\n",
      "[2017-07-12 10:26:31.851410] ScipyOptimizer > Compiling function for loss+gradients\n",
      "[2017-07-12 10:26:58.158806] ScipyOptimizer > Optimizing parameters\n",
      "[2017-07-12 10:26:58.228704] ScipyOptimizer > Initial loss [0.9999962783209636]\n",
      "[2017-07-12 10:26:58.229600] ScipyOptimizer > Using L-BFGS-B optimizer\n",
      "\u001b[2K[2017-07-12 10:26:59.147949] ScipyOptimizer > Current loss: 0.9999959931162289, Total evaluations: 9, Avg. time per call: 0.107220   \n",
      "[2017-07-12 10:26:59.151710] ScipyOptimizer > Done training. New value [0.999992] iter: [7]\n",
      "[2017-07-12 10:26:59.155181] apply_controller > Starting run\n",
      "[2017-07-12 10:26:59.157873] apply_controller > Running for 4.000000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/miniconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py:2453: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-12 10:27:01.387523] apply_controller > Done. Stopping robot. Value of run [39.999422]\n",
      "[2017-07-12 10:27:01.397272] Cartpole > Stopping robot\n",
      "[2017-07-12 10:27:01.399597] Iteration 2, total experience: 200 steps\n",
      "[2017-07-12 10:27:01.401472] train_dynamics > Training dynamics model\n",
      "[2017-07-12 10:27:01.404400] train_dynamics > Dataset size:: Inputs: [ (195, 6) ], Targets: [ (195, 4) ]  \n",
      "[2017-07-12 10:27:01.406314] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-07-12 10:27:01.414149] BNN_opt > Initial loss [17.196826602347112]\n",
      "\u001b[2K[2017-07-12 10:27:12.876903] BNN_opt > Current value: 1.147638E+00, Total evaluations: 979, Avg. time per updt: 0.005107"
     ]
    }
   ],
   "source": [
    "# learning loop\n",
    "for i in range(n_polopt): \n",
    "    utils.print_with_stamp('Iteration %d, total experience: %d steps'%(i+1, sum([len(st) for st in exp.states])))\n",
    "    # train dynamics model\n",
    "    train_dynamics(dynmodel, exp, angle_dims=angle_dims, init_episode=0)\n",
    "    #X, Y = exp.get_dynmodel_dataset(deltas=True, angle_dims=angle_dims)\n",
    "    #dynmodel.set_dataset(X, Y)\n",
    "    #if dynopt.loss_fn is None:\n",
    "    #    loss_gp, inps, updts = dynmodel.get_loss()\n",
    "    #    dynopt.set_objective(loss_gp, dynmodel.get_params(symbolic=True), inps, updts)\n",
    "    #dynopt.minimize()\n",
    "    \n",
    "    # train policy\n",
    "    if polopt.loss_fn is None:\n",
    "        loss_pol, inps, updts = mc_pilco_.get_loss(policy, dynmodel, cost, D, angle_dims)\n",
    "        polopt.set_objective(loss_pol, policy.get_params(symbolic=True), inps, updts)\n",
    "    polopt.minimize(p0.mean, p0.cov, 40, 1)\n",
    "    \n",
    "    # apply controller\n",
    "    exp.new_episode(policy_params=policy.get_params())\n",
    "    states, actions, costs, infos = apply_controller(env, policy, max_steps,\n",
    "                                                     preprocess=gTrig, callback=step_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(924.1811476478766),\n",
       " array([[ -306.01761488,  -202.17335583,  -215.72509143,  -119.86554306,\n",
       "          -276.31764957,   -67.52521367, -1667.62789131,   -16.79423829],\n",
       "        [  -45.49039863,   -52.60383272,   -41.9701915 ,   -15.58153214,\n",
       "           -45.7787077 ,    -9.85335037,  -240.07397572,     1.93446688],\n",
       "        [  -54.84919972,   -45.99877261,   -54.86776936,   -11.95147382,\n",
       "           -56.88412831,   -11.30721787,  -166.43947718,     2.66633356],\n",
       "        [  -70.63741594,   -50.67703573,   -34.74237804,   -42.54835666,\n",
       "           -54.95024117,    -4.01160943,  -162.12062864,     2.64143425]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynopt.grads_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SSGP_UI>loghyp]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynopt.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
