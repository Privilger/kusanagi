{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib tk\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from kusanagi.ghost import control\n",
    "from kusanagi.ghost import regression\n",
    "from kusanagi.shell import cartpole\n",
    "from kusanagi.ghost.algorithms import pilco, mc_pilco\n",
    "from kusanagi.ghost.optimizers import ScipyOptimizer, SGDOptimizer\n",
    "from kusanagi.base import apply_controller, train_dynamics, ExperienceDataset\n",
    "from kusanagi import utils\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# np.random.seed(1337)\n",
    "np.set_printoptions(linewidth=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rollout(rollout_fn, *args, **kwargs):\n",
    "    fig = kwargs.get('fig')\n",
    "    axarr = kwargs.get('axarr')\n",
    "    loss, costs, trajectories = rollout_fn(*args)\n",
    "    n_samples, T, dims = trajectories.shape\n",
    "\n",
    "    if fig is None or axarr is None:\n",
    "        fig, axarr = plt.subplots(dims, sharex=True)\n",
    "    exp_states = np.array(exp.states)\n",
    "    for d in range(dims):\n",
    "        axarr[d].clear()\n",
    "        st = trajectories[:, :, d]\n",
    "        # plot predictive distribution\n",
    "        for i in range(n_samples):\n",
    "            axarr[d].plot(\n",
    "                np.arange(T-1), st[i, :-1], color='steelblue', alpha=0.3)\n",
    "        # for i in range(len(exp.states)):\n",
    "        #    axarr[d].plot(\n",
    "        #         np.arange(T-1), exp_states[i,1:,d],\n",
    "        #         color='orange', alpha=0.3)\n",
    "        # plot experience\n",
    "        axarr[d].plot(\n",
    "            np.arange(T-1), np.array(exp.states[-1])[1:H, d], color='red')\n",
    "        axarr[d].plot(\n",
    "            np.arange(T-1), st[:, :-1].mean(0), color='purple')\n",
    "    plt.show(block=False)\n",
    "    plt.waitforbuttonpress(0.1)\n",
    "\n",
    "    return fig, axarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_bnn_dyn = True\n",
    "use_bnn_pol = True\n",
    "\n",
    "# setup output directory\n",
    "utils.set_output_dir(os.path.join(utils.get_output_dir(), 'cartpole'))\n",
    "\n",
    "params = cartpole.default_params()\n",
    "n_rnd = 4                           # number of random initial trials\n",
    "n_opt = 100                         # learning iterations\n",
    "n_samples = 50                      # number of MC samples if bayesian nn\n",
    "learning_rate = 5e-4\n",
    "polyak_averaging = 0.99\n",
    "H = params['max_steps']\n",
    "gamma = params['discount']\n",
    "angle_dims = params['angle_dims']\n",
    "\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kusanagi.ghost.control.NNPolicy.NNPolicy'> True\n",
      "[2017-08-22 08:55:30.738066] Experience > Initialising new experience dataset\n"
     ]
    }
   ],
   "source": [
    "# init environment\n",
    "env = cartpole.Cartpole(**params['plant'])\n",
    "\n",
    "# init policy\n",
    "pol = control.NNPolicy(p0.mean, **params['policy'])\\\n",
    "    if use_bnn_pol else control.RBFPolicy(**params['policy'])\n",
    "randpol = control.RandPolicy(maxU=pol.maxU)\n",
    "\n",
    "# init dynmodel\n",
    "dyn = regression.BNN(**params['dynamics_model'])\\\n",
    "    if use_bnn_dyn else regression.SSGP_UI(**params['dynamics_model'])\n",
    "\n",
    "# init cost model\n",
    "cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# create experience dataset\n",
    "exp = ExperienceDataset()\n",
    "\n",
    "# init policy optimizer\n",
    "if use_bnn_dyn:\n",
    "    params['optimizer']['min_method'] = 'adam'\n",
    "    params['optimizer']['max_evals'] = 1000\n",
    "    polopt = SGDOptimizer(**params['optimizer'])\n",
    "else:\n",
    "    polopt = ScipyOptimizer(**params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-08-22 08:55:30.833284] apply_controller > Starting run\n",
      "[2017-08-22 08:55:30.834136] apply_controller > Running for 4.000000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/miniconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py:2453: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-08-22 08:55:33.103047] apply_controller > Done. Stopping robot. Value of run [39.996964]\n",
      "[2017-08-22 08:55:33.104203] Cartpole > Stopping robot\n",
      "[2017-08-22 08:55:33.105613] apply_controller > Starting run\n",
      "[2017-08-22 08:55:33.107012] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 08:55:35.008577] apply_controller > Done. Stopping robot. Value of run [39.990791]\n",
      "[2017-08-22 08:55:35.009431] Cartpole > Stopping robot\n",
      "[2017-08-22 08:55:35.010121] apply_controller > Starting run\n",
      "[2017-08-22 08:55:35.010892] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 08:55:36.957314] apply_controller > Done. Stopping robot. Value of run [39.979496]\n",
      "[2017-08-22 08:55:36.958081] Cartpole > Stopping robot\n",
      "[2017-08-22 08:55:36.958687] apply_controller > Starting run\n",
      "[2017-08-22 08:55:36.959345] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 08:55:38.852115] apply_controller > Done. Stopping robot. Value of run [38.235622]\n",
      "[2017-08-22 08:55:38.852821] Cartpole > Stopping robot\n"
     ]
    }
   ],
   "source": [
    "# callback executed after every call to env.step\n",
    "def step_cb(state, action, cost, info):\n",
    "    exp.add_sample(state, action, cost, info)\n",
    "    env.render()\n",
    "\n",
    "def polopt_cb(*args, **kwargs):\n",
    "    if hasattr(dyn, 'update'):\n",
    "        dyn.update()\n",
    "    if hasattr(pol, 'update'):\n",
    "        pol.update()\n",
    "        \n",
    "    loss, dloss = args[:2]\n",
    "    grad_norms = [np.sqrt((d.__array__()**2).sum()) for d in dloss]\n",
    "    if sum(grad_norms) >  10.0*len(grad_norms):\n",
    "        print([np.sqrt((d.__array__()**2).sum()) for d in dloss])\n",
    "\n",
    "# function to execute before applying policy\n",
    "def gTrig(state):\n",
    "    return utils.gTrig_np(state, angle_dims).flatten()\n",
    "\n",
    "# during first n_rnd trials, apply randomized controls\n",
    "for i in range(n_rnd):\n",
    "    exp.new_episode()\n",
    "    apply_controller(env, randpol, H,\n",
    "                     preprocess=gTrig,\n",
    "                     callback=step_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-08-22 08:55:39.067902] ==== Iteration [1], experience: [160 steps] ====\n",
      "[2017-08-22 08:55:39.068672] train_dynamics > Training dynamics model\n",
      "[2017-08-22 08:55:39.072653] train_dynamics > Dataset size:: Inputs: [ (156, 6) ], Targets: [ (156, 4) ]  \n",
      "[2017-08-22 08:55:39.073947] BNN > Building network\n",
      "InputLayer {'shape': (None, 6), 'name': 'BNN_input'}\n",
      "DenseLayer {'num_units': 400, 'nonlinearity': <lasagne.nonlinearities.LeakyRectify object at 0x7f729b150ef0>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'BNN_fc0'}\n",
      "DropoutLayer {'p': 0.1, 'rescale': False, 'name': 'BNN_drop0', 'n_samples': array(25, dtype=int32)}\n",
      "DenseLayer {'num_units': 400, 'nonlinearity': <lasagne.nonlinearities.LeakyRectify object at 0x7f729b150ef0>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'BNN_fc1'}\n",
      "DropoutLayer {'p': 0.1, 'rescale': False, 'name': 'BNN_drop1', 'n_samples': array(25, dtype=int32)}\n",
      "DenseLayer {'num_units': 400, 'nonlinearity': <lasagne.nonlinearities.LeakyRectify object at 0x7f729b150ef0>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'BNN_fc2'}\n",
      "DropoutLayer {'p': 0.1, 'rescale': False, 'name': 'BNN_drop2', 'n_samples': array(25, dtype=int32)}\n",
      "DenseLayer {'num_units': 8, 'nonlinearity': <function linear at 0x7f729b157048>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'BNN_output'}\n",
      "[2017-08-22 08:55:39.166975] BNN > Initialising loss function\n",
      "[2017-08-22 08:55:39.997844] BNN_opt > Building computation graph for gradients\n",
      "[2017-08-22 08:55:40.112829] BNN_opt > Computing parameter update rules\n",
      "[2017-08-22 08:55:40.192768] BNN_opt > Compiling function for loss\n",
      "[2017-08-22 08:55:41.769271] BNN_opt > Compiling parameter updates\n",
      "[2017-08-22 08:55:45.280125] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 08:55:45.298537] BNN_opt > Initial loss [560.778564453125]\n",
      "\u001b[2K[2017-08-22 08:55:57.654772] BNN_opt > Curr loss: -9.225377E+02 [960: -9.302339E+02], n_evals: 1000, Avg. time per updt: 0.011181\n",
      "[2017-08-22 08:55:57.672240] BNN_opt > Done training. New loss [-952.262756] iter: [1001]\n",
      "[2017-08-22 08:55:57.673045] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 08:55:57.991823] NNPolicy > Building network\n",
      "InputLayer {'shape': (None, 5), 'name': 'NNPolicy_input'}\n",
      "DenseLayer {'num_units': 100, 'nonlinearity': <function rectify at 0x7f729b154ae8>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'NNPolicy_fc0'}\n",
      "DropoutLayer {'p': 0.05, 'rescale': False, 'name': 'NNPolicy_drop0', 'n_samples': array(50, dtype=int32)}\n",
      "DenseLayer {'num_units': 100, 'nonlinearity': <function rectify at 0x7f729b154ae8>, 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'NNPolicy_fc1'}\n",
      "DropoutLayer {'p': 0.05, 'rescale': False, 'name': 'NNPolicy_drop1', 'n_samples': array(50, dtype=int32)}\n",
      "DenseLayer {'num_units': 1, 'nonlinearity': functools.partial(<function tanhSat at 0x7f729abeaf28>, e=array([ 10.], dtype=float32)), 'W': <lasagne.init.Orthogonal object at 0x7f729abec0b8>, 'b': <lasagne.init.Constant object at 0x7f729abec128>, 'name': 'NNPolicy_output'}\n",
      "[2017-08-22 08:55:58.767471] mc_pilco.rollout > Building computation graph for state particles propagation\n",
      "[2017-08-22 08:55:59.194072] SGDOptimizer > Building computation graph for gradients\n",
      "[2017-08-22 08:55:59.857581] SGDOptimizer > Computing parameter update rules\n",
      "[2017-08-22 08:55:59.910982] SGDOptimizer > Compiling function for loss\n",
      "[2017-08-22 08:56:03.846793] SGDOptimizer > Compiling parameter updates\n",
      "[2017-08-22 08:56:17.492777] mc_pilco.rollout > Building computation graph for state particles propagation\n",
      "[2017-08-22 08:56:19.531539] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 08:56:19.714873] SGDOptimizer > Initial loss [0.9999964833259583]\n",
      "\u001b[2K[2017-08-22 08:58:53.054715] SGDOptimizer > Curr loss: 8.729975E-01 [996: 8.726196E-01], n_evals: 999, Avg. time per updt: 0.152688\n",
      "[2017-08-22 08:58:53.098396] SGDOptimizer > Done training. New loss [0.855116] iter: [999]\n",
      "[2017-08-22 08:58:53.099461] apply_controller > Starting run\n",
      "[2017-08-22 08:58:53.100266] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 08:58:53.101606] NNPolicy > Initialising expression graph for prediction\n",
      "[2017-08-22 08:58:53.229761] NNPolicy > Compiling mean and variance of prediction\n",
      "[2017-08-22 08:58:53.370178] NNPolicy > Done compiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/miniconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py:2453: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-08-22 08:58:55.413758] apply_controller > Done. Stopping robot. Value of run [25.206909]\n",
      "[2017-08-22 08:58:55.414743] Cartpole > Stopping robot\n",
      "[2017-08-22 08:58:56.681187] ==== Iteration [2], experience: [200 steps] ====\n",
      "[2017-08-22 08:58:56.682127] train_dynamics > Training dynamics model\n",
      "[2017-08-22 08:58:56.684337] train_dynamics > Dataset size:: Inputs: [ (195, 6) ], Targets: [ (195, 4) ]  \n",
      "[2017-08-22 08:58:56.685198] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 08:58:56.702383] BNN_opt > Initial loss [-94.5313949584961]\n",
      "\u001b[2K[2017-08-22 08:59:09.548228] BNN_opt > Curr loss: -9.357072E+02 [987: -9.431229E+02], n_evals: 1000, Avg. time per updt: 0.011584\n",
      "[2017-08-22 08:59:09.566915] BNN_opt > Done training. New loss [-910.167236] iter: [1001]\n",
      "[2017-08-22 08:59:09.570349] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 08:59:10.405125] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 08:59:10.562705] SGDOptimizer > Initial loss [0.8878908157348633]\n",
      "\u001b[2K[2017-08-22 09:01:51.338590] SGDOptimizer > Curr loss: 8.816276E-01 [602: 8.789349E-01], n_evals: 999, Avg. time per updt: 0.160109\n",
      "[2017-08-22 09:01:51.386375] SGDOptimizer > Done training. New loss [0.881300] iter: [999]\n",
      "[2017-08-22 09:01:51.387549] apply_controller > Starting run\n",
      "[2017-08-22 09:01:51.388403] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:01:56.497121] apply_controller > Done. Stopping robot. Value of run [28.502312]\n",
      "[2017-08-22 09:01:56.498111] Cartpole > Stopping robot\n",
      "[2017-08-22 09:01:57.350215] ==== Iteration [3], experience: [240 steps] ====\n",
      "[2017-08-22 09:01:57.351860] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:01:57.356030] train_dynamics > Dataset size:: Inputs: [ (234, 6) ], Targets: [ (234, 4) ]  \n",
      "[2017-08-22 09:01:57.358746] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:01:57.376289] BNN_opt > Initial loss [-619.9646606445312]\n",
      "\u001b[2K[2017-08-22 09:02:11.573535] BNN_opt > Curr loss: -9.857764E+02 [964: -9.945239E+02], n_evals: 1000, Avg. time per updt: 0.012841\n",
      "[2017-08-22 09:02:11.594126] BNN_opt > Done training. New loss [-989.287415] iter: [1001]\n",
      "[2017-08-22 09:02:11.596578] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:02:12.450623] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:02:12.612670] SGDOptimizer > Initial loss [0.8763510584831238]\n",
      "\u001b[2K[2017-08-22 09:04:53.464001] SGDOptimizer > Curr loss: 8.908548E-01 [9: 8.775677E-01], n_evals: 999, Avg. time per updt: 0.160177\n",
      "[2017-08-22 09:04:53.505993] SGDOptimizer > Done training. New loss [0.872563] iter: [999]\n",
      "[2017-08-22 09:04:53.506981] apply_controller > Starting run\n",
      "[2017-08-22 09:04:53.507760] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:04:58.322491] apply_controller > Done. Stopping robot. Value of run [30.888557]\n",
      "[2017-08-22 09:04:58.323343] Cartpole > Stopping robot\n",
      "[2017-08-22 09:04:59.088313] ==== Iteration [4], experience: [280 steps] ====\n",
      "[2017-08-22 09:04:59.089171] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:04:59.091414] train_dynamics > Dataset size:: Inputs: [ (273, 6) ], Targets: [ (273, 4) ]  \n",
      "[2017-08-22 09:04:59.092323] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:04:59.109104] BNN_opt > Initial loss [-571.6293334960938]\n",
      "\u001b[2K[2017-08-22 09:05:11.497191] BNN_opt > Curr loss: -1.016882E+03 [998: -1.017918E+03], n_evals: 1000, Avg. time per updt: 0.011180\n",
      "[2017-08-22 09:05:11.517448] BNN_opt > Done training. New loss [-1035.862183] iter: [1001]\n",
      "[2017-08-22 09:05:11.519148] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:05:12.370238] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:05:12.542697] SGDOptimizer > Initial loss [0.8826278448104858]\n",
      "\u001b[2K[2017-08-22 09:07:43.603437] SGDOptimizer > Curr loss: 8.773439E-01 [989: 8.770952E-01], n_evals: 999, Avg. time per updt: 0.150408\n",
      "[2017-08-22 09:07:43.642416] SGDOptimizer > Done training. New loss [0.874178] iter: [999]\n",
      "[2017-08-22 09:07:43.643498] apply_controller > Starting run\n",
      "[2017-08-22 09:07:43.644305] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:07:48.536427] apply_controller > Done. Stopping robot. Value of run [30.163364]\n",
      "[2017-08-22 09:07:48.537232] Cartpole > Stopping robot\n",
      "[2017-08-22 09:07:49.293898] ==== Iteration [5], experience: [320 steps] ====\n",
      "[2017-08-22 09:07:49.294696] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:07:49.298074] train_dynamics > Dataset size:: Inputs: [ (312, 6) ], Targets: [ (312, 4) ]  \n",
      "[2017-08-22 09:07:49.298836] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:07:49.317242] BNN_opt > Initial loss [-837.0512084960938]\n",
      "\u001b[2K[2017-08-22 09:08:01.869201] BNN_opt > Curr loss: -1.031964E+03 [891: -1.041445E+03], n_evals: 1000, Avg. time per updt: 0.011366\n",
      "[2017-08-22 09:08:01.887938] BNN_opt > Done training. New loss [-1035.473633] iter: [1001]\n",
      "[2017-08-22 09:08:01.888815] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:08:02.673934] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:08:02.830411] SGDOptimizer > Initial loss [0.8713998794555664]\n",
      "\u001b[2K[2017-08-22 09:10:36.237274] SGDOptimizer > Curr loss: 8.844561E-01 [9: 8.717306E-01], n_evals: 999, Avg. time per updt: 0.152744\n",
      "[2017-08-22 09:10:36.276377] SGDOptimizer > Done training. New loss [0.870661] iter: [999]\n",
      "[2017-08-22 09:10:36.277456] apply_controller > Starting run\n",
      "[2017-08-22 09:10:36.278501] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:10:41.302094] apply_controller > Done. Stopping robot. Value of run [28.882496]\n",
      "[2017-08-22 09:10:41.302884] Cartpole > Stopping robot\n",
      "[2017-08-22 09:10:42.881801] ==== Iteration [6], experience: [360 steps] ====\n",
      "[2017-08-22 09:10:42.883729] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:10:42.888943] train_dynamics > Dataset size:: Inputs: [ (351, 6) ], Targets: [ (351, 4) ]  \n",
      "[2017-08-22 09:10:42.890415] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:10:42.907496] BNN_opt > Initial loss [-774.8704223632812]\n",
      "\u001b[2K[2017-08-22 09:10:56.138167] BNN_opt > Curr loss: -1.045884E+03 [684: -1.051305E+03], n_evals: 1000, Avg. time per updt: 0.012029\n",
      "[2017-08-22 09:10:56.157079] BNN_opt > Done training. New loss [-1087.266968] iter: [1001]\n",
      "[2017-08-22 09:10:56.158413] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:10:56.986388] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:10:57.180993] SGDOptimizer > Initial loss [0.8821266293525696]\n",
      "\u001b[2K[2017-08-22 09:13:28.795363] SGDOptimizer > Curr loss: 8.914379E-01 [10: 8.823391E-01], n_evals: 999, Avg. time per updt: 0.150961\n",
      "[2017-08-22 09:13:28.838484] SGDOptimizer > Done training. New loss [0.880083] iter: [999]\n",
      "[2017-08-22 09:13:28.839686] apply_controller > Starting run\n",
      "[2017-08-22 09:13:28.840470] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:13:34.335691] apply_controller > Done. Stopping robot. Value of run [30.973045]\n",
      "[2017-08-22 09:13:34.336626] Cartpole > Stopping robot\n",
      "[2017-08-22 09:13:35.148642] ==== Iteration [7], experience: [400 steps] ====\n",
      "[2017-08-22 09:13:35.149453] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:13:35.152015] train_dynamics > Dataset size:: Inputs: [ (390, 6) ], Targets: [ (390, 4) ]  \n",
      "[2017-08-22 09:13:35.152940] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:13:35.167806] BNN_opt > Initial loss [-795.2657470703125]\n",
      "\u001b[2K[2017-08-22 09:13:47.959366] BNN_opt > Curr loss: -1.052903E+03 [978: -1.060388E+03], n_evals: 1000, Avg. time per updt: 0.011595\n",
      "[2017-08-22 09:13:47.977900] BNN_opt > Done training. New loss [-1090.196533] iter: [1001]\n",
      "[2017-08-22 09:13:47.979574] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:13:48.786871] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:13:48.967117] SGDOptimizer > Initial loss [0.887752890586853]\n",
      "\u001b[2K[2017-08-22 09:16:22.939420] SGDOptimizer > Curr loss: 8.867928E-01 [477: 8.827451E-01], n_evals: 999, Avg. time per updt: 0.153313\n",
      "[2017-08-22 09:16:22.979904] SGDOptimizer > Done training. New loss [0.885800] iter: [999]\n",
      "[2017-08-22 09:16:22.981081] apply_controller > Starting run\n",
      "[2017-08-22 09:16:22.981866] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:16:27.917262] apply_controller > Done. Stopping robot. Value of run [29.857691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-08-22 09:16:27.918026] Cartpole > Stopping robot\n",
      "[2017-08-22 09:16:28.701238] ==== Iteration [8], experience: [440 steps] ====\n",
      "[2017-08-22 09:16:28.702185] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:16:28.704814] train_dynamics > Dataset size:: Inputs: [ (429, 6) ], Targets: [ (429, 4) ]  \n",
      "[2017-08-22 09:16:28.705657] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:16:28.723029] BNN_opt > Initial loss [-996.7118530273438]\n",
      "\u001b[2K[2017-08-22 09:16:40.049278] BNN_opt > Curr loss: -1.063284E+03 [792: -1.070397E+03], n_evals: 1000, Avg. time per updt: 0.010296\n",
      "[2017-08-22 09:16:40.067836] BNN_opt > Done training. New loss [-1099.074951] iter: [1001]\n",
      "[2017-08-22 09:16:40.068670] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:16:40.881274] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:16:41.032379] SGDOptimizer > Initial loss [0.8833974599838257]\n",
      "\u001b[2K[2017-08-22 09:19:18.642946] SGDOptimizer > Curr loss: 8.900027E-01 [28: 8.827827E-01], n_evals: 999, Avg. time per updt: 0.156921\n",
      "[2017-08-22 09:19:18.685936] SGDOptimizer > Done training. New loss [0.888797] iter: [999]\n",
      "[2017-08-22 09:19:18.687307] apply_controller > Starting run\n",
      "[2017-08-22 09:19:18.688239] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:19:23.922545] apply_controller > Done. Stopping robot. Value of run [29.416195]\n",
      "[2017-08-22 09:19:23.923618] Cartpole > Stopping robot\n",
      "[2017-08-22 09:19:24.781839] ==== Iteration [9], experience: [480 steps] ====\n",
      "[2017-08-22 09:19:24.782623] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:19:24.786828] train_dynamics > Dataset size:: Inputs: [ (468, 6) ], Targets: [ (468, 4) ]  \n",
      "[2017-08-22 09:19:24.787590] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:19:24.804125] BNN_opt > Initial loss [-900.066650390625]\n",
      "\u001b[2K[2017-08-22 09:19:36.036767] BNN_opt > Curr loss: -1.060030E+03 [526: -1.071150E+03], n_evals: 1000, Avg. time per updt: 0.010221\n",
      "[2017-08-22 09:19:36.054886] BNN_opt > Done training. New loss [-1131.071167] iter: [1001]\n",
      "[2017-08-22 09:19:36.055683] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:19:36.871407] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:19:37.018866] SGDOptimizer > Initial loss [0.8849982023239136]\n",
      "\u001b[2K[2017-08-22 09:22:16.729906] SGDOptimizer > Curr loss: 8.945532E-01 [11: 8.852454E-01], n_evals: 999, Avg. time per updt: 0.159027\n",
      "[2017-08-22 09:22:16.781207] SGDOptimizer > Done training. New loss [0.895899] iter: [999]\n",
      "[2017-08-22 09:22:16.782459] apply_controller > Starting run\n",
      "[2017-08-22 09:22:16.783219] apply_controller > Running for 4.000000 seconds\n",
      "[2017-08-22 09:22:21.898005] apply_controller > Done. Stopping robot. Value of run [36.304504]\n",
      "[2017-08-22 09:22:21.898833] Cartpole > Stopping robot\n",
      "[2017-08-22 09:22:22.712651] ==== Iteration [10], experience: [520 steps] ====\n",
      "[2017-08-22 09:22:22.713553] train_dynamics > Training dynamics model\n",
      "[2017-08-22 09:22:22.719116] train_dynamics > Dataset size:: Inputs: [ (507, 6) ], Targets: [ (507, 4) ]  \n",
      "[2017-08-22 09:22:22.720179] BNN_opt > Optimizing parameters via mini batches\n",
      "[2017-08-22 09:22:22.735184] BNN_opt > Initial loss [-909.3292236328125]\n",
      "\u001b[2K[2017-08-22 09:22:34.679242] BNN_opt > Curr loss: -1.064568E+03 [983: -1.072627E+03], n_evals: 1000, Avg. time per updt: 0.010837\n",
      "[2017-08-22 09:22:34.699587] BNN_opt > Done training. New loss [-1047.317383] iter: [1001]\n",
      "[2017-08-22 09:22:34.700875] train_dynamics > Done training dynamics model\n",
      "[2017-08-22 09:22:35.509953] SGDOptimizer > Optimizing parameters\n",
      "[2017-08-22 09:22:35.697325] SGDOptimizer > Initial loss [0.908614993095398]\n",
      "\u001b[2K[2017-08-22 09:24:31.883107] SGDOptimizer > Curr loss: 9.113502E-01 [40: 9.055173E-01], n_evals: 728, Avg. time per updt: 0.158754"
     ]
    }
   ],
   "source": [
    "# PILCO loop\n",
    "rollout_fn = None\n",
    "fig, axarr = None, None\n",
    "for i in range(n_opt):\n",
    "    total_exp = sum([len(st) for st in exp.states])\n",
    "    msg = '==== Iteration [%d], experience: [%d steps] ===='\n",
    "    utils.print_with_stamp(msg % (i+1, total_exp))\n",
    "\n",
    "    # train dynamics model\n",
    "    train_dynamics(dyn, exp, angle_dims=angle_dims)\n",
    "\n",
    "    # initial state distribution\n",
    "    x0 = np.array([st[0] for st in exp.states])\n",
    "    m0 = x0.mean(0)\n",
    "    S0 = np.cov(x0, rowvar=False, ddof=1) +\\\n",
    "        1e-4*np.eye(x0.shape[1]) if len(x0) > 2 else p0.cov\n",
    "\n",
    "    if fig is not None:\n",
    "        # plot rollout\n",
    "        fig, axarr = plot_rollout(\n",
    "            rollout_fn, m0, S0, H, gamma, fig=fig, axarr=axarr)\n",
    "\n",
    "    # train policy\n",
    "    if polopt.loss_fn is None or dyn.should_recompile:\n",
    "        loss_kwargs = {}\n",
    "        obj_kwargs = {}\n",
    "        extra_inps = []\n",
    "        if use_bnn_dyn:\n",
    "            # init learning rate parameter\n",
    "            lr = theano.tensor.scalar('lr')\n",
    "            extra_inps += [lr]\n",
    "\n",
    "            # parameters for building loss function\n",
    "            loss_kwargs['n_samples'] = n_samples\n",
    "            loss_kwargs['resample_particles'] = True\n",
    "            obj_kwargs['learning_rate'] = lr\n",
    "            obj_kwargs['clip'] = 10.0\n",
    "            obj_kwargs['polyak_averaging'] = polyak_averaging\n",
    "            learner = mc_pilco\n",
    "        else:\n",
    "            learner = pilco\n",
    "\n",
    "        # build loss function\n",
    "        loss, inps, updts = learner.get_loss(\n",
    "            pol, dyn, cost, D, angle_dims, **loss_kwargs)\n",
    "        inps += extra_inps\n",
    "\n",
    "        # set objective of policy optimizer\n",
    "        polopt.set_objective(loss, pol.get_params(symbolic=True),\n",
    "                             inps, updts, **obj_kwargs)\n",
    "\n",
    "        # build rollout function for plotting\n",
    "        if rollout_fn is None:\n",
    "            loss_kwargs['resample_particles'] = False\n",
    "            rollout_fn = learner.build_rollout(\n",
    "                pol, dyn, cost, D, angle_dims, **loss_kwargs)\n",
    "\n",
    "    polopt_args = [m0, S0, H, gamma]\n",
    "    if use_bnn_dyn:\n",
    "        polopt_args.append(learning_rate)\n",
    "    polopt.minimize(*polopt_args,\n",
    "                    callback=polopt_cb)\n",
    "\n",
    "    # apply controller\n",
    "    exp.new_episode(policy_params=pol.get_params())\n",
    "    apply_controller(env, pol, H,\n",
    "                     preprocess=gTrig, callback=step_cb)\n",
    "\n",
    "    # plot rollout\n",
    "    fig, axarr = plot_rollout(\n",
    "        rollout_fn, m0, S0, H, gamma, fig=fig, axarr=axarr)\n",
    "input('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
