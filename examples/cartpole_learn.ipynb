{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda0: TITAN Xp (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    " %matplotlib tk\n",
    "from kusanagi.shell import cartpole\n",
    "from kusanagi.ghost import control\n",
    "from kusanagi.ghost import regression\n",
    "from kusanagi.base import apply_controller, train_dynamics, ExperienceDataset\n",
    "from kusanagi.ghost.optimizers import ScipyOptimizer\n",
    "from kusanagi.ghost.algorithms import pilco_, mc_pilco_\n",
    "from kusanagi import utils\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "params = cartpole.default_params()\n",
    "angle_dims = params['angle_dims']\n",
    "n_random = 4\n",
    "n_polopt = 20\n",
    "max_steps = 40\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-04 10:29:55.590162] RBFPolicy_sat > Initializing parameters\n",
      "[2017-07-04 10:29:55.600540] RBFPolicy_sat > Initialising expression graph for full GP training loss function\n",
      "[2017-07-04 10:29:55.648513] RBFPolicy_sat > Initialising expression graph for prediction\n",
      "[2017-07-04 10:29:55.663472] RBFPolicy_sat > Compiling mean and variance of prediction\n",
      "[2017-07-04 10:29:56.483038] RBFPolicy_sat > Done compiling\n",
      "[2017-07-04 10:29:56.496639] Experience > Initialising new experience dataset\n"
     ]
    }
   ],
   "source": [
    "# environment\n",
    "env = cartpole.Cartpole(**params['plant'])\n",
    "\n",
    "# policy\n",
    "policy = control.RBFPolicy(**params['policy'])\n",
    "randpol = control.RandPolicy(maxU=policy.maxU, random_walk=True)\n",
    "\n",
    "# dynamics model, inputs are state + action, outputs are changes in state\n",
    "dynmodel = regression.SSGP_UI(**params['dynamics_model'])\n",
    "\n",
    "# cost function model\n",
    "cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# experience dataset\n",
    "exp = ExperienceDataset()\n",
    "\n",
    "# optimizers\n",
    "dynopt = ScipyOptimizer(**params['optimizer'])\n",
    "polopt = ScipyOptimizer(**params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-04 10:29:56.582885] apply_controller > Starting run\n",
      "[2017-07-04 10:29:56.585381] apply_controller > Running for 4.000000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/miniconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py:2453: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-04 10:29:58.956347] apply_controller > Done. Stopping robot. Value of run [39.868665]\n",
      "[2017-07-04 10:29:58.957924] Cartpole > Stopping robot\n",
      "[2017-07-04 10:29:58.958622] apply_controller > Starting run\n",
      "[2017-07-04 10:29:58.962546] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-04 10:30:01.288938] apply_controller > Done. Stopping robot. Value of run [39.999393]\n",
      "[2017-07-04 10:30:01.305763] Cartpole > Stopping robot\n",
      "[2017-07-04 10:30:01.308037] apply_controller > Starting run\n",
      "[2017-07-04 10:30:01.309965] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-04 10:30:03.446801] apply_controller > Done. Stopping robot. Value of run [39.999460]\n",
      "[2017-07-04 10:30:03.463140] Cartpole > Stopping robot\n",
      "[2017-07-04 10:30:03.465378] apply_controller > Starting run\n",
      "[2017-07-04 10:30:03.467278] apply_controller > Running for 4.000000 seconds\n",
      "[2017-07-04 10:30:05.601202] apply_controller > Done. Stopping robot. Value of run [39.860530]\n",
      "[2017-07-04 10:30:05.617529] Cartpole > Stopping robot\n"
     ]
    }
   ],
   "source": [
    "# callback executed after every call to env.step\n",
    "def step_cb(state, action, cost, info):\n",
    "    exp.add_sample(state, action, cost, info)\n",
    "    env.render()\n",
    "    \n",
    "# function to execute before applying policy\n",
    "def gTrig(state):\n",
    "    return utils.gTrig_np(state, angle_dims).flatten()\n",
    "\n",
    "# initial data collection runs with random controls\n",
    "for i in range(n_random):\n",
    "    exp.new_episode()\n",
    "    states, actions, costs, infos = apply_controller(env, policy, max_steps,\n",
    "                                                     preprocess=gTrig, callback=step_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-07-04 10:30:05.733518] Iteration 1, total experience: 160 steps\n",
      "[2017-07-04 10:30:05.736889] SSGP_UI > Initialising parameters\n",
      "[2017-07-04 10:30:05.742412] SSGP_UI > Initialising expression graph for full GP training loss function\n",
      "[2017-07-04 10:30:05.787306] ScipyOptimizer > Building computation graph for gradients\n",
      "[2017-07-04 10:30:06.031563] ScipyOptimizer > Compiling function for loss\n",
      "[2017-07-04 10:30:06.554745] ScipyOptimizer > Compiling function for loss+gradients\n",
      "[2017-07-04 10:30:10.223542] ScipyOptimizer > Optimizing parameters\n",
      "[2017-07-04 10:30:10.244801] ScipyOptimizer > Initial loss [303.13458279479397]\n",
      "[2017-07-04 10:30:10.245588] ScipyOptimizer > Using BFGS optimizer\n",
      "\u001b[2K[2017-07-04 10:30:10.419054] ScipyOptimizer > Current value: -398.03754391416976, Total evaluations: 6,         Avg. time per call: 0.031891   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancamilog/workspace/kusanagi/kusanagi/ghost/optimizers/scipy_optimizer.py:145: OptimizeWarning: Unknown solver options: maxfun, maxcor, maxls, ftol\n",
      "  'gtol': 1.0e-6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2017-07-04 10:30:13.530043] ScipyOptimizer > Current value: -1241.603170525901, Total evaluations: 138,         Avg. time per call: 0.019742    \n",
      "[2017-07-04 10:30:13.533816] ScipyOptimizer > Done training. New value [-1241.603171] iter: [136]\n",
      "[2017-07-04 10:30:13.537197] pilco.rollout > Building computation graph for belief state propagation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-14531cb96720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# train policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpolopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_pol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilco_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpolopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_pol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpolopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/algorithms/pilco_.py\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(policy, dynmodel, cost, D, angle_dims, intermediate_outs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     r_outs, updts = rollout(mx0, Sx0, H, gamma0,\n\u001b[1;32m    173\u001b[0m                             \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                             D, angle_dims)\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mmean_costs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/algorithms/pilco_.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(mx0, Sx0, H, gamma0, policy, dynmodel, cost, D, angle_dims)\u001b[0m\n\u001b[1;32m    128\u001b[0m                                         \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                                         \u001b[0mallow_gc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                                         name=\"pilco.rollout_scan\")\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmean_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/lib/Theano/theano/scan_module/scan.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict, return_list)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# and outputs that needs to be separated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mas_while\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/algorithms/pilco_.py\u001b[0m in \u001b[0;36mstep_rollout\u001b[0;34m(mx, Sx, gamma, *args)\u001b[0m\n\u001b[1;32m    105\u001b[0m         '''\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# get next state distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mb_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_belief\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mmx_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSx_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/algorithms/pilco_.py\u001b[0m in \u001b[0;36mpropagate_belief\u001b[0;34m(mx, Sx, policy, dynmodel, D, angle_dims)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#  predict the change in state given current state-action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# C_deltax = inv (Sxu) dot Sxu_deltax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mm_deltax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_deltax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_deltax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmxu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# compute the successor state distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/regression/SSGP.py\u001b[0m in \u001b[0;36mpredict_symbolic\u001b[0;34m(self, mx, Sx)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# precompute some variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mMs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0msf2M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloghyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0msn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloghyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midims\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# learning loop\n",
    "for i in range(n_polopt): \n",
    "    utils.print_with_stamp('Iteration %d, total experience: %d steps'%(i+1, sum([len(st) for st in exp.states])))\n",
    "    # train dynamics model\n",
    "    #train_dynamics(dynmodel, exp, angle_dims=angle_dims, init_episode=0)\n",
    "    X, Y = exp.get_dynmodel_dataset(deltas=True, angle_dims=angle_dims)\n",
    "    dynmodel.set_dataset(X, Y)\n",
    "    if dynopt.loss_fn is None:\n",
    "        loss_gp, inps, updts = dynmodel.get_loss()\n",
    "        dynopt.set_objective(loss_gp, dynmodel.get_params(symbolic=True), inps, updts)\n",
    "    dynopt.minimize()\n",
    "    \n",
    "    # train policy\n",
    "    if polopt.loss_fn is None:\n",
    "        loss_pol, inps, updts = pilco_.get_loss(policy, dynmodel, cost, D, angle_dims)\n",
    "        polopt.set_objective(loss_pol, policy.get_params(symbolic=True), inps, updts)\n",
    "    polopt.minimize(p0.mean, p0.cov, 40, 1)\n",
    "    \n",
    "    # apply controller\n",
    "    exp.new_episode(policy_params=policy.get_params())\n",
    "    states, actions, costs, infos = apply_controller(env, policy, max_steps,\n",
    "                                                     preprocess=gTrig, callback=step_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(924.1811476478766),\n",
       " array([[ -306.01761488,  -202.17335583,  -215.72509143,  -119.86554306,\n",
       "          -276.31764957,   -67.52521367, -1667.62789131,   -16.79423829],\n",
       "        [  -45.49039863,   -52.60383272,   -41.9701915 ,   -15.58153214,\n",
       "           -45.7787077 ,    -9.85335037,  -240.07397572,     1.93446688],\n",
       "        [  -54.84919972,   -45.99877261,   -54.86776936,   -11.95147382,\n",
       "           -56.88412831,   -11.30721787,  -166.43947718,     2.66633356],\n",
       "        [  -70.63741594,   -50.67703573,   -34.74237804,   -42.54835666,\n",
       "           -54.95024117,    -4.01160943,  -162.12062864,     2.64143425]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynopt.grads_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SSGP_UI>loghyp]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynopt.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
