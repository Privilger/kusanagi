{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5005 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 770 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from kusanagi.ghost.algorithms.ExperienceDataset import ExperienceDataset\n",
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "global_dtype = torch.FloatTensor\n",
    "#global_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "MATRIX_STRUCTURES = ['general', 'lower', 'upper', 'symmetric']\n",
    "class Solve(torch.autograd.Function):\n",
    "    def __init__(self, A_structure='general'):\n",
    "        self.A_structure = A_structure\n",
    "        \n",
    "    def forward(self, A, b):\n",
    "        if self.A_structure == 'lower':\n",
    "            x = torch.trtrs(b, A, False)[0]\n",
    "        elif self.A_structure == 'upper':\n",
    "            x = torch.trtrs(b, A, True)[0]\n",
    "        else:\n",
    "            x = torch.gesv(b, A)[0]\n",
    "        \n",
    "        self.save_for_backward(A, b, x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def backward(self, output_grads):\n",
    "        \"\"\"\n",
    "        Reverse-mode gradient updates for matrix solve operation c = A \\ b.\n",
    "        Symbolic expression for updates taken from [1]_.\n",
    "        References\n",
    "        ----------\n",
    "        ..[1] M. B. Giles, \"An extended collection of matrix derivative results\n",
    "          for forward and reverse mode automatic differentiation\",\n",
    "          http://eprints.maths.ox.ac.uk/1079/\n",
    "        \"\"\"\n",
    "        A, b, x = self.saved_tensors\n",
    "        \n",
    "        grad_x = output_grads\n",
    "       \n",
    "        # transpose solve\n",
    "        if self.A_structure == 'lower':\n",
    "            grad_b = torch.trtrs(b, A.t(), True)[0]\n",
    "        elif self.A_structure == 'upper':\n",
    "            grad_b = torch.trtrs(b, A.t(), False)[0]\n",
    "        else:\n",
    "            grad_b = torch.gesv(b, A.t())[0]\n",
    "            \n",
    "        # force outer product if vector second input\n",
    "        grad_A = -grad_b[:,None].mm(x[None,:])\\\n",
    "                 if x.ndimension() == 1\\\n",
    "                 else -grad_b.mm(x.t())\n",
    "                \n",
    "        if self.A_structure == 'lower':\n",
    "            grad_A = torch.tril(grad_A)\n",
    "        elif self.A_structure == 'upper':\n",
    "            grad_A = torch.triu(grad_A)\n",
    "        \n",
    "        return grad_A, grad_b\n",
    "    \n",
    "def solve_lower_triangular(A, b):\n",
    "    return Solve(A_structure='lower')(A, b)\n",
    "\n",
    "def solve_upper_triangular(A, b):\n",
    "    return Solve(A_structure='upper')(A, b)\n",
    "\n",
    "class Cholesky(torch.autograd.Function):\n",
    "    def __init__(self, lower=True):\n",
    "        self.lower = lower\n",
    "        \n",
    "    def forward(self, input):\n",
    "        chol = torch.potrf(input, not self.lower)\n",
    "        self.save_for_backward(input,chol)\n",
    "        return chol\n",
    "    \n",
    "    def backward(self, output_grads):\n",
    "        \"\"\"\n",
    "        Cholesky decomposition reverse-mode gradient update.\n",
    "        Symbolic expression for reverse-mode Cholesky gradient taken from [0]_\n",
    "        References\n",
    "        ----------\n",
    "        .. [0] I. Murray, \"Differentiation of the Cholesky decomposition\",\n",
    "           http://arxiv.org/abs/1602.07527\n",
    "        \"\"\"\n",
    "\n",
    "        x, chol_x = self.saved_tensors\n",
    "        dz = output_grads\n",
    "        \n",
    "        # TODO deal with nans \n",
    "        \n",
    "        if not self.lower:\n",
    "            chol_x = chol_x.t()\n",
    "            dz = dz.t()\n",
    "\n",
    "        def tril_and_halve_diagonal(mtx):\n",
    "            \"\"\"Extracts lower triangle of square matrix and halves diagonal.\"\"\"\n",
    "            return torch.tril(mtx) - torch.diag(torch.diag(mtx)/2)\n",
    "            \n",
    "        def conjugate_solve_triangular(outer, inner):\n",
    "            \"\"\"Computes L^{-T} P L^{-1} for lower-triangular L.\"\"\"\n",
    "            return solve_upper_triangular(\n",
    "                outer.t(), solve_upper_triangular(outer.t(), inner.t()).t())\n",
    "        \n",
    "     \n",
    "        s = conjugate_solve_triangular(\n",
    "            chol_x, tril_and_halve_diagonal(chol_x.t().mm(dz)))\n",
    "        \n",
    "        s2 = s + s.t()\n",
    "        sdiag = torch.diag(torch.diag(s))\n",
    "        \n",
    "        if self.lower:\n",
    "            grad = torch.tril(s2) - sdiag\n",
    "        else:\n",
    "            grad = torch.triu(s2) - sdiag\n",
    "            \n",
    "        return grad\n",
    "    \n",
    "def cholesky(input, lower=True):\n",
    "    return Cholesky(lower)(input)\n",
    "\n",
    "def maha(X,Y,M=None):\n",
    "    if not M is None:\n",
    "        XM = X.mm(M)\n",
    "        YM = Y.mm(M)\n",
    "        dist = (XM*X).sum(1).repeat(1, Y.size(0))\\\n",
    "             + (YM*Y).sum(1).t().repeat(X.size(0), 1)\\\n",
    "             - 2*XM.mm(Y.t())\n",
    "    else:\n",
    "        dist = (X**2).sum(1).repeat(1,Y.size(0))\\\n",
    "             + (Y**2).sum(1).t().repeat(X.size(0),1)\\\n",
    "             - 2*X.mm(Y.t())\n",
    "    return dist\n",
    "\n",
    "def SEard(loghyp, X, Y):\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n, D = X.size()\n",
    "    dist = maha(X, Y, torch.diag(torch.exp(-2*loghyp[:D])))\n",
    "    return torch.exp(2*loghyp[D].expand(dist.size()) - 0.5*dist )\n",
    "\n",
    "def Noise(loghyp, X, Y=None):\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    if X is Y:\n",
    "        ones = torch.autograd.Variable(torch.ones(X.size(0)))\n",
    "        K = ones*torch.exp(2*loghyp).expand(ones.size())\n",
    "        return K.diag()\n",
    "    else:\n",
    "        return torch.zeros(X.size(0), X.size(0))\n",
    "    \n",
    "def Sum(loghyp_list,cov_list, X, Y=None):\n",
    "    D = len(cov_list)\n",
    "    K = sum([cov_list[i](loghyp_list[i], X, Y) for i in range(D)])\n",
    "    return K\n",
    "\n",
    "def SEard_params(X, Y):\n",
    "    n, idims = X.size()\n",
    "    odims = Y.size(1)\n",
    "    \n",
    "    loghyp = torch.autograd.Variable(torch.Tensor(odims,idims+1).type(global_dtype),\n",
    "                                     requires_grad=True)\n",
    "    loghyp.data[:, :idims] = 0.5*X.std(0).repeat(odims,1)\n",
    "    loghyp.data[:, idims] = 0.5*Y.std(0)\n",
    "    \n",
    "    return loghyp\n",
    "\n",
    "def Noise_params(X, Y):\n",
    "    n, idims = X.size()\n",
    "    odims = Y.size(1)\n",
    "    \n",
    "    loghyp = torch.autograd.Variable(torch.Tensor(odims,1), requires_grad=True)\n",
    "    loghyp.data[:, 0] = 0.1*Y.std(0)\n",
    "    \n",
    "    return loghyp\n",
    "\n",
    "def GP_loss(loghyps, covs, X, Y):\n",
    "    if not type(covs) is list:\n",
    "        covs= covs[covs]\n",
    "        \n",
    "    n, idims = X.size()\n",
    "    odims = Y.size(1)\n",
    "    \n",
    "    loss = 0\n",
    "    X_ = torch.autograd.Variable(X)\n",
    "    loghyps_ = zip(*loghyps)\n",
    "    \n",
    "    for i in range(odims):\n",
    "        K = Sum(loghyps_[i],covs, X_)\n",
    "        L = cholesky(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-06-15 21:54:10.268943] Experience > Loading state from /media/diskstation/juan/kusanagi/2016_08_11_first_pool_trial/bellyup_experience.zip\n"
     ]
    }
   ],
   "source": [
    "exp = ExperienceDataset(filename='/media/diskstation/juan/kusanagi/2016_08_11_first_pool_trial/bellyup_experience')\n",
    "X, Y = exp.get_dynmodel_dataset()\n",
    "#convert to torch tensors\n",
    "X, Y = torch.from_numpy(X).type(global_dtype),torch.from_numpy(Y).type(global_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = torch.autograd.Variable(X)\n",
    "loghyps = SEard_params(X, Y), Noise_params(X,Y)\n",
    "K = Sum(zip(*loghyps)[0],[SEard,Noise], X_, X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_loss(loghyps, [SEard, Noise], X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cholK = cholesky(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = torch.randn(165,165)\n",
    "S = S + S.t()\n",
    "S = torch.autograd.Variable(S, requires_grad=True)\n",
    "Y0 = torch.autograd.Variable(Y[:,0,None], requires_grad=True)\n",
    "R = Solve('general')(S, Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = torch.eye(R.size(0))\n",
    "R.backward(test_, retain_variables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.1325e+00  7.2322e-01  6.1566e-01  ...  -1.6265e-01  1.0828e-01 -1.5203e+00\n",
       " 7.2322e-01 -4.6186e-01 -3.9317e-01  ...   1.0387e-01 -6.9151e-02  9.7087e-01\n",
       " 6.1566e-01 -3.9317e-01 -3.3469e-01  ...   8.8423e-02 -5.8867e-02  8.2647e-01\n",
       "                ...                   ⋱                   ...                \n",
       "-1.6265e-01  1.0387e-01  8.8423e-02  ...  -2.3361e-02  1.5552e-02 -2.1835e-01\n",
       " 1.0828e-01 -6.9151e-02 -5.8867e-02  ...   1.5552e-02 -1.0354e-02  1.4536e-01\n",
       "-1.5203e+00  9.7087e-01  8.2647e-01  ...  -2.1835e-01  1.4536e-01 -2.0409e+00\n",
       "[torch.FloatTensor of size 165x165]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.grad.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "def alternative_Rop(f, x, u):\n",
    "    v = theano.tensor.ones_like(f)    # Dummy variable v of same type as f\n",
    "    g = theano.tensor.Lop(f, x, v)    # Jacobian of f left multiplied by v\n",
    "    return theano.tensor.Lop(g.flatten(), v, u)\n",
    "\n",
    "s = theano.tensor.fmatrix('s')\n",
    "y = theano.tensor.fvector('y')\n",
    "ymat = theano.tensor.diag(y)\n",
    "r = theano.tensor.slinalg.Cholesky()(s)\n",
    "dr1 = theano.tensor.jacobian(r.flatten(),s)\n",
    "dr2 = theano.tensor.Lop(r, s, theano.tensor.eye(s.shape[0]))\n",
    "f = theano.function(outputs=r, inputs=[s])\n",
    "df1 = theano.function(outputs=dr1, inputs=[s])\n",
    "df2 = theano.function(outputs=dr2, inputs=[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 165)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2(np.eye(165).astype('float32')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Too many parameter passed to theano function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-8916ffac879c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/localdata_ssd/juan/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many parameter passed to theano function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# Set positional arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Too many parameter passed to theano function"
     ]
    }
   ],
   "source": [
    "df2(S.data.numpy(), Y0.data.numpy()[:,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(df1(S.data.numpy(), Y0.data.numpy()[:,0]).reshape((165,165,165)) ,\n",
    "            df2(S.data.numpy(), Y0.data.numpy()[:,0]).reshape((165,165,165)), atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = s.type('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.var.TensorVariable"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
