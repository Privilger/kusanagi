{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib qt\n",
    "import os\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from kusanagi import utils\n",
    "from kusanagi.ghost import control, regression\n",
    "from kusanagi.shell import cartpole, arduino\n",
    "from kusanagi.shell.cost import gaussian_kl_loss, convert_angle_dimensions\n",
    "from kusanagi.shell.experiment_utils import run_pilco_experiment, setup_mc_pilco_experiment\n",
    "\n",
    "# np.random.seed(1337)\n",
    "np.set_printoptions(linewidth=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "params = cartpole.default_params()\n",
    "params['optimizer']['min_method'] = 'adam'\n",
    "params['optimizer']['max_evals'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "params['crn_dropout'] = True\n",
    "params['min_steps'] = 40\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 40                # learning iterations\n",
    "n_samples = 100                     # number of MC samples for bayesian nn\n",
    "\n",
    "H = params['min_steps']\n",
    "gamma = params['discount']\n",
    "angle_dims = params['angle_dims']\n",
    "\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dynamics model\n",
    "dyn_spec = dict(\n",
    "    hidden_dims=[200]*2,\n",
    "    p=True, p_input=True,\n",
    "    nonlinearities=regression.nonlinearities.rectify,\n",
    "    W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "    dropout_class=regression.layers.DenseLogNormalDropoutLayer,\n",
    "    build_fn=regression.dropout_mlp)\n",
    "dyn = regression.BNN(network_spec=dyn_spec, **params['dynamics_model'])\n",
    "\n",
    "# init policy\n",
    "pol_spec = dict(\n",
    "    hidden_dims=[200]*2,\n",
    "    p=0.1, p_input=0.0,\n",
    "    nonlinearities=regression.nonlinearities.rectify,\n",
    "    W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "    dropout_class=regression.layers.DenseDropoutLayer,\n",
    "    build_fn=regression.dropout_mlp)\n",
    "pol = control.NNPolicy(dyn.E, network_spec=pol_spec, heteroscedastic=False, **params['policy'])\n",
    "\n",
    "# init cost model\n",
    "task_cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# init environment\n",
    "env = cartpole.Cartpole(**params['plant'])\n",
    "#env = arduino.SerialPlant(maxU=pol.maxU, loss_func= task_cost, name='target',**params['plant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl regularization\n",
    "state_dims = dyn.E + len(angle_dims)\n",
    "trajs = theano.shared(\n",
    "    np.zeros((n_samples, H+1, state_dims)).astype(theano.config.floatX),\n",
    "    name='trajs')\n",
    "target_mean = theano.shared(\n",
    "    np.zeros(\n",
    "        (H+1, state_dims)).astype(theano.config.floatX),\n",
    "    name='target_mean')\n",
    "target_cov = theano.shared(\n",
    "    np.repeat(\n",
    "        np.eye(state_dims)[None, :, :], H+1, axis=0).astype(theano.config.floatX),\n",
    "    name='target_cov')\n",
    "\n",
    "# define cost as sum of task cost and deviation form expert demonstration\n",
    "def task_plus_il_cost(t, mx, Sx, weights=[1, 1e-4], loss_type=utils.ImitationLossType.KLQP):\n",
    "    '''\n",
    "        The IL term will penalize rollout predictive distributions that \n",
    "        are too different from the target distribution\n",
    "    '''\n",
    "    mxa, Sxa = convert_angle_dimensions(mx, Sx, angle_dims)\n",
    "    mt, St = target_mean[t], target_cov[t]\n",
    "    imitation_loss = 0\n",
    "    if loss_type == utils.ImitationLossType.KLQP:\n",
    "        imitation_loss = gaussian_kl_loss(mxa, Sxa, mt, St)\n",
    "    elif loss_type == utils.ImitationLossType.KLPQ:\n",
    "        imitation_loss = gaussian_kl_loss(mt, St, mxa, Sxa)\n",
    "    elif loss_type == utils.ImitationLossType.KLSYM:\n",
    "        imitation_loss = 0.5*(gaussian_kl_loss(mt, St, mxa, Sxa) + gaussian_kl_loss(mxa, Sxa, mt, St))\n",
    "    return weights[0]*task_cost(mx, Sx)[0] + weights[1]*imitation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extra_shared = [trajs, target_mean, target_cov]\n",
    "rollout_fn = None\n",
    "target_exp = None\n",
    "fig = None\n",
    "axarr = None\n",
    "\n",
    "def update_target_traj(loss, costs, trajectories):\n",
    "    '''\n",
    "        Target distribution will be the rollout predictive \n",
    "        distribution from the previous optimization iterations;\n",
    "        i.e. the KL term in the cost will be \n",
    "                 KL(rollout_pred(params_{i}) || rollout_pred(params_{i-1}) )\n",
    "             when using the reverse KL loss\n",
    "    '''\n",
    "    tr_shape = trajectories.shape\n",
    "    trajectories = trajectories.reshape((tr_shape[0]*tr_shape[1], tr_shape[2]))\n",
    "    trajectories = utils.gTrig(trajectories, angle_dims)\n",
    "    trajectories = trajectories.reshape((tr_shape[0], tr_shape[1], trajectories.shape[-1]))\n",
    "    trajm = trajectories.mean(0)\n",
    "    \n",
    "    trajc = trajectories[:, :, :, None]\n",
    "    trajmm = trajm[:, :, None]\n",
    "    \n",
    "    N = (trajc.shape[0]-1.0).astype(theano.config.floatX)\n",
    "    traj_cov = (trajc*trajc.swapaxes(2,3)).sum(0)/N\n",
    "    traj_cov -= (trajmm*trajmm.swapaxes(1,2))\n",
    "\n",
    "    updates = theano.updates.OrderedUpdates()\n",
    "    updates[trajs] = trajectories\n",
    "    updates[target_mean] = trajm\n",
    "    updates[target_cov] = traj_cov\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def learning_iteration_cb(exp, dyn, pol, polopt, params, rollout_fn_in):\n",
    "    global rollout_fn\n",
    "    global target_exp\n",
    "    i = exp.curr_episode\n",
    "    # setup output directory\n",
    "    exp.save(None, 'experience_%d' % (i))\n",
    "    pol.save(None, 'policy_%d' % (i))\n",
    "    dyn.save(None, 'dynamics_%d' % (i))\n",
    "    with open(os.path.join(utils.get_output_dir(), 'config.dill'), 'wb') as f:\n",
    "        dill.dump(params, f)\n",
    "    rollout_fn = rollout_fn_in\n",
    "    target_exp = exp\n",
    "\n",
    "counter = 0\n",
    "def minimize_cb(*args, **kwargs):\n",
    "    global fig\n",
    "    global axarr\n",
    "    global counter\n",
    "    if counter % 500 == 0:\n",
    "        p0 = params['state0_dist']\n",
    "        m0, S0 = p0.mean, p0.cov\n",
    "        fig, axarr = plot_rollout(rollout_fn, source_exp, m0, S0, H, 1.0,\n",
    "                                  fig=fig, axarr=axarr, n_exp=n_demo, name='Rollout during optimization')\n",
    "        plt.waitforbuttonpress(0.01)\n",
    "    counter += 1\n",
    "    \n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared, extra_updts_init=update_target_traj,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=pol, dyn=dyn)\n",
    "cost = partial(task_plus_il_cost, loss_type=utils.ImitationLossType.KLSYM)\n",
    "\n",
    "# setup output directory\n",
    "output_dir = os.path.join(utils.get_output_dir(), env.name + '_kl_reg')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "\n",
    "run_pilco_experiment(\n",
    "    env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
