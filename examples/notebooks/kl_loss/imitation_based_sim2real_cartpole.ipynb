{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib qt\n",
    "import copy\n",
    "import dill\n",
    "import os\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from kusanagi import utils\n",
    "from kusanagi.base import apply_controller, ExperienceDataset\n",
    "from kusanagi.ghost import control, regression\n",
    "from kusanagi.shell import cartpole, arduino\n",
    "from kusanagi.shell.cost import gaussian_kl_loss, convert_angle_dimensions\n",
    "from kusanagi.shell.experiment_utils import run_pilco_experiment, setup_mc_pilco_experiment, plot_rollout\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# np.random.seed(1337)\n",
    "np.set_printoptions(linewidth=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "output_dir = utils.get_output_dir()\n",
    "sim2real_output_dir = '/localdata/juan/sim2real_results'\n",
    "\n",
    "\n",
    "params = cartpole.default_params()\n",
    "params['optimizer']['min_method'] = 'adam'\n",
    "params['optimizer']['max_evals'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "params['crn_dropout'] = True\n",
    "params['min_steps'] = 30\n",
    "n_samples = 100                     # number of MC samples for bayesian nn\n",
    "n_demo = 10                          # number of example trajectories\n",
    "pol_adjustment = False\n",
    "\n",
    "H = params['min_steps']\n",
    "gamma = params['discount']\n",
    "angle_dims = params['angle_dims']\n",
    "\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size\n",
    "\n",
    "dyn_path = os.path.join(output_dir, 'cartpole_kl_loss/dynamics_21')\n",
    "pol_path = os.path.join(output_dir, 'cartpole_kl_loss/policy_21')\n",
    "exp_path = None #os.path.join(output_dir, 'cartpole_kl_loss/experience_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dyn(params, dyn_path=None, copy_params=True):\n",
    "\n",
    "    dyn_spec = dict(\n",
    "        hidden_dims=[200]*2,\n",
    "        p=True, p_input=True,\n",
    "        nonlinearities=regression.nonlinearities.rectify,\n",
    "        W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "        dropout_class=regression.layers.DenseLogNormalDropoutLayer,\n",
    "        build_fn=regression.dropout_mlp)\n",
    "    \n",
    "    if dyn_path is not None:\n",
    "        # load dynamics model\n",
    "        source_dyn = regression.BNN(\n",
    "            filename=dyn_path, name='source_dyn', **params['dynamics_model'])\n",
    "    else:\n",
    "        # init dynamics model\n",
    "        source_dyn = regression.BNN(network_spec=dyn_spec, name='source_dyn', **params['dynamics_model'])\n",
    "        \n",
    "    if copy_params and dyn_path is not None:\n",
    "        target_dyn = regression.BNN(\n",
    "            filename=dyn_path, name='target_dyn', **params['dynamics_model'])\n",
    "    else:\n",
    "        target_dyn = regression.BNN(network_spec=dyn_spec, name='target_dyn', **params['dynamics_model'])\n",
    "\n",
    "    return source_dyn, target_dyn\n",
    "\n",
    "def init_pol(params,  pol_path=None, adjustment=False, copy_params=True):\n",
    "    pol_spec = dict(\n",
    "        hidden_dims=[200]*2,\n",
    "        p=0.1, p_input=0.0,\n",
    "        nonlinearities=regression.nonlinearities.rectify,\n",
    "        W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "        dropout_class=regression.layers.DenseDropoutLayer,\n",
    "        build_fn=regression.dropout_mlp)\n",
    "\n",
    "    if pol_path is not None:\n",
    "        # load policy\n",
    "        source_pol = control.NNPolicy(params['dynamics_model']['odims'], filename=pol_path, **params['policy'])\n",
    "    else:\n",
    "        # init policy\n",
    "        source_pol = control.NNPolicy(\n",
    "            params['dynamics_model']['odims'], network_spec=pol_spec, heteroscedastic=False, **params['policy'])\n",
    "    if pol_adjustment:\n",
    "        # init adjustment model\n",
    "        target_pol = control.AdjustedPolicy(\n",
    "            source_pol, maxU=source_pol.maxU, angle_dims=source_pol.angle_dims,\n",
    "            adjustment_model_class=regression.BNN)\n",
    "        target_pol.adjustment_model.trained = True\n",
    "    else:\n",
    "        if copy_params and pol_path is not None:\n",
    "            target_pol = control.NNPolicy(\n",
    "                params['dynamics_model']['odims'], filename=pol_path, **params['policy'])\n",
    "        else:\n",
    "            target_pol = control.NNPolicy(\n",
    "                params['dynamics_model']['odims'], network_spec=pol_spec, heteroscedastic=False, **params['policy'])\n",
    "            \n",
    "    return source_pol, target_pol\n",
    "\n",
    "# init task cost\n",
    "task_cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# init source environment\n",
    "params['source'] = params['plant']\n",
    "params['source']['name'] = 'Cartpole_src'\n",
    "source_env = cartpole.Cartpole(**params['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 15:54:17.591285] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 15:54:17.604110] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 15:54:17.609301] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 15:54:17.621552] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 15:54:17.625293] Experience > Initialising new experience dataset\n",
      "[2018-05-12 15:54:17.627521] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 15:54:18.193028] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 15:54:18.433061] NNPolicy > Done compiling\n",
      "[2018-05-12 15:54:18.443733] apply_controller > Starting run\n",
      "[2018-05-12 15:54:18.445150] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:18.995307] apply_controller > Done. Stopping robot. Value of run [8.138649]\n",
      "[2018-05-12 15:54:18.996221] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:18.997192] apply_controller > Starting run\n",
      "[2018-05-12 15:54:18.997895] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:19.368429] apply_controller > Done. Stopping robot. Value of run [7.503297]\n",
      "[2018-05-12 15:54:19.370048] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:19.371749] apply_controller > Starting run\n",
      "[2018-05-12 15:54:19.373127] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:19.741990] apply_controller > Done. Stopping robot. Value of run [8.376228]\n",
      "[2018-05-12 15:54:19.743484] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:19.745254] apply_controller > Starting run\n",
      "[2018-05-12 15:54:19.746631] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:20.119679] apply_controller > Done. Stopping robot. Value of run [7.592145]\n",
      "[2018-05-12 15:54:20.121102] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:20.122635] apply_controller > Starting run\n",
      "[2018-05-12 15:54:20.123953] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:20.456508] apply_controller > Done. Stopping robot. Value of run [7.490353]\n",
      "[2018-05-12 15:54:20.457893] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:20.459771] apply_controller > Starting run\n",
      "[2018-05-12 15:54:20.461355] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:20.839508] apply_controller > Done. Stopping robot. Value of run [7.472194]\n",
      "[2018-05-12 15:54:20.841078] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:20.842560] apply_controller > Starting run\n",
      "[2018-05-12 15:54:20.843943] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:21.171584] apply_controller > Done. Stopping robot. Value of run [8.781160]\n",
      "[2018-05-12 15:54:21.173607] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:21.175171] apply_controller > Starting run\n",
      "[2018-05-12 15:54:21.176546] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:21.517967] apply_controller > Done. Stopping robot. Value of run [8.829089]\n",
      "[2018-05-12 15:54:21.520131] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:21.521834] apply_controller > Starting run\n",
      "[2018-05-12 15:54:21.523440] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:21.840138] apply_controller > Done. Stopping robot. Value of run [7.615602]\n",
      "[2018-05-12 15:54:21.841544] Cartpole_src > Stopping robot\n",
      "[2018-05-12 15:54:21.843113] apply_controller > Starting run\n",
      "[2018-05-12 15:54:21.844796] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-12 15:54:22.245325] apply_controller > Done. Stopping robot. Value of run [8.148943]\n",
      "[2018-05-12 15:54:22.246810] Cartpole_src > Stopping robot\n"
     ]
    }
   ],
   "source": [
    "# collect example trajectory data on sim environment\n",
    "source_pol = init_pol(params, pol_path)[0]\n",
    "if exp_path is not None:\n",
    "    source_exp = ExperienceDataset(filename=exp_path)\n",
    "else:\n",
    "    source_exp = ExperienceDataset()\n",
    "\n",
    "# init expert trajectory variables\n",
    "n_episodes = source_exp.n_episodes()\n",
    "if n_demo > n_episodes:\n",
    "    # function to execute before applying policy\n",
    "    def gTrig(state):\n",
    "        return utils.gTrig_np(state, angle_dims).flatten()\n",
    "\n",
    "    # function to execute after applying policy\n",
    "    def step_cb(state, action, cost, info, env=None):\n",
    "        env.render()\n",
    "\n",
    "    # apply controller\n",
    "    callback = partial(step_cb, env=source_env)\n",
    "\n",
    "    for i in range(n_demo-n_episodes):\n",
    "        ret = apply_controller(source_env, source_pol, H+1, gTrig, callback)\n",
    "        source_exp.append_episode(*ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source trajectory\n",
    "trajs = np.array(source_exp.states)\n",
    "tr_shape = trajs.shape\n",
    "\n",
    "trajs = utils.gTrig_np(trajs.reshape((tr_shape[0]*tr_shape[1], tr_shape[2])), angle_dims)\n",
    "trajectories = trajs.reshape((tr_shape[0], tr_shape[1], trajs.shape[-1])).astype(theano.config.floatX)\n",
    "\n",
    "traj_mean = trajectories.mean(0)\n",
    "trajc = trajectories[:, :, :, None]\n",
    "trajmm = traj_mean[:, :, None]\n",
    "N = (trajc.shape[0]-1.0)\n",
    "traj_cov = (trajc*trajc.swapaxes(2,3)).sum(0)/N\n",
    "traj_cov -= (trajmm*trajmm.swapaxes(1,2))\n",
    "\n",
    "trajs = theano.shared(trajectories, name='trajs')\n",
    "target_mean = theano.shared(traj_mean, name='target_mean')\n",
    "target_cov = theano.shared(traj_cov, name='target_cov')\n",
    "\n",
    "# define cost as sum of task cost and deviation form expert demonstration\n",
    "def task_plus_il_cost(t, mx, Sx, weights=[1, 1e-4], loss_type=utils.ImitationLossType.KLQP):\n",
    "    '''\n",
    "        The IL term will penalize rollout predictive distributions that \n",
    "        are too different from the target distribution\n",
    "    '''\n",
    "    mxa, Sxa = convert_angle_dimensions(mx, Sx, angle_dims)\n",
    "    mt, St = target_mean[t], target_cov[t]\n",
    "\n",
    "    if loss_type == utils.ImitationLossType.KLQP:\n",
    "        imitation_loss = gaussian_kl_loss(mxa, Sxa, mt, St)\n",
    "    elif loss_type == utils.ImitationLossType.KLPQ:\n",
    "        imitation_loss = gaussian_kl_loss(mt, St, mxa, Sxa)\n",
    "    elif loss_type == utils.ImitationLossType.KLSYM:\n",
    "        imitation_loss = 0.5*(gaussian_kl_loss(mt, St, mxa, Sxa) + gaussian_kl_loss(mxa, Sxa, mt, St))\n",
    "    return weights[0]*task_cost(mx, Sx)[0] + weights[1]*imitation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_shared = [trajs, target_mean, target_cov]\n",
    "rollout_fn = None\n",
    "target_exp = None\n",
    "fig = None\n",
    "axarr = None\n",
    "\n",
    "\n",
    "def learning_iteration_cb(exp, dyn, pol, polopt, params, rollout_fn_in):\n",
    "    global rollout_fn\n",
    "    global target_exp\n",
    "    i = exp.curr_episode\n",
    "    # setup output directory\n",
    "    exp.save(None, 'experience_%d' % (i))\n",
    "    pol.save(None, 'policy_%d' % (i))\n",
    "    dyn.save(None, 'dynamics_%d' % (i))\n",
    "    with open(os.path.join(utils.get_output_dir(), 'config.dill'), 'wb') as f:\n",
    "        dill.dump(params, f)\n",
    "    rollout_fn = rollout_fn_in\n",
    "    target_exp = exp\n",
    "\n",
    "counter = 0\n",
    "def minimize_cb(*args, **kwargs):\n",
    "    global fig\n",
    "    global axarr\n",
    "    global counter\n",
    "    if counter % 500 == 0:\n",
    "        p0 = params['state0_dist']\n",
    "        m0, S0 = p0.mean, p0.cov\n",
    "        fig, axarr = plot_rollout(rollout_fn, source_exp, m0, S0, H, 1.0,\n",
    "                                  fig=fig, axarr=axarr, n_exp=n_demo, name='Rollout during optimization')\n",
    "        plt.waitforbuttonpress(0.01)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['target'] = copy.deepcopy(params['plant'])\n",
    "params['target']['pole_mass'] *= 2\n",
    "params['target']['name'] = 'target_2x_mass'\n",
    "target_env = cartpole.Cartpole(**params['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['target'] = copy.deepcopy(params['plant'])\n",
    "params['target']['pole_length'] *= 2\n",
    "params['target']['name'] = 'target_2x_length'\n",
    "target_env = cartpole.Cartpole(**params['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 15:54:22.429103] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 15:54:22.451849] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 15:54:22.480726] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 15:54:22.493210] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 15:54:22.499046] Experience > Initialising new experience dataset\n",
      "[2018-05-12 15:54:22.500763] Executing uniformly-random controls\n",
      "[2018-05-12 15:54:22.502218] apply_controller > Starting run\n",
      "[2018-05-12 15:54:22.503510] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:54:22.667749] apply_controller > Done. Stopping robot. Value of run [29.996679]\n",
      "[2018-05-12 15:54:22.669485] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:54:22.670841] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:54:22.673648] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 15:54:22.675294] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "[2018-05-12 15:54:22.707433] target_dyn > Initialising loss function\n",
      "[2018-05-12 15:54:22.864353] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 15:54:23.145299] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 15:54:23.146511] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 15:54:23.216382] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 15:54:24.130883] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 15:54:30.560563] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:54:30.570183] target_dyn_opt > Initial loss [6680.729931462471]\n",
      "\u001b[2K[2018-05-12 15:54:40.093248] target_dyn_opt > Curr loss: 6.614115E+01 [1582: 5.576927E+01], n_evals: 1999, Avg. time per updt: 0.003255\n",
      "[2018-05-12 15:54:40.100234] target_dyn_opt > Done training. New loss [61.648689] iter: [2000]\n",
      "[2018-05-12 15:54:40.329352] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:54:40.365362] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>})\n",
      "[2018-05-12 15:54:40.526931] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 15:54:40.528146] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 15:54:40.618289] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 15:54:40.619538] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 15:54:41.087795] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 15:54:41.089035] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 15:54:41.181472] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 15:54:41.183264] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 15:54:46.790113] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 15:54:47.682534] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 15:54:47.692359] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 15:54:47.722888] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 15:54:51.311553] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 15:55:07.834267] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_0.zip\n",
      "[2018-05-12 15:55:07.903521] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_0.zip\n",
      "[2018-05-12 15:55:07.982366] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_0.zip\n",
      "[2018-05-12 15:55:08.090997] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 15:55:08.092789] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 15:55:08.097873] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:55:08.239651] SGDOptimizer > Initial loss [0.996991753578186]\n",
      "\u001b[2K[2018-05-12 15:56:33.102718] SGDOptimizer > Curr loss: 8.589609E-01, n_evals: 999, Avg. time per updt: 0.083514\n",
      "[2018-05-12 15:56:33.129142] SGDOptimizer > Done training. New loss [0.910608] iter: [999]\n",
      "[2018-05-12 15:56:33.131208] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 15:56:33.210818] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 15:56:33.364007] NNPolicy > Done compiling\n",
      "[2018-05-12 15:56:33.365593] apply_controller > Starting run\n",
      "[2018-05-12 15:56:33.368855] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:56:33.577236] apply_controller > Done. Stopping robot. Value of run [29.406206]\n",
      "[2018-05-12 15:56:33.578505] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:56:33.579738] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:56:33.582315] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 15:56:33.583698] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 15:56:33.598963] target_dyn_opt > Initial loss [196.87817812073425]\n",
      "\u001b[2K[2018-05-12 15:56:46.483913] target_dyn_opt > Curr loss: 2.487258E+01 [1720: 2.168714E+01], n_evals: 1999, Avg. time per updt: 0.004921\n",
      "[2018-05-12 15:56:46.492488] target_dyn_opt > Done training. New loss [23.101507] iter: [2000]\n",
      "[2018-05-12 15:56:46.495014] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:56:46.496376] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_1.zip\n",
      "[2018-05-12 15:56:46.613623] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_1.zip\n",
      "[2018-05-12 15:56:46.689021] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_1.zip\n",
      "[2018-05-12 15:56:48.088281] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 15:56:48.093368] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:56:48.199887] SGDOptimizer > Initial loss [0.9666119813919067]\n",
      "\u001b[2K[2018-05-12 15:58:12.793353] SGDOptimizer > Curr loss: 8.108242E-01, n_evals: 999, Avg. time per updt: 0.083266\n",
      "[2018-05-12 15:58:12.821772] SGDOptimizer > Done training. New loss [0.816964] iter: [999]\n",
      "[2018-05-12 15:58:12.823729] apply_controller > Starting run\n",
      "[2018-05-12 15:58:12.824903] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:58:13.052633] apply_controller > Done. Stopping robot. Value of run [26.188398]\n",
      "[2018-05-12 15:58:13.053845] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:58:13.055404] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:58:13.057702] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 15:58:13.059097] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:58:13.071762] target_dyn_opt > Initial loss [28.16285134718657]\n",
      "\u001b[2K[2018-05-12 15:58:29.390715] target_dyn_opt > Curr loss: 1.268149E+01 [1843: 1.088499E+01], n_evals: 1999, Avg. time per updt: 0.006636\n",
      "[2018-05-12 15:58:29.404673] target_dyn_opt > Done training. New loss [11.506210] iter: [2000]\n",
      "[2018-05-12 15:58:29.407450] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:58:29.408803] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_2.zip\n",
      "[2018-05-12 15:58:29.567255] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_2.zip\n",
      "[2018-05-12 15:58:29.641351] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_2.zip\n",
      "[2018-05-12 15:58:31.310925] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 15:58:31.316038] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:58:31.422628] SGDOptimizer > Initial loss [0.9062098264694214]\n",
      "\u001b[2K[2018-05-12 15:59:57.894523] SGDOptimizer > Curr loss: 8.198906E-01, n_evals: 999, Avg. time per updt: 0.085126\n",
      "[2018-05-12 15:59:57.917962] SGDOptimizer > Done training. New loss [0.816083] iter: [999]\n",
      "[2018-05-12 15:59:57.920037] apply_controller > Starting run\n",
      "[2018-05-12 15:59:57.921298] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:59:58.101218] apply_controller > Done. Stopping robot. Value of run [25.714014]\n",
      "[2018-05-12 15:59:58.102815] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:59:58.104101] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:59:58.107067] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 15:59:58.108327] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:59:58.123630] target_dyn_opt > Initial loss [14.526789581685142]\n",
      "\u001b[2K[2018-05-12 16:00:15.858973] target_dyn_opt > Curr loss: 6.003786E+00 [1897: 5.110294E+00], n_evals: 1999, Avg. time per updt: 0.007335\n",
      "[2018-05-12 16:00:15.871927] target_dyn_opt > Done training. New loss [5.697748] iter: [2000]\n",
      "[2018-05-12 16:00:15.874535] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:00:15.875918] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_3.zip\n",
      "[2018-05-12 16:00:16.081283] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_3.zip\n",
      "[2018-05-12 16:00:16.156858] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_3.zip\n",
      "[2018-05-12 16:00:17.844487] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 16:00:17.850016] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:00:17.960042] SGDOptimizer > Initial loss [0.9002598524093628]\n",
      "\u001b[2K[2018-05-12 16:01:46.136104] SGDOptimizer > Curr loss: 8.457360E-01, n_evals: 999, Avg. time per updt: 0.086852\n",
      "[2018-05-12 16:01:46.158964] SGDOptimizer > Done training. New loss [0.845662] iter: [999]\n",
      "[2018-05-12 16:01:46.160661] apply_controller > Starting run\n",
      "[2018-05-12 16:01:46.161979] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:01:46.377873] apply_controller > Done. Stopping robot. Value of run [24.415106]\n",
      "[2018-05-12 16:01:46.380399] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:01:46.381787] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:01:46.384781] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 16:01:46.386300] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:01:46.403138] target_dyn_opt > Initial loss [18.001908555011873]\n",
      "\u001b[2K[2018-05-12 16:02:04.619841] target_dyn_opt > Curr loss: 2.175640E+00 [1945: 1.684306E+00], n_evals: 1999, Avg. time per updt: 0.007544\n",
      "[2018-05-12 16:02:04.633090] target_dyn_opt > Done training. New loss [2.177034] iter: [2000]\n",
      "[2018-05-12 16:02:04.635776] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:02:04.637179] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_4.zip\n",
      "[2018-05-12 16:02:04.909643] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_4.zip\n",
      "[2018-05-12 16:02:04.984933] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_4.zip\n",
      "[2018-05-12 16:02:06.699086] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 16:02:06.704070] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:02:06.816811] SGDOptimizer > Initial loss [0.9224860668182373]\n",
      "\u001b[2K[2018-05-12 16:03:33.813123] SGDOptimizer > Curr loss: 7.669514E-01, n_evals: 999, Avg. time per updt: 0.085638\n",
      "[2018-05-12 16:03:33.834641] SGDOptimizer > Done training. New loss [0.738872] iter: [999]\n",
      "[2018-05-12 16:03:33.836273] apply_controller > Starting run\n",
      "[2018-05-12 16:03:33.837595] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:03:34.024990] apply_controller > Done. Stopping robot. Value of run [24.237082]\n",
      "[2018-05-12 16:03:34.026519] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:03:34.027877] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:03:34.030151] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 16:03:34.031730] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:03:34.045748] target_dyn_opt > Initial loss [2.850281277623285]\n",
      "\u001b[2K[2018-05-12 16:03:51.892236] target_dyn_opt > Curr loss: -2.799526E-01 [1972: -7.647247E-01], n_evals: 1999, Avg. time per updt: 0.007366\n",
      "[2018-05-12 16:03:51.904489] target_dyn_opt > Done training. New loss [-0.221255] iter: [2000]\n",
      "[2018-05-12 16:03:51.907271] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:03:51.908596] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_5.zip\n",
      "[2018-05-12 16:03:52.206777] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_5.zip\n",
      "[2018-05-12 16:03:52.283388] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_5.zip\n",
      "[2018-05-12 16:03:55.292070] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 16:03:55.297525] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:03:55.415911] SGDOptimizer > Initial loss [0.8053287267684937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 16:05:21.333019] SGDOptimizer > Curr loss: 6.946740E-01, n_evals: 999, Avg. time per updt: 0.084595\n",
      "[2018-05-12 16:05:21.356317] SGDOptimizer > Done training. New loss [0.714920] iter: [999]\n",
      "[2018-05-12 16:05:21.358078] apply_controller > Starting run\n",
      "[2018-05-12 16:05:21.359390] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:05:21.582548] apply_controller > Done. Stopping robot. Value of run [22.796093]\n",
      "[2018-05-12 16:05:21.584227] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:05:21.585468] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:05:21.588266] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 16:05:21.589721] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:05:21.603583] target_dyn_opt > Initial loss [3.0791926721473377]\n",
      "\u001b[2K[2018-05-12 16:05:39.782419] target_dyn_opt > Curr loss: -2.215102E+00 [1806: -2.733445E+00], n_evals: 1999, Avg. time per updt: 0.007560\n",
      "[2018-05-12 16:05:39.795991] target_dyn_opt > Done training. New loss [-2.365056] iter: [2000]\n",
      "[2018-05-12 16:05:39.799409] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:05:39.800821] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_6.zip\n",
      "[2018-05-12 16:05:40.137386] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_6.zip\n",
      "[2018-05-12 16:05:40.215434] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_6.zip\n",
      "[2018-05-12 16:05:41.900141] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 16:05:41.905422] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:05:42.014940] SGDOptimizer > Initial loss [0.9103012681007385]\n",
      "\u001b[2K[2018-05-12 16:07:07.219015] SGDOptimizer > Curr loss: 5.426455E-01, n_evals: 999, Avg. time per updt: 0.083865\n",
      "[2018-05-12 16:07:07.242964] SGDOptimizer > Done training. New loss [0.527927] iter: [999]\n",
      "[2018-05-12 16:07:07.244924] apply_controller > Starting run\n",
      "[2018-05-12 16:07:07.246274] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:07:07.467814] apply_controller > Done. Stopping robot. Value of run [14.235567]\n",
      "[2018-05-12 16:07:07.469228] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:07:07.470482] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:07:07.473732] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 16:07:07.475050] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:07:07.494418] target_dyn_opt > Initial loss [0.8324918304590092]\n",
      "\u001b[2K[2018-05-12 16:07:25.766572] target_dyn_opt > Curr loss: -3.936918E+00 [1981: -4.171124E+00], n_evals: 1999, Avg. time per updt: 0.007611\n",
      "[2018-05-12 16:07:25.779595] target_dyn_opt > Done training. New loss [-3.571067] iter: [2000]\n",
      "[2018-05-12 16:07:25.782400] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:07:25.783955] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_7.zip\n",
      "[2018-05-12 16:07:26.167292] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_7.zip\n",
      "[2018-05-12 16:07:26.246468] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_7.zip\n",
      "[2018-05-12 16:07:27.939763] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 16:07:27.945381] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:07:28.058361] SGDOptimizer > Initial loss [0.6074377298355103]\n",
      "\u001b[2K[2018-05-12 16:08:53.009261] SGDOptimizer > Curr loss: 5.067383E-01, n_evals: 999, Avg. time per updt: 0.083632\n",
      "[2018-05-12 16:08:53.032318] SGDOptimizer > Done training. New loss [0.536229] iter: [999]\n",
      "[2018-05-12 16:08:53.033999] apply_controller > Starting run\n",
      "[2018-05-12 16:08:53.035326] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:08:53.224607] apply_controller > Done. Stopping robot. Value of run [17.202480]\n",
      "[2018-05-12 16:08:53.226085] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:08:53.227562] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:08:53.230699] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 16:08:53.231977] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:08:53.247516] target_dyn_opt > Initial loss [-2.979046790289668]\n",
      "\u001b[2K[2018-05-12 16:09:11.641490] target_dyn_opt > Curr loss: -4.637620E+00 [1668: -5.299921E+00], n_evals: 1999, Avg. time per updt: 0.007666\n",
      "[2018-05-12 16:09:11.656955] target_dyn_opt > Done training. New loss [-4.776088] iter: [2000]\n",
      "[2018-05-12 16:09:11.659604] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:09:11.660937] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_8.zip\n",
      "[2018-05-12 16:09:12.110165] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_8.zip\n",
      "[2018-05-12 16:09:12.189705] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_8.zip\n",
      "[2018-05-12 16:09:13.892991] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 16:09:13.898110] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:09:14.019104] SGDOptimizer > Initial loss [0.7862829566001892]\n",
      "\u001b[2K[2018-05-12 16:10:39.307868] SGDOptimizer > Curr loss: 5.205716E-01, n_evals: 999, Avg. time per updt: 0.083955\n",
      "[2018-05-12 16:10:39.330913] SGDOptimizer > Done training. New loss [0.494929] iter: [999]\n",
      "[2018-05-12 16:10:39.332585] apply_controller > Starting run\n",
      "[2018-05-12 16:10:39.334136] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:10:39.515652] apply_controller > Done. Stopping robot. Value of run [14.324215]\n",
      "[2018-05-12 16:10:39.517031] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:10:39.518409] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:10:39.521550] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 16:10:39.523399] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:10:39.537319] target_dyn_opt > Initial loss [-4.3257115140878435]\n",
      "\u001b[2K[2018-05-12 16:10:57.611454] target_dyn_opt > Curr loss: -5.389552E+00 [1952: -6.511031E+00], n_evals: 1999, Avg. time per updt: 0.007496\n",
      "[2018-05-12 16:10:57.625496] target_dyn_opt > Done training. New loss [-5.978143] iter: [2000]\n",
      "[2018-05-12 16:10:57.628410] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:10:57.630124] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_9.zip\n",
      "[2018-05-12 16:10:58.121366] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_9.zip\n",
      "[2018-05-12 16:10:58.204587] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_9.zip\n",
      "[2018-05-12 16:10:59.959787] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 16:10:59.964743] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:11:00.087675] SGDOptimizer > Initial loss [0.8145965933799744]\n",
      "\u001b[2K[2018-05-12 16:12:27.113606] SGDOptimizer > Curr loss: 5.435282E-01, n_evals: 999, Avg. time per updt: 0.085674\n",
      "[2018-05-12 16:12:27.140677] SGDOptimizer > Done training. New loss [0.552734] iter: [999]\n",
      "[2018-05-12 16:12:27.142731] apply_controller > Starting run\n",
      "[2018-05-12 16:12:27.143950] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:12:27.358839] apply_controller > Done. Stopping robot. Value of run [15.382326]\n",
      "[2018-05-12 16:12:27.360055] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:12:27.361390] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:12:27.364712] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 16:12:27.366158] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:12:27.383377] target_dyn_opt > Initial loss [-5.310978428726333]\n",
      "\u001b[2K[2018-05-12 16:12:45.447432] target_dyn_opt > Curr loss: -6.583827E+00 [1887: -7.109356E+00], n_evals: 1999, Avg. time per updt: 0.007503\n",
      "[2018-05-12 16:12:45.462921] target_dyn_opt > Done training. New loss [-6.602919] iter: [2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:12:45.465630] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:12:45.467167] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_10.zip\n",
      "[2018-05-12 16:12:46.000982] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_10.zip\n",
      "[2018-05-12 16:12:46.085452] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_10.zip\n",
      "[2018-05-12 16:12:47.950014] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 16:12:47.955059] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:12:48.087515] SGDOptimizer > Initial loss [0.5894615650177002]\n",
      "\u001b[2K[2018-05-12 16:14:14.796930] SGDOptimizer > Curr loss: 4.647201E-01, n_evals: 999, Avg. time per updt: 0.085369\n",
      "[2018-05-12 16:14:14.820512] SGDOptimizer > Done training. New loss [0.461924] iter: [999]\n",
      "[2018-05-12 16:14:14.822207] apply_controller > Starting run\n",
      "[2018-05-12 16:14:14.823692] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:14:15.009753] apply_controller > Done. Stopping robot. Value of run [15.191338]\n",
      "[2018-05-12 16:14:15.011363] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:14:15.012415] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:14:15.015647] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 16:14:15.017055] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:14:15.033146] target_dyn_opt > Initial loss [-6.28331089201758]\n",
      "\u001b[2K[2018-05-12 16:14:33.115095] target_dyn_opt > Curr loss: -7.046298E+00 [1775: -7.853820E+00], n_evals: 1999, Avg. time per updt: 0.007523\n",
      "[2018-05-12 16:14:33.130554] target_dyn_opt > Done training. New loss [-7.340509] iter: [2000]\n",
      "[2018-05-12 16:14:33.134117] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:14:33.135909] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_11.zip\n",
      "[2018-05-12 16:14:33.794483] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_11.zip\n",
      "[2018-05-12 16:14:33.880834] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_11.zip\n",
      "[2018-05-12 16:14:35.708806] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 16:14:35.714188] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:14:35.835405] SGDOptimizer > Initial loss [0.583663284778595]\n",
      "\u001b[2K[2018-05-12 16:16:05.106724] SGDOptimizer > Curr loss: 4.449430E-01, n_evals: 999, Avg. time per updt: 0.087933\n",
      "[2018-05-12 16:16:05.131215] SGDOptimizer > Done training. New loss [0.446292] iter: [999]\n",
      "[2018-05-12 16:16:05.132886] apply_controller > Starting run\n",
      "[2018-05-12 16:16:05.134082] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:16:05.320866] apply_controller > Done. Stopping robot. Value of run [13.530364]\n",
      "[2018-05-12 16:16:05.322491] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:16:05.323890] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:16:05.327222] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 16:16:05.328704] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:16:05.344919] target_dyn_opt > Initial loss [-6.539858841018589]\n",
      "\u001b[2K[2018-05-12 16:16:23.641966] target_dyn_opt > Curr loss: -7.957913E+00 [1788: -8.391265E+00], n_evals: 1999, Avg. time per updt: 0.007617\n",
      "[2018-05-12 16:16:23.655599] target_dyn_opt > Done training. New loss [-7.957363] iter: [2000]\n",
      "[2018-05-12 16:16:23.658238] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:16:23.659568] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_12.zip\n",
      "[2018-05-12 16:16:24.280140] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_12.zip\n",
      "[2018-05-12 16:16:24.360777] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_12.zip\n",
      "[2018-05-12 16:16:26.174709] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 16:16:26.180167] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:16:26.299221] SGDOptimizer > Initial loss [0.7275120615959167]\n",
      "\u001b[2K[2018-05-12 16:17:52.492495] SGDOptimizer > Curr loss: 4.513001E-01, n_evals: 999, Avg. time per updt: 0.084861\n",
      "[2018-05-12 16:17:52.515102] SGDOptimizer > Done training. New loss [0.451197] iter: [999]\n",
      "[2018-05-12 16:17:52.517209] apply_controller > Starting run\n",
      "[2018-05-12 16:17:52.518593] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:17:52.703460] apply_controller > Done. Stopping robot. Value of run [12.671826]\n",
      "[2018-05-12 16:17:52.704789] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:17:52.706374] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:17:52.710454] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 16:17:52.711713] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:17:52.725990] target_dyn_opt > Initial loss [-6.913726246470741]\n",
      "\u001b[2K[2018-05-12 16:18:10.717859] target_dyn_opt > Curr loss: -8.072589E+00 [1926: -8.970943E+00], n_evals: 1999, Avg. time per updt: 0.007490\n",
      "[2018-05-12 16:18:10.733067] target_dyn_opt > Done training. New loss [-8.154395] iter: [2000]\n",
      "[2018-05-12 16:18:10.735925] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:18:10.737361] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_13.zip\n",
      "[2018-05-12 16:18:11.385973] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_13.zip\n",
      "[2018-05-12 16:18:11.465130] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_13.zip\n",
      "[2018-05-12 16:18:13.191879] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 16:18:13.197284] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:18:13.313797] SGDOptimizer > Initial loss [0.8377482295036316]\n",
      "\u001b[2K[2018-05-12 16:19:40.451774] SGDOptimizer > Curr loss: 4.433659E-01, n_evals: 999, Avg. time per updt: 0.085809\n",
      "[2018-05-12 16:19:40.483077] SGDOptimizer > Done training. New loss [0.549982] iter: [999]\n",
      "[2018-05-12 16:19:40.485161] apply_controller > Starting run\n",
      "[2018-05-12 16:19:40.486624] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:19:40.662366] apply_controller > Done. Stopping robot. Value of run [11.986037]\n",
      "[2018-05-12 16:19:40.663700] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:19:40.664683] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:19:40.668538] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 16:19:40.670198] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:19:40.684557] target_dyn_opt > Initial loss [-8.018091110182905]\n",
      "\u001b[2K[2018-05-12 16:20:00.680799] target_dyn_opt > Curr loss: -8.750321E+00 [1814: -9.396071E+00], n_evals: 1999, Avg. time per updt: 0.008462\n",
      "[2018-05-12 16:20:00.704877] target_dyn_opt > Done training. New loss [-8.804405] iter: [2000]\n",
      "[2018-05-12 16:20:00.710294] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:20:00.711811] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_14.zip\n",
      "[2018-05-12 16:20:01.662609] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_14.zip\n",
      "[2018-05-12 16:20:01.753061] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_14.zip\n",
      "[2018-05-12 16:20:03.645135] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 16:20:03.650119] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:20:03.762546] SGDOptimizer > Initial loss [0.7987380623817444]\n",
      "\u001b[2K[2018-05-12 16:21:33.162697] SGDOptimizer > Curr loss: 4.346551E-01, n_evals: 999, Avg. time per updt: 0.088072\n",
      "[2018-05-12 16:21:33.191266] SGDOptimizer > Done training. New loss [0.432401] iter: [999]\n",
      "[2018-05-12 16:21:33.193352] apply_controller > Starting run\n",
      "[2018-05-12 16:21:33.194610] apply_controller > Running for 3.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:21:33.370308] apply_controller > Done. Stopping robot. Value of run [23.538347]\n",
      "[2018-05-12 16:21:33.371786] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:21:33.373087] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:21:33.376251] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 16:21:33.377630] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:21:33.392611] target_dyn_opt > Initial loss [-6.725470505590582]\n",
      "\u001b[2K[2018-05-12 16:21:55.476629] target_dyn_opt > Curr loss: -9.423353E+00 [1672: -9.679023E+00], n_evals: 1999, Avg. time per updt: 0.009358\n",
      "[2018-05-12 16:21:55.489449] target_dyn_opt > Done training. New loss [-9.322177] iter: [2000]\n",
      "[2018-05-12 16:21:55.491991] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:21:55.493929] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_15.zip\n",
      "[2018-05-12 16:21:56.224672] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_15.zip\n",
      "[2018-05-12 16:21:56.302211] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_15.zip\n",
      "[2018-05-12 16:21:58.010822] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 16:21:58.016491] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:21:58.136582] SGDOptimizer > Initial loss [0.4488633871078491]\n",
      "\u001b[2K[2018-05-12 16:23:29.074788] SGDOptimizer > Curr loss: 4.151183E-01, n_evals: 999, Avg. time per updt: 0.089571\n",
      "[2018-05-12 16:23:29.105559] SGDOptimizer > Done training. New loss [0.414394] iter: [999]\n",
      "[2018-05-12 16:23:29.107324] apply_controller > Starting run\n",
      "[2018-05-12 16:23:29.108797] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:23:29.291502] apply_controller > Done. Stopping robot. Value of run [21.323595]\n",
      "[2018-05-12 16:23:29.292883] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:23:29.294155] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:23:29.297612] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 16:23:29.298924] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:23:29.315539] target_dyn_opt > Initial loss [-6.938327069245052]\n",
      "\u001b[2K[2018-05-12 16:23:47.380066] target_dyn_opt > Curr loss: -9.664986E+00 [1782: -1.002174E+01], n_evals: 1999, Avg. time per updt: 0.007522\n",
      "[2018-05-12 16:23:47.393293] target_dyn_opt > Done training. New loss [-9.364713] iter: [2000]\n",
      "[2018-05-12 16:23:47.396232] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:23:47.397719] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_16.zip\n",
      "[2018-05-12 16:23:48.175456] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_16.zip\n",
      "[2018-05-12 16:23:48.255600] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_16.zip\n",
      "[2018-05-12 16:23:49.990658] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 16:23:49.996114] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:23:50.120891] SGDOptimizer > Initial loss [0.6435902118682861]\n",
      "\u001b[2K[2018-05-12 16:25:19.461742] SGDOptimizer > Curr loss: 4.130366E-01, n_evals: 999, Avg. time per updt: 0.087989\n",
      "[2018-05-12 16:25:19.488698] SGDOptimizer > Done training. New loss [0.413840] iter: [999]\n",
      "[2018-05-12 16:25:19.490278] apply_controller > Starting run\n",
      "[2018-05-12 16:25:19.491561] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:25:19.672965] apply_controller > Done. Stopping robot. Value of run [13.039907]\n",
      "[2018-05-12 16:25:19.674663] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:25:19.675970] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:25:19.681322] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 16:25:19.682859] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:25:19.699565] target_dyn_opt > Initial loss [-8.446266184621615]\n",
      "\u001b[2K[2018-05-12 16:25:38.114046] target_dyn_opt > Curr loss: -9.881607E+00 [1152: -1.036036E+01], n_evals: 1999, Avg. time per updt: 0.007689\n",
      "[2018-05-12 16:25:38.126975] target_dyn_opt > Done training. New loss [-9.942652] iter: [2000]\n",
      "[2018-05-12 16:25:38.129763] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:25:38.131692] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_17.zip\n",
      "[2018-05-12 16:25:38.957410] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_17.zip\n",
      "[2018-05-12 16:25:39.039252] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_17.zip\n",
      "[2018-05-12 16:25:40.777230] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 16:25:40.782403] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:25:40.900957] SGDOptimizer > Initial loss [0.6621149778366089]\n",
      "\u001b[2K[2018-05-12 16:27:10.045658] SGDOptimizer > Curr loss: 4.123432E-01, n_evals: 999, Avg. time per updt: 0.087797\n",
      "[2018-05-12 16:27:10.076768] SGDOptimizer > Done training. New loss [0.914717] iter: [999]\n",
      "[2018-05-12 16:27:10.078579] apply_controller > Starting run\n",
      "[2018-05-12 16:27:10.079758] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:27:10.328471] apply_controller > Done. Stopping robot. Value of run [11.824644]\n",
      "[2018-05-12 16:27:10.329711] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:27:10.331191] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:27:10.335140] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 16:27:10.336946] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:27:10.352619] target_dyn_opt > Initial loss [-8.886890855004264]\n",
      "\u001b[2K[2018-05-12 16:27:28.738145] target_dyn_opt > Curr loss: -1.009981E+01 [1738: -1.075862E+01], n_evals: 1999, Avg. time per updt: 0.007683\n",
      "[2018-05-12 16:27:28.751867] target_dyn_opt > Done training. New loss [-10.416551] iter: [2000]\n",
      "[2018-05-12 16:27:28.754625] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:27:28.756119] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_18.zip\n",
      "[2018-05-12 16:27:29.644807] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_18.zip\n",
      "[2018-05-12 16:27:29.728197] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_18.zip\n",
      "[2018-05-12 16:27:31.479889] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 16:27:31.484940] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:27:31.598514] SGDOptimizer > Initial loss [0.9239051342010498]\n",
      "\u001b[2K[2018-05-12 16:29:02.011055] SGDOptimizer > Curr loss: 4.042665E-01, n_evals: 999, Avg. time per updt: 0.089089\n",
      "[2018-05-12 16:29:02.039721] SGDOptimizer > Done training. New loss [0.404029] iter: [999]\n",
      "[2018-05-12 16:29:02.041820] apply_controller > Starting run\n",
      "[2018-05-12 16:29:02.043096] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:29:02.244211] apply_controller > Done. Stopping robot. Value of run [12.204680]\n",
      "[2018-05-12 16:29:02.245809] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:29:02.246499] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:29:02.250088] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 16:29:02.251363] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:29:02.266598] target_dyn_opt > Initial loss [-9.130418600964134]\n",
      "\u001b[2K[2018-05-12 16:29:20.897445] target_dyn_opt > Curr loss: -1.045332E+01 [1767: -1.103362E+01], n_evals: 1999, Avg. time per updt: 0.007748\n",
      "[2018-05-12 16:29:20.910325] target_dyn_opt > Done training. New loss [-10.775248] iter: [2000]\n",
      "[2018-05-12 16:29:20.912863] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:29:20.914260] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_19.zip\n",
      "[2018-05-12 16:29:21.833713] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_19.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:29:21.915939] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_19.zip\n",
      "[2018-05-12 16:29:23.690466] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 16:29:23.695736] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:29:23.814728] SGDOptimizer > Initial loss [0.6612314581871033]\n",
      "\u001b[2K[2018-05-12 16:30:53.828263] SGDOptimizer > Curr loss: 4.069581E-01, n_evals: 999, Avg. time per updt: 0.088693\n",
      "[2018-05-12 16:30:53.853326] SGDOptimizer > Done training. New loss [0.403314] iter: [999]\n",
      "[2018-05-12 16:30:53.855186] apply_controller > Starting run\n",
      "[2018-05-12 16:30:53.856561] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:30:54.031195] apply_controller > Done. Stopping robot. Value of run [12.916805]\n",
      "[2018-05-12 16:30:54.032896] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:30:54.034244] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:30:54.038782] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 16:30:54.040448] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:30:54.054396] target_dyn_opt > Initial loss [-9.561625983278544]\n",
      "\u001b[2K[2018-05-12 16:31:13.065832] target_dyn_opt > Curr loss: -1.077188E+01 [1186: -1.131254E+01], n_evals: 1999, Avg. time per updt: 0.008006\n",
      "[2018-05-12 16:31:13.081301] target_dyn_opt > Done training. New loss [-10.891156] iter: [2000]\n",
      "[2018-05-12 16:31:13.084055] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:31:13.085870] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_20.zip\n",
      "[2018-05-12 16:31:14.082485] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_20.zip\n",
      "[2018-05-12 16:31:14.165046] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_20.zip\n",
      "[2018-05-12 16:31:15.903644] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 16:31:15.909271] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:31:16.026849] SGDOptimizer > Initial loss [0.5692761540412903]\n",
      "\u001b[2K[2018-05-12 16:32:48.480549] SGDOptimizer > Curr loss: 3.958789E-01, n_evals: 999, Avg. time per updt: 0.091111\n",
      "[2018-05-12 16:32:48.506534] SGDOptimizer > Done training. New loss [0.396587] iter: [999]\n",
      "[2018-05-12 16:32:48.508324] apply_controller > Starting run\n",
      "[2018-05-12 16:32:48.509541] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:32:48.689465] apply_controller > Done. Stopping robot. Value of run [11.502531]\n",
      "[2018-05-12 16:32:48.690716] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:32:48.692243] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:32:48.696182] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 16:32:48.697554] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:32:48.711728] target_dyn_opt > Initial loss [-9.53167524779665]\n",
      "\u001b[2K[2018-05-12 16:33:07.281576] target_dyn_opt > Curr loss: -1.119185E+01 [1237: -1.152511E+01], n_evals: 1999, Avg. time per updt: 0.007720\n",
      "[2018-05-12 16:33:07.296939] target_dyn_opt > Done training. New loss [-10.933733] iter: [2000]\n",
      "[2018-05-12 16:33:07.299542] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:33:07.300992] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_21.zip\n",
      "[2018-05-12 16:33:08.351429] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_21.zip\n",
      "[2018-05-12 16:33:08.438524] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_21.zip\n",
      "[2018-05-12 16:33:10.198286] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 16:33:10.203770] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:33:10.338858] SGDOptimizer > Initial loss [0.7624673247337341]\n",
      "\u001b[2K[2018-05-12 16:34:40.873973] SGDOptimizer > Curr loss: 4.132390E-01, n_evals: 999, Avg. time per updt: 0.089215\n",
      "[2018-05-12 16:34:40.900200] SGDOptimizer > Done training. New loss [0.394949] iter: [999]\n",
      "[2018-05-12 16:34:40.902597] apply_controller > Starting run\n",
      "[2018-05-12 16:34:40.903855] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:34:41.081053] apply_controller > Done. Stopping robot. Value of run [11.550950]\n",
      "[2018-05-12 16:34:41.082396] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:34:41.083914] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:34:41.089262] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 16:34:41.090591] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:34:41.108567] target_dyn_opt > Initial loss [-9.863526495902434]\n",
      "\u001b[2K[2018-05-12 16:34:59.525628] target_dyn_opt > Curr loss: -1.120978E+01 [1781: -1.170081E+01], n_evals: 1999, Avg. time per updt: 0.007653\n",
      "[2018-05-12 16:34:59.539516] target_dyn_opt > Done training. New loss [-11.338870] iter: [2000]\n",
      "[2018-05-12 16:34:59.542293] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:34:59.543716] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_22.zip\n",
      "[2018-05-12 16:35:00.591636] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_22.zip\n",
      "[2018-05-12 16:35:00.671632] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_22.zip\n",
      "[2018-05-12 16:35:02.428546] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 16:35:02.434342] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:35:02.553323] SGDOptimizer > Initial loss [0.8416908979415894]\n",
      "\u001b[2K[2018-05-12 16:36:36.302705] SGDOptimizer > Curr loss: 4.071636E-01, n_evals: 999, Avg. time per updt: 0.092430\n",
      "[2018-05-12 16:36:36.327050] SGDOptimizer > Done training. New loss [0.411444] iter: [999]\n",
      "[2018-05-12 16:36:36.328924] apply_controller > Starting run\n",
      "[2018-05-12 16:36:36.330307] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:36:36.504938] apply_controller > Done. Stopping robot. Value of run [12.853815]\n",
      "[2018-05-12 16:36:36.506156] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:36:36.507693] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:36:36.512044] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 16:36:36.513471] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:36:36.529241] target_dyn_opt > Initial loss [-10.042172753262793]\n",
      "\u001b[2K[2018-05-12 16:36:55.180123] target_dyn_opt > Curr loss: -1.151457E+01 [1732: -1.188537E+01], n_evals: 1999, Avg. time per updt: 0.007783\n",
      "[2018-05-12 16:36:55.193493] target_dyn_opt > Done training. New loss [-11.622420] iter: [2000]\n",
      "[2018-05-12 16:36:55.196611] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:36:55.198137] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_23.zip\n",
      "[2018-05-12 16:36:56.286645] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_23.zip\n",
      "[2018-05-12 16:36:56.367606] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_23.zip\n",
      "[2018-05-12 16:36:58.111703] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 16:36:58.116779] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:36:58.246142] SGDOptimizer > Initial loss [0.7352240681648254]\n",
      "\u001b[2K[2018-05-12 16:38:31.880100] SGDOptimizer > Curr loss: 3.953906E-01, n_evals: 999, Avg. time per updt: 0.092278\n",
      "[2018-05-12 16:38:31.905850] SGDOptimizer > Done training. New loss [0.396038] iter: [999]\n",
      "[2018-05-12 16:38:31.908036] apply_controller > Starting run\n",
      "[2018-05-12 16:38:31.909392] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:38:32.084291] apply_controller > Done. Stopping robot. Value of run [12.880498]\n",
      "[2018-05-12 16:38:32.085618] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:38:32.087253] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:38:32.092390] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:38:32.093783] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:38:32.108932] target_dyn_opt > Initial loss [-10.190879085063933]\n",
      "\u001b[2K[2018-05-12 16:38:50.328376] target_dyn_opt > Curr loss: -1.164239E+01 [1642: -1.206825E+01], n_evals: 1999, Avg. time per updt: 0.007624\n",
      "[2018-05-12 16:38:50.341468] target_dyn_opt > Done training. New loss [-11.568586] iter: [2000]\n",
      "[2018-05-12 16:38:50.344299] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:38:50.350676] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_24.zip\n",
      "[2018-05-12 16:38:51.478282] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_24.zip\n",
      "[2018-05-12 16:38:51.560647] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_24.zip\n",
      "[2018-05-12 16:38:53.318351] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 16:38:53.323465] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:38:53.443430] SGDOptimizer > Initial loss [0.45506635308265686]\n",
      "\u001b[2K[2018-05-12 16:40:29.162289] SGDOptimizer > Curr loss: 3.982220E-01, n_evals: 999, Avg. time per updt: 0.094378\n",
      "[2018-05-12 16:40:29.189837] SGDOptimizer > Done training. New loss [0.398812] iter: [999]\n",
      "[2018-05-12 16:40:29.191888] apply_controller > Starting run\n",
      "[2018-05-12 16:40:29.193101] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:40:29.438184] apply_controller > Done. Stopping robot. Value of run [11.732679]\n",
      "[2018-05-12 16:40:29.439623] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:40:29.440954] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:40:29.446230] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 16:40:29.447654] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:40:29.464503] target_dyn_opt > Initial loss [-10.371524787905678]\n",
      "\u001b[2K[2018-05-12 16:40:47.963747] target_dyn_opt > Curr loss: -1.165584E+01 [1767: -1.226230E+01], n_evals: 1999, Avg. time per updt: 0.007707\n",
      "[2018-05-12 16:40:47.977421] target_dyn_opt > Done training. New loss [-11.693893] iter: [2000]\n",
      "[2018-05-12 16:40:47.980424] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:40:47.982109] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_25.zip\n",
      "[2018-05-12 16:40:49.146539] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_25.zip\n",
      "[2018-05-12 16:40:49.227669] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_25.zip\n",
      "[2018-05-12 16:40:50.975253] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 16:40:50.980434] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:40:51.100720] SGDOptimizer > Initial loss [0.46670040488243103]\n",
      "\u001b[2K[2018-05-12 16:42:33.242386] SGDOptimizer > Curr loss: 3.921075E-01, n_evals: 999, Avg. time per updt: 0.100737\n",
      "[2018-05-12 16:42:33.271248] SGDOptimizer > Done training. New loss [0.391837] iter: [999]\n",
      "[2018-05-12 16:42:33.273098] apply_controller > Starting run\n",
      "[2018-05-12 16:42:33.274415] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:42:33.446961] apply_controller > Done. Stopping robot. Value of run [22.300606]\n",
      "[2018-05-12 16:42:33.448171] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:42:33.449543] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:42:33.453962] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 16:42:33.455627] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:42:33.471766] target_dyn_opt > Initial loss [-8.777333464659037]\n",
      "\u001b[2K[2018-05-12 16:43:03.369361] target_dyn_opt > Curr loss: -1.171248E+01 [1810: -1.249146E+01], n_evals: 1999, Avg. time per updt: 0.012940\n",
      "[2018-05-12 16:43:03.384455] target_dyn_opt > Done training. New loss [-11.919639] iter: [2000]\n",
      "[2018-05-12 16:43:03.387505] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:43:03.389053] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_26.zip\n",
      "[2018-05-12 16:43:04.603780] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_26.zip\n",
      "[2018-05-12 16:43:04.685652] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_26.zip\n",
      "[2018-05-12 16:43:05.951779] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 16:43:05.958356] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:43:06.076696] SGDOptimizer > Initial loss [0.7397891283035278]\n",
      "\u001b[2K[2018-05-12 16:44:48.930810] SGDOptimizer > Curr loss: 3.906748E-01, n_evals: 999, Avg. time per updt: 0.101484\n",
      "[2018-05-12 16:44:48.959331] SGDOptimizer > Done training. New loss [0.390253] iter: [999]\n",
      "[2018-05-12 16:44:48.961153] apply_controller > Starting run\n",
      "[2018-05-12 16:44:48.962588] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:44:49.147462] apply_controller > Done. Stopping robot. Value of run [14.087741]\n",
      "[2018-05-12 16:44:49.148883] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:44:49.150207] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:44:49.155410] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 16:44:49.157385] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:44:49.171756] target_dyn_opt > Initial loss [-10.497926295317452]\n",
      "\u001b[2K[2018-05-12 16:45:13.251996] target_dyn_opt > Curr loss: -1.207246E+01 [1952: -1.262481E+01], n_evals: 1999, Avg. time per updt: 0.010298\n",
      "[2018-05-12 16:45:13.272984] target_dyn_opt > Done training. New loss [-11.953260] iter: [2000]\n",
      "[2018-05-12 16:45:13.276555] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:45:13.278209] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_27.zip\n",
      "[2018-05-12 16:45:14.681443] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_27.zip\n",
      "[2018-05-12 16:45:14.760927] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_27.zip\n",
      "[2018-05-12 16:45:16.507866] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 16:45:16.513124] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:45:16.633139] SGDOptimizer > Initial loss [0.49476340413093567]\n",
      "\u001b[2K[2018-05-12 16:46:53.668497] SGDOptimizer > Curr loss: 3.867943E-01, n_evals: 999, Avg. time per updt: 0.095714\n",
      "[2018-05-12 16:46:53.698689] SGDOptimizer > Done training. New loss [0.388752] iter: [999]\n",
      "[2018-05-12 16:46:53.700671] apply_controller > Starting run\n",
      "[2018-05-12 16:46:53.702005] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:46:53.876183] apply_controller > Done. Stopping robot. Value of run [14.012474]\n",
      "[2018-05-12 16:46:53.877962] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:46:53.879221] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:46:53.884184] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 16:46:53.885493] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:46:53.900322] target_dyn_opt > Initial loss [-10.003723355592644]\n",
      "\u001b[2K[2018-05-12 16:47:13.615353] target_dyn_opt > Curr loss: -1.188452E+01 [687: -1.274567E+01], n_evals: 1999, Avg. time per updt: 0.008329\n",
      "[2018-05-12 16:47:13.631451] target_dyn_opt > Done training. New loss [-12.389182] iter: [2000]\n",
      "[2018-05-12 16:47:13.634322] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:47:13.635766] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_28.zip\n",
      "[2018-05-12 16:47:14.955053] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_28.zip\n",
      "[2018-05-12 16:47:15.040032] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_28.zip\n",
      "[2018-05-12 16:47:16.798291] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 16:47:16.804166] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:47:16.933906] SGDOptimizer > Initial loss [0.817743182182312]\n",
      "\u001b[2K[2018-05-12 16:48:53.999075] SGDOptimizer > Curr loss: 3.867545E-01, n_evals: 999, Avg. time per updt: 0.095736\n",
      "[2018-05-12 16:48:54.031433] SGDOptimizer > Done training. New loss [0.729472] iter: [999]\n",
      "[2018-05-12 16:48:54.033400] apply_controller > Starting run\n",
      "[2018-05-12 16:48:54.034705] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:48:54.222518] apply_controller > Done. Stopping robot. Value of run [12.085616]\n",
      "[2018-05-12 16:48:54.224002] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:48:54.225281] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:48:54.229871] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 16:48:54.231179] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:48:54.248269] target_dyn_opt > Initial loss [-10.706662858525911]\n",
      "\u001b[2K[2018-05-12 16:49:13.598108] target_dyn_opt > Curr loss: -1.233316E+01 [1634: -1.292781E+01], n_evals: 1999, Avg. time per updt: 0.008155\n",
      "[2018-05-12 16:49:13.614031] target_dyn_opt > Done training. New loss [-12.223246] iter: [2000]\n",
      "[2018-05-12 16:49:13.618777] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:49:13.620476] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_29.zip\n",
      "[2018-05-12 16:49:15.034375] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_29.zip\n",
      "[2018-05-12 16:49:15.120803] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_29.zip\n",
      "[2018-05-12 16:49:16.897996] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 16:49:16.903031] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:49:17.024133] SGDOptimizer > Initial loss [0.906024158000946]\n",
      "\u001b[2K[2018-05-12 16:50:57.332738] SGDOptimizer > Curr loss: 4.054628E-01, n_evals: 999, Avg. time per updt: 0.098958\n",
      "[2018-05-12 16:50:57.361663] SGDOptimizer > Done training. New loss [0.404846] iter: [999]\n",
      "[2018-05-12 16:50:57.363576] apply_controller > Starting run\n",
      "[2018-05-12 16:50:57.364826] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:50:57.561478] apply_controller > Done. Stopping robot. Value of run [11.698903]\n",
      "[2018-05-12 16:50:57.565520] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:50:57.568108] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:50:57.573233] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 16:50:57.574509] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:50:57.591777] target_dyn_opt > Initial loss [-11.025957715789787]\n",
      "\u001b[2K[2018-05-12 16:51:16.953181] target_dyn_opt > Curr loss: -1.234534E+01 [1835: -1.312031E+01], n_evals: 1999, Avg. time per updt: 0.008160\n",
      "[2018-05-12 16:51:16.967683] target_dyn_opt > Done training. New loss [-12.505176] iter: [2000]\n",
      "[2018-05-12 16:51:16.970415] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:51:16.971815] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_30.zip\n",
      "[2018-05-12 16:51:18.372492] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_30.zip\n",
      "[2018-05-12 16:51:18.457142] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 1 learn from scratch\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_001_no_transfer')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=False,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, task_cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:51:20.497790] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 16:51:20.534702] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 16:51:20.567159] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 16:51:20.589777] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 16:51:20.637248] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 16:51:20.653636] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 16:51:20.660297] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 16:51:20.675688] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 16:51:20.686612] Experience > Initialising new experience dataset\n",
      "[2018-05-12 16:51:20.688150] Executing initial policy\n",
      "[2018-05-12 16:51:20.689608] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 16:51:20.792805] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 16:51:20.995632] NNPolicy > Done compiling\n",
      "[2018-05-12 16:51:20.997207] apply_controller > Starting run\n",
      "[2018-05-12 16:51:20.998464] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:51:21.272605] apply_controller > Done. Stopping robot. Value of run [29.357145]\n",
      "[2018-05-12 16:51:21.273530] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:51:21.274435] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:51:21.276344] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 16:51:21.277372] target_dyn > Initialising loss function\n",
      "[2018-05-12 16:51:21.447626] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 16:51:21.786553] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 16:51:21.787826] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 16:51:21.855146] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 16:51:22.863898] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 16:51:29.234731] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:51:29.241630] target_dyn_opt > Initial loss [1650.8427462475054]\n",
      "\u001b[2K[2018-05-12 16:51:40.433155] target_dyn_opt > Curr loss: 4.138493E+01 [1923: 4.088250E+01], n_evals: 1999, Avg. time per updt: 0.003958\n",
      "[2018-05-12 16:51:40.441137] target_dyn_opt > Done training. New loss [41.601050] iter: [2000]\n",
      "[2018-05-12 16:51:40.674309] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:51:40.872081] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 16:51:40.873332] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 16:51:40.963419] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 16:51:40.964717] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 16:51:41.457177] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 16:51:41.458406] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 16:51:41.542573] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 16:51:41.543953] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 16:51:44.526701] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 16:51:45.421740] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 16:51:45.432449] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 16:51:45.465154] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 16:51:48.101891] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 16:52:05.007587] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_0.zip\n",
      "[2018-05-12 16:52:05.094177] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_0.zip\n",
      "[2018-05-12 16:52:05.185267] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_0.zip\n",
      "[2018-05-12 16:52:05.330763] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 16:52:05.332210] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 16:52:05.337830] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:52:05.551273] SGDOptimizer > Initial loss [0.9696505069732666]\n",
      "\u001b[2K[2018-05-12 16:54:09.127583] SGDOptimizer > Curr loss: 5.708410E-01, n_evals: 999, Avg. time per updt: 0.122194\n",
      "[2018-05-12 16:54:09.160266] SGDOptimizer > Done training. New loss [0.759420] iter: [999]\n",
      "[2018-05-12 16:54:09.162602] apply_controller > Starting run\n",
      "[2018-05-12 16:54:09.164087] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:54:09.369762] apply_controller > Done. Stopping robot. Value of run [25.767223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:54:09.371597] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:54:09.373750] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:54:09.376520] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 16:54:09.377812] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:54:09.390318] target_dyn_opt > Initial loss [75.53877804659564]\n",
      "\u001b[2K[2018-05-12 16:54:23.136133] target_dyn_opt > Curr loss: 1.404247E+01 [1977: 1.374613E+01], n_evals: 1999, Avg. time per updt: 0.005315\n",
      "[2018-05-12 16:54:23.146592] target_dyn_opt > Done training. New loss [14.228373] iter: [2000]\n",
      "[2018-05-12 16:54:23.149583] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:54:23.150953] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_1.zip\n",
      "[2018-05-12 16:54:23.280492] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_1.zip\n",
      "[2018-05-12 16:54:23.369710] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_1.zip\n",
      "[2018-05-12 16:54:25.523160] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 16:54:25.528144] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:54:25.662423] SGDOptimizer > Initial loss [0.932483971118927]\n",
      "\u001b[2K[2018-05-12 16:56:17.067790] SGDOptimizer > Curr loss: 8.588750E-01, n_evals: 999, Avg. time per updt: 0.110031\n",
      "[2018-05-12 16:56:17.100013] SGDOptimizer > Done training. New loss [0.834917] iter: [999]\n",
      "[2018-05-12 16:56:17.101752] apply_controller > Starting run\n",
      "[2018-05-12 16:56:17.102947] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:56:17.310249] apply_controller > Done. Stopping robot. Value of run [26.054157]\n",
      "[2018-05-12 16:56:17.311842] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:56:17.313217] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:56:17.315355] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 16:56:17.317106] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:56:17.330335] target_dyn_opt > Initial loss [27.61830285568347]\n",
      "\u001b[2K[2018-05-12 16:56:35.342598] target_dyn_opt > Curr loss: 4.234750E+00 [1921: 4.170052E+00], n_evals: 1999, Avg. time per updt: 0.007443\n",
      "[2018-05-12 16:56:35.356996] target_dyn_opt > Done training. New loss [4.321399] iter: [2000]\n",
      "[2018-05-12 16:56:35.359868] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:56:35.361212] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_2.zip\n",
      "[2018-05-12 16:56:35.535246] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_2.zip\n",
      "[2018-05-12 16:56:35.620865] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_2.zip\n",
      "[2018-05-12 16:56:37.775714] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 16:56:37.781316] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:56:37.928086] SGDOptimizer > Initial loss [0.8669836521148682]\n",
      "\u001b[2K[2018-05-12 16:58:29.365069] SGDOptimizer > Curr loss: 6.383805E-01, n_evals: 999, Avg. time per updt: 0.110158\n",
      "[2018-05-12 16:58:29.401133] SGDOptimizer > Done training. New loss [0.670397] iter: [999]\n",
      "[2018-05-12 16:58:29.403046] apply_controller > Starting run\n",
      "[2018-05-12 16:58:29.404403] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:58:29.595625] apply_controller > Done. Stopping robot. Value of run [27.469084]\n",
      "[2018-05-12 16:58:29.596868] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:58:29.598155] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:58:29.600717] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 16:58:29.602115] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:58:29.619819] target_dyn_opt > Initial loss [23.285630660581177]\n",
      "\u001b[2K[2018-05-12 16:58:49.071925] target_dyn_opt > Curr loss: -1.826612E-01 [1898: -6.858972E-01], n_evals: 1999, Avg. time per updt: 0.008174\n",
      "[2018-05-12 16:58:49.086814] target_dyn_opt > Done training. New loss [0.103309] iter: [2000]\n",
      "[2018-05-12 16:58:49.090138] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:58:49.091922] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_3.zip\n",
      "[2018-05-12 16:58:49.307318] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_3.zip\n",
      "[2018-05-12 16:58:49.394404] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_3.zip\n",
      "[2018-05-12 16:58:51.557446] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 16:58:51.562451] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:58:51.697688] SGDOptimizer > Initial loss [0.8911036849021912]\n",
      "\u001b[2K[2018-05-12 17:00:42.135750] SGDOptimizer > Curr loss: 4.686151E-01, n_evals: 999, Avg. time per updt: 0.109097\n",
      "[2018-05-12 17:00:42.169606] SGDOptimizer > Done training. New loss [0.482879] iter: [999]\n",
      "[2018-05-12 17:00:42.171243] apply_controller > Starting run\n",
      "[2018-05-12 17:00:42.172693] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:00:42.391945] apply_controller > Done. Stopping robot. Value of run [16.315678]\n",
      "[2018-05-12 17:00:42.393498] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:00:42.394881] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:00:42.397890] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 17:00:42.399226] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:00:42.417111] target_dyn_opt > Initial loss [6.628444227473489]\n",
      "\u001b[2K[2018-05-12 17:01:03.729722] target_dyn_opt > Curr loss: -3.009000E+00 [1845: -3.606079E+00], n_evals: 1999, Avg. time per updt: 0.009008\n",
      "[2018-05-12 17:01:03.748654] target_dyn_opt > Done training. New loss [-3.372504] iter: [2000]\n",
      "[2018-05-12 17:01:03.751379] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:01:03.758175] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_4.zip\n",
      "[2018-05-12 17:01:04.036863] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_4.zip\n",
      "[2018-05-12 17:01:04.128491] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_4.zip\n",
      "[2018-05-12 17:01:06.376926] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 17:01:06.382696] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:01:06.537199] SGDOptimizer > Initial loss [0.8303786516189575]\n",
      "\u001b[2K[2018-05-12 17:03:04.349239] SGDOptimizer > Curr loss: 4.430756E-01, n_evals: 999, Avg. time per updt: 0.116492\n",
      "[2018-05-12 17:03:04.385178] SGDOptimizer > Done training. New loss [0.441728] iter: [999]\n",
      "[2018-05-12 17:03:04.387096] apply_controller > Starting run\n",
      "[2018-05-12 17:03:04.388330] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:03:04.576761] apply_controller > Done. Stopping robot. Value of run [12.309449]\n",
      "[2018-05-12 17:03:04.578140] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:03:04.582475] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:03:04.585691] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 17:03:04.587326] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:03:04.603323] target_dyn_opt > Initial loss [-1.3675252248843517]\n",
      "\u001b[2K[2018-05-12 17:03:26.324875] target_dyn_opt > Curr loss: -5.298388E+00 [1959: -5.633589E+00], n_evals: 1999, Avg. time per updt: 0.009284\n",
      "[2018-05-12 17:03:26.341938] target_dyn_opt > Done training. New loss [-5.262766] iter: [2000]\n",
      "[2018-05-12 17:03:26.344629] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:03:26.346060] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_5.zip\n",
      "[2018-05-12 17:03:26.651799] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:03:26.738427] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_5.zip\n",
      "[2018-05-12 17:03:28.906829] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 17:03:28.911590] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:03:29.100702] SGDOptimizer > Initial loss [0.4596257507801056]\n",
      "\u001b[2K[2018-05-12 17:05:42.244139] SGDOptimizer > Curr loss: 4.473623E-01, n_evals: 999, Avg. time per updt: 0.131875\n",
      "[2018-05-12 17:05:42.288190] SGDOptimizer > Done training. New loss [0.442795] iter: [999]\n",
      "[2018-05-12 17:05:42.289929] apply_controller > Starting run\n",
      "[2018-05-12 17:05:42.291144] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:05:42.482667] apply_controller > Done. Stopping robot. Value of run [13.155147]\n",
      "[2018-05-12 17:05:42.483926] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:05:42.485186] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:05:42.488359] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 17:05:42.489717] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:05:42.507971] target_dyn_opt > Initial loss [-3.4581469162344343]\n",
      "\u001b[2K[2018-05-12 17:06:03.436592] target_dyn_opt > Curr loss: -6.332025E+00 [1771: -7.041620E+00], n_evals: 1999, Avg. time per updt: 0.008938\n",
      "[2018-05-12 17:06:03.451403] target_dyn_opt > Done training. New loss [-6.575892] iter: [2000]\n",
      "[2018-05-12 17:06:03.454413] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:06:03.455910] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_6.zip\n",
      "[2018-05-12 17:06:03.806328] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_6.zip\n",
      "[2018-05-12 17:06:03.896645] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_6.zip\n",
      "[2018-05-12 17:06:06.065053] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 17:06:06.070352] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:06:06.215567] SGDOptimizer > Initial loss [0.7908809781074524]\n",
      "\u001b[2K[2018-05-12 17:08:09.696968] SGDOptimizer > Curr loss: 6.657990E-01, n_evals: 999, Avg. time per updt: 0.122175\n",
      "[2018-05-12 17:08:09.745474] SGDOptimizer > Done training. New loss [0.812294] iter: [999]\n",
      "[2018-05-12 17:08:09.747506] apply_controller > Starting run\n",
      "[2018-05-12 17:08:09.749015] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:08:09.950129] apply_controller > Done. Stopping robot. Value of run [13.250772]\n",
      "[2018-05-12 17:08:09.951349] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:08:09.952706] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:08:09.955885] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 17:08:09.957200] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:08:09.973414] target_dyn_opt > Initial loss [-4.840738253089889]\n",
      "\u001b[2K[2018-05-12 17:08:30.695387] target_dyn_opt > Curr loss: -7.392769E+00 [1773: -8.179483E+00], n_evals: 1999, Avg. time per updt: 0.008835\n",
      "[2018-05-12 17:08:30.709502] target_dyn_opt > Done training. New loss [-7.740361] iter: [2000]\n",
      "[2018-05-12 17:08:30.712312] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:08:30.713809] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_7.zip\n",
      "[2018-05-12 17:08:31.112205] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_7.zip\n",
      "[2018-05-12 17:08:31.202212] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_7.zip\n",
      "[2018-05-12 17:08:33.379442] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 17:08:33.384833] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:08:33.524002] SGDOptimizer > Initial loss [0.7224271297454834]\n",
      "\u001b[2K[2018-05-12 17:10:18.336508] SGDOptimizer > Curr loss: 4.539546E-01, n_evals: 999, Avg. time per updt: 0.103476\n",
      "[2018-05-12 17:10:18.371434] SGDOptimizer > Done training. New loss [0.453065] iter: [999]\n",
      "[2018-05-12 17:10:18.373527] apply_controller > Starting run\n",
      "[2018-05-12 17:10:18.375278] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:10:18.594222] apply_controller > Done. Stopping robot. Value of run [15.922234]\n",
      "[2018-05-12 17:10:18.595508] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:10:18.596824] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:10:18.601122] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 17:10:18.603643] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:10:18.623201] target_dyn_opt > Initial loss [-6.02898797655471]\n",
      "\u001b[2K[2018-05-12 17:10:38.847216] target_dyn_opt > Curr loss: -8.662624E+00 [1317: -8.824895E+00], n_evals: 1999, Avg. time per updt: 0.008612\n",
      "[2018-05-12 17:10:38.861776] target_dyn_opt > Done training. New loss [-8.602093] iter: [2000]\n",
      "[2018-05-12 17:10:38.864622] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:10:38.865972] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_8.zip\n",
      "[2018-05-12 17:10:39.309733] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_8.zip\n",
      "[2018-05-12 17:10:39.402856] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_8.zip\n",
      "[2018-05-12 17:10:41.583969] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 17:10:41.588953] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:10:41.731945] SGDOptimizer > Initial loss [0.491035521030426]\n",
      "\u001b[2K[2018-05-12 17:12:36.256561] SGDOptimizer > Curr loss: 4.426951E-01, n_evals: 999, Avg. time per updt: 0.113223\n",
      "[2018-05-12 17:12:36.295455] SGDOptimizer > Done training. New loss [0.426930] iter: [999]\n",
      "[2018-05-12 17:12:36.297394] apply_controller > Starting run\n",
      "[2018-05-12 17:12:36.298911] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:12:36.501971] apply_controller > Done. Stopping robot. Value of run [14.040269]\n",
      "[2018-05-12 17:12:36.503200] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:12:36.504413] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:12:36.507283] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 17:12:36.508289] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:12:36.526566] target_dyn_opt > Initial loss [-5.103829019645165]\n",
      "\u001b[2K[2018-05-12 17:12:57.080495] target_dyn_opt > Curr loss: -8.960094E+00 [1908: -9.577222E+00], n_evals: 1999, Avg. time per updt: 0.008770\n",
      "[2018-05-12 17:12:57.097457] target_dyn_opt > Done training. New loss [-9.249247] iter: [2000]\n",
      "[2018-05-12 17:12:57.100103] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:12:57.101743] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_9.zip\n",
      "[2018-05-12 17:12:57.583709] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_9.zip\n",
      "[2018-05-12 17:12:57.673530] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_9.zip\n",
      "[2018-05-12 17:12:59.870184] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 17:12:59.875124] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:13:00.059816] SGDOptimizer > Initial loss [0.44236525893211365]\n",
      "\u001b[2K[2018-05-12 17:15:23.967806] SGDOptimizer > Curr loss: 4.456660E-01, n_evals: 999, Avg. time per updt: 0.142597\n",
      "[2018-05-12 17:15:24.017853] SGDOptimizer > Done training. New loss [0.432991] iter: [999]\n",
      "[2018-05-12 17:15:24.019651] apply_controller > Starting run\n",
      "[2018-05-12 17:15:24.020963] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:15:24.210286] apply_controller > Done. Stopping robot. Value of run [11.943687]\n",
      "[2018-05-12 17:15:24.211539] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:15:24.212954] train_dynamics > Training dynamics model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:15:24.216665] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 17:15:24.217917] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:15:24.238609] target_dyn_opt > Initial loss [-8.527793052428194]\n",
      "\u001b[2K[2018-05-12 17:15:45.492051] target_dyn_opt > Curr loss: -9.501811E+00 [1678: -1.011010E+01], n_evals: 1999, Avg. time per updt: 0.009128\n",
      "[2018-05-12 17:15:45.534376] target_dyn_opt > Done training. New loss [-9.623624] iter: [2000]\n",
      "[2018-05-12 17:15:45.540950] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:15:45.543022] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_10.zip\n",
      "[2018-05-12 17:15:46.166306] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_10.zip\n",
      "[2018-05-12 17:15:46.260506] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_10.zip\n",
      "[2018-05-12 17:15:48.714374] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 17:15:48.719187] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:15:48.881040] SGDOptimizer > Initial loss [0.434078574180603]\n",
      "\u001b[2K[2018-05-12 17:17:57.539373] SGDOptimizer > Curr loss: 4.171840E-01, n_evals: 999, Avg. time per updt: 0.127358\n",
      "[2018-05-12 17:17:57.577763] SGDOptimizer > Done training. New loss [0.413443] iter: [999]\n",
      "[2018-05-12 17:17:57.579639] apply_controller > Starting run\n",
      "[2018-05-12 17:17:57.581212] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:17:57.764311] apply_controller > Done. Stopping robot. Value of run [11.866219]\n",
      "[2018-05-12 17:17:57.765574] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:17:57.766911] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:17:57.771233] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 17:17:57.772745] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:17:57.788863] target_dyn_opt > Initial loss [-8.07676002623021]\n",
      "\u001b[2K[2018-05-12 17:18:17.584833] target_dyn_opt > Curr loss: -1.006716E+01 [1861: -1.060481E+01], n_evals: 1999, Avg. time per updt: 0.008413\n",
      "[2018-05-12 17:18:17.600494] target_dyn_opt > Done training. New loss [-9.725331] iter: [2000]\n",
      "[2018-05-12 17:18:17.603339] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:18:17.604942] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_11.zip\n",
      "[2018-05-12 17:18:18.223585] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_11.zip\n",
      "[2018-05-12 17:18:18.315227] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_11.zip\n",
      "[2018-05-12 17:18:20.604765] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 17:18:20.609539] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:18:20.759489] SGDOptimizer > Initial loss [0.4417686462402344]\n",
      "\u001b[2K[2018-05-12 17:20:27.609653] SGDOptimizer > Curr loss: 4.277354E-01, n_evals: 999, Avg. time per updt: 0.125539\n",
      "[2018-05-12 17:20:27.647813] SGDOptimizer > Done training. New loss [0.409942] iter: [999]\n",
      "[2018-05-12 17:20:27.649740] apply_controller > Starting run\n",
      "[2018-05-12 17:20:27.651198] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:20:27.847382] apply_controller > Done. Stopping robot. Value of run [11.255022]\n",
      "[2018-05-12 17:20:27.849121] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:20:27.850401] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:20:27.854911] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 17:20:27.856220] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:20:27.872146] target_dyn_opt > Initial loss [-9.1585997320929]\n",
      "\u001b[2K[2018-05-12 17:20:48.495744] target_dyn_opt > Curr loss: -1.034206E+01 [1507: -1.101070E+01], n_evals: 1999, Avg. time per updt: 0.008791\n",
      "[2018-05-12 17:20:48.511825] target_dyn_opt > Done training. New loss [-10.329329] iter: [2000]\n",
      "[2018-05-12 17:20:48.514437] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:20:48.515877] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_12.zip\n",
      "[2018-05-12 17:20:49.133501] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_12.zip\n",
      "[2018-05-12 17:20:49.223460] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_12.zip\n",
      "[2018-05-12 17:20:51.398767] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 17:20:51.404132] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:20:51.545658] SGDOptimizer > Initial loss [0.4230128228664398]\n",
      "\u001b[2K[2018-05-12 17:22:47.352097] SGDOptimizer > Curr loss: 4.122142E-01, n_evals: 999, Avg. time per updt: 0.114454\n",
      "[2018-05-12 17:22:47.385735] SGDOptimizer > Done training. New loss [0.408531] iter: [999]\n",
      "[2018-05-12 17:22:47.387767] apply_controller > Starting run\n",
      "[2018-05-12 17:22:47.389357] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:22:47.594470] apply_controller > Done. Stopping robot. Value of run [26.830193]\n",
      "[2018-05-12 17:22:47.595832] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:22:47.597375] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:22:47.601821] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 17:22:47.603334] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:22:47.621406] target_dyn_opt > Initial loss [16.777019733131812]\n",
      "\u001b[2K[2018-05-12 17:23:07.707513] target_dyn_opt > Curr loss: -1.065493E+01 [1475: -1.128197E+01], n_evals: 1999, Avg. time per updt: 0.008527\n",
      "[2018-05-12 17:23:07.722589] target_dyn_opt > Done training. New loss [-10.795560] iter: [2000]\n",
      "[2018-05-12 17:23:07.725089] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:23:07.726833] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_13.zip\n",
      "[2018-05-12 17:23:08.419254] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_13.zip\n",
      "[2018-05-12 17:23:08.513168] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_13.zip\n",
      "[2018-05-12 17:23:10.854213] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 17:23:10.858752] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:23:11.046565] SGDOptimizer > Initial loss [0.6666689515113831]\n",
      "\u001b[2K[2018-05-12 17:25:30.358491] SGDOptimizer > Curr loss: 4.286476E-01, n_evals: 999, Avg. time per updt: 0.137943\n",
      "[2018-05-12 17:25:30.406762] SGDOptimizer > Done training. New loss [0.423145] iter: [999]\n",
      "[2018-05-12 17:25:30.408669] apply_controller > Starting run\n",
      "[2018-05-12 17:25:30.411947] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:25:30.619225] apply_controller > Done. Stopping robot. Value of run [13.198034]\n",
      "[2018-05-12 17:25:30.620963] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:25:30.622319] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:25:30.626005] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 17:25:30.627286] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:25:30.646032] target_dyn_opt > Initial loss [-8.475280188143937]\n",
      "\u001b[2K[2018-05-12 17:25:51.731120] target_dyn_opt > Curr loss: -1.107234E+01 [1697: -1.167606E+01], n_evals: 1999, Avg. time per updt: 0.009007\n",
      "[2018-05-12 17:25:51.748101] target_dyn_opt > Done training. New loss [-11.424143] iter: [2000]\n",
      "[2018-05-12 17:25:51.750911] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:25:51.752483] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_14.zip\n",
      "[2018-05-12 17:25:52.443427] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_14.zip\n",
      "[2018-05-12 17:25:52.536145] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:25:54.723339] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 17:25:54.728714] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:25:54.934577] SGDOptimizer > Initial loss [0.440027117729187]\n",
      "\u001b[2K[2018-05-12 17:28:19.372399] SGDOptimizer > Curr loss: 4.150839E-01, n_evals: 999, Avg. time per updt: 0.143137\n",
      "[2018-05-12 17:28:19.422012] SGDOptimizer > Done training. New loss [0.413236] iter: [999]\n",
      "[2018-05-12 17:28:19.423858] apply_controller > Starting run\n",
      "[2018-05-12 17:28:19.425226] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:28:19.607488] apply_controller > Done. Stopping robot. Value of run [12.009007]\n",
      "[2018-05-12 17:28:19.608740] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:28:19.610076] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:28:19.614198] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 17:28:19.615983] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:28:19.634866] target_dyn_opt > Initial loss [-8.683484556474562]\n",
      "\u001b[2K[2018-05-12 17:28:39.822179] target_dyn_opt > Curr loss: -1.161714E+01 [1450: -1.192039E+01], n_evals: 1999, Avg. time per updt: 0.008582\n",
      "[2018-05-12 17:28:39.837805] target_dyn_opt > Done training. New loss [-11.505696] iter: [2000]\n",
      "[2018-05-12 17:28:39.840379] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:28:39.842103] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_15.zip\n",
      "[2018-05-12 17:28:40.612359] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_15.zip\n",
      "[2018-05-12 17:28:40.704022] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_15.zip\n",
      "[2018-05-12 17:28:42.921347] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 17:28:42.926668] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:28:43.094240] SGDOptimizer > Initial loss [0.5070917010307312]\n",
      "\u001b[2K[2018-05-12 17:30:49.394367] SGDOptimizer > Curr loss: 4.453478E-01, n_evals: 999, Avg. time per updt: 0.124971\n",
      "[2018-05-12 17:30:49.433950] SGDOptimizer > Done training. New loss [0.430968] iter: [999]\n",
      "[2018-05-12 17:30:49.435615] apply_controller > Starting run\n",
      "[2018-05-12 17:30:49.436846] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:30:49.626719] apply_controller > Done. Stopping robot. Value of run [11.240334]\n",
      "[2018-05-12 17:30:49.628432] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:30:49.629665] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:30:49.633569] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 17:30:49.635036] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:30:49.650821] target_dyn_opt > Initial loss [-9.582875539879286]\n",
      "\u001b[2K[2018-05-12 17:31:09.728290] target_dyn_opt > Curr loss: -1.151728E+01 [1534: -1.216379E+01], n_evals: 1999, Avg. time per updt: 0.008523\n",
      "[2018-05-12 17:31:09.744526] target_dyn_opt > Done training. New loss [-11.800635] iter: [2000]\n",
      "[2018-05-12 17:31:09.747986] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:31:09.750267] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_16.zip\n",
      "[2018-05-12 17:31:10.579872] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_16.zip\n",
      "[2018-05-12 17:31:10.673631] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_16.zip\n",
      "[2018-05-12 17:31:12.553823] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 17:31:12.558853] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:31:12.710356] SGDOptimizer > Initial loss [0.6935774087905884]\n",
      "\u001b[2K[2018-05-12 17:33:02.795465] SGDOptimizer > Curr loss: 4.157199E-01, n_evals: 999, Avg. time per updt: 0.108726\n",
      "[2018-05-12 17:33:02.829388] SGDOptimizer > Done training. New loss [0.419240] iter: [999]\n",
      "[2018-05-12 17:33:02.831163] apply_controller > Starting run\n",
      "[2018-05-12 17:33:02.832679] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:33:03.029405] apply_controller > Done. Stopping robot. Value of run [14.814023]\n",
      "[2018-05-12 17:33:03.030762] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:33:03.032544] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:33:03.036247] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 17:33:03.037643] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:33:03.053352] target_dyn_opt > Initial loss [-8.964946417630404]\n",
      "\u001b[2K[2018-05-12 17:33:22.996093] target_dyn_opt > Curr loss: -1.147010E+01 [1660: -1.253858E+01], n_evals: 1999, Avg. time per updt: 0.008471\n",
      "[2018-05-12 17:33:23.011850] target_dyn_opt > Done training. New loss [-11.687528] iter: [2000]\n",
      "[2018-05-12 17:33:23.015182] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:33:23.016779] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_17.zip\n",
      "[2018-05-12 17:33:23.865466] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_17.zip\n",
      "[2018-05-12 17:33:23.956034] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_17.zip\n",
      "[2018-05-12 17:33:26.145232] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 17:33:26.151391] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:33:26.287739] SGDOptimizer > Initial loss [0.4281851649284363]\n",
      "\u001b[2K[2018-05-12 17:35:17.313300] SGDOptimizer > Curr loss: 4.108897E-01, n_evals: 999, Avg. time per updt: 0.109621\n",
      "[2018-05-12 17:35:17.348542] SGDOptimizer > Done training. New loss [0.414717] iter: [999]\n",
      "[2018-05-12 17:35:17.350613] apply_controller > Starting run\n",
      "[2018-05-12 17:35:17.351932] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:35:17.558748] apply_controller > Done. Stopping robot. Value of run [13.594633]\n",
      "[2018-05-12 17:35:17.560045] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:35:17.561356] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:35:17.566089] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 17:35:17.567473] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:35:17.586513] target_dyn_opt > Initial loss [-9.283283035032547]\n",
      "\u001b[2K[2018-05-12 17:35:37.431049] target_dyn_opt > Curr loss: -1.214411E+01 [1675: -1.269432E+01], n_evals: 1999, Avg. time per updt: 0.008433\n",
      "[2018-05-12 17:35:37.445636] target_dyn_opt > Done training. New loss [-12.158201] iter: [2000]\n",
      "[2018-05-12 17:35:37.448402] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:35:37.449875] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_18.zip\n",
      "[2018-05-12 17:35:38.375994] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_18.zip\n",
      "[2018-05-12 17:35:38.467441] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_18.zip\n",
      "[2018-05-12 17:35:42.240287] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 17:35:42.246028] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:35:42.402000] SGDOptimizer > Initial loss [0.42172253131866455]\n",
      "\u001b[2K[2018-05-12 17:37:40.410029] SGDOptimizer > Curr loss: 3.880881E-01, n_evals: 999, Avg. time per updt: 0.116676\n",
      "[2018-05-12 17:37:40.447860] SGDOptimizer > Done training. New loss [0.384883] iter: [999]\n",
      "[2018-05-12 17:37:40.449905] apply_controller > Starting run\n",
      "[2018-05-12 17:37:40.451391] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:37:40.636323] apply_controller > Done. Stopping robot. Value of run [11.056768]\n",
      "[2018-05-12 17:37:40.637671] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:37:40.638931] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:37:40.643230] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 17:37:40.644701] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:37:40.661451] target_dyn_opt > Initial loss [-10.131616319047993]\n",
      "\u001b[2K[2018-05-12 17:38:01.001045] target_dyn_opt > Curr loss: -1.200429E+01 [1485: -1.287330E+01], n_evals: 1999, Avg. time per updt: 0.008657\n",
      "[2018-05-12 17:38:01.016656] target_dyn_opt > Done training. New loss [-11.990581] iter: [2000]\n",
      "[2018-05-12 17:38:01.019278] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:38:01.020661] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_19.zip\n",
      "[2018-05-12 17:38:01.943593] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_19.zip\n",
      "[2018-05-12 17:38:02.036684] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_19.zip\n",
      "[2018-05-12 17:38:04.244616] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 17:38:04.249311] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:38:04.426673] SGDOptimizer > Initial loss [0.5929355621337891]\n",
      "\u001b[2K[2018-05-12 17:40:23.350682] SGDOptimizer > Curr loss: 4.197245E-01, n_evals: 999, Avg. time per updt: 0.137598\n",
      "[2018-05-12 17:40:23.399207] SGDOptimizer > Done training. New loss [0.405119] iter: [999]\n",
      "[2018-05-12 17:40:23.401024] apply_controller > Starting run\n",
      "[2018-05-12 17:40:23.402378] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:40:23.572421] apply_controller > Done. Stopping robot. Value of run [10.749657]\n",
      "[2018-05-12 17:40:23.573876] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:40:23.575177] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:40:23.579255] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 17:40:23.580906] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:40:23.597022] target_dyn_opt > Initial loss [-8.216172428651788]\n",
      "\u001b[2K[2018-05-12 17:40:44.109001] target_dyn_opt > Curr loss: -1.234614E+01 [1805: -1.293580E+01], n_evals: 1999, Avg. time per updt: 0.008745\n",
      "[2018-05-12 17:40:44.125293] target_dyn_opt > Done training. New loss [-12.750066] iter: [2000]\n",
      "[2018-05-12 17:40:44.129146] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:40:44.130788] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_20.zip\n",
      "[2018-05-12 17:40:45.093707] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_20.zip\n",
      "[2018-05-12 17:40:45.187204] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_20.zip\n",
      "[2018-05-12 17:40:47.369621] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 17:40:47.374911] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:40:47.541050] SGDOptimizer > Initial loss [0.6740347146987915]\n",
      "\u001b[2K[2018-05-12 17:43:14.490919] SGDOptimizer > Curr loss: 3.759529E-01, n_evals: 999, Avg. time per updt: 0.145535\n",
      "[2018-05-12 17:43:14.539314] SGDOptimizer > Done training. New loss [0.440000] iter: [999]\n",
      "[2018-05-12 17:43:14.541231] apply_controller > Starting run\n",
      "[2018-05-12 17:43:14.542636] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:43:14.749360] apply_controller > Done. Stopping robot. Value of run [25.240799]\n",
      "[2018-05-12 17:43:14.750721] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:43:14.752211] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:43:14.756203] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 17:43:14.757709] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:43:14.775846] target_dyn_opt > Initial loss [-1.6851684045642146]\n",
      "\u001b[2K[2018-05-12 17:43:35.728551] target_dyn_opt > Curr loss: -1.254691E+01 [1399: -1.314618E+01], n_evals: 1999, Avg. time per updt: 0.008918\n",
      "[2018-05-12 17:43:35.743299] target_dyn_opt > Done training. New loss [-12.411468] iter: [2000]\n",
      "[2018-05-12 17:43:35.746073] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:43:35.747565] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_21.zip\n",
      "[2018-05-12 17:43:36.778072] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_21.zip\n",
      "[2018-05-12 17:43:36.870163] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_21.zip\n",
      "[2018-05-12 17:43:39.083736] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 17:43:39.089148] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:43:39.235993] SGDOptimizer > Initial loss [0.7474124431610107]\n",
      "\u001b[2K[2018-05-12 17:45:31.995846] SGDOptimizer > Curr loss: 4.000421E-01, n_evals: 999, Avg. time per updt: 0.111400\n",
      "[2018-05-12 17:45:32.030621] SGDOptimizer > Done training. New loss [0.396896] iter: [999]\n",
      "[2018-05-12 17:45:32.032535] apply_controller > Starting run\n",
      "[2018-05-12 17:45:32.033841] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:45:32.244553] apply_controller > Done. Stopping robot. Value of run [11.798441]\n",
      "[2018-05-12 17:45:32.246060] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:45:32.248663] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:45:32.253646] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 17:45:32.254930] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:45:32.271822] target_dyn_opt > Initial loss [-9.373591334119194]\n",
      "\u001b[2K[2018-05-12 17:45:53.064292] target_dyn_opt > Curr loss: -1.286662E+01 [1903: -1.336084E+01], n_evals: 1999, Avg. time per updt: 0.008838\n",
      "[2018-05-12 17:45:53.079959] target_dyn_opt > Done training. New loss [-12.576307] iter: [2000]\n",
      "[2018-05-12 17:45:53.082739] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:45:53.084557] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_22.zip\n",
      "[2018-05-12 17:45:54.146322] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_22.zip\n",
      "[2018-05-12 17:45:54.238579] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_22.zip\n",
      "[2018-05-12 17:45:56.415002] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 17:45:56.420951] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:45:56.580701] SGDOptimizer > Initial loss [0.6775530576705933]\n",
      "\u001b[2K[2018-05-12 17:47:58.904384] SGDOptimizer > Curr loss: 3.816882E-01, n_evals: 999, Avg. time per updt: 0.121007\n",
      "[2018-05-12 17:47:58.941913] SGDOptimizer > Done training. New loss [0.378493] iter: [999]\n",
      "[2018-05-12 17:47:58.943995] apply_controller > Starting run\n",
      "[2018-05-12 17:47:58.945302] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:47:59.131066] apply_controller > Done. Stopping robot. Value of run [11.016406]\n",
      "[2018-05-12 17:47:59.132410] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:47:59.133729] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:47:59.138448] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 17:47:59.139863] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:47:59.158486] target_dyn_opt > Initial loss [-10.182641957597486]\n",
      "\u001b[2K[2018-05-12 17:48:19.787922] target_dyn_opt > Curr loss: -1.289684E+01 [1513: -1.342050E+01], n_evals: 1999, Avg. time per updt: 0.008771\n",
      "[2018-05-12 17:48:19.804373] target_dyn_opt > Done training. New loss [-12.778950] iter: [2000]\n",
      "[2018-05-12 17:48:19.807061] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:48:19.808535] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_23.zip\n",
      "[2018-05-12 17:48:20.937759] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_23.zip\n",
      "[2018-05-12 17:48:21.032366] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_23.zip\n",
      "[2018-05-12 17:48:22.774788] ==== Iteration [24], experience: [720 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:48:22.780171] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:48:22.952205] SGDOptimizer > Initial loss [0.38807886838912964]\n",
      "\u001b[2K[2018-05-12 17:50:27.951149] SGDOptimizer > Curr loss: 3.800575E-01, n_evals: 999, Avg. time per updt: 0.123710\n",
      "[2018-05-12 17:50:27.992171] SGDOptimizer > Done training. New loss [0.383806] iter: [999]\n",
      "[2018-05-12 17:50:27.994084] apply_controller > Starting run\n",
      "[2018-05-12 17:50:27.995567] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:50:28.183770] apply_controller > Done. Stopping robot. Value of run [18.834042]\n",
      "[2018-05-12 17:50:28.185118] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:50:28.186364] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:50:28.190992] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 17:50:28.192269] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:50:28.207996] target_dyn_opt > Initial loss [-7.73263591207307]\n",
      "\u001b[2K[2018-05-12 17:50:47.999689] target_dyn_opt > Curr loss: -1.282054E+01 [1513: -1.351387E+01], n_evals: 1999, Avg. time per updt: 0.008364\n",
      "[2018-05-12 17:50:48.013452] target_dyn_opt > Done training. New loss [-12.785029] iter: [2000]\n",
      "[2018-05-12 17:50:48.016290] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:50:48.017805] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_24.zip\n",
      "[2018-05-12 17:50:49.151938] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_24.zip\n",
      "[2018-05-12 17:50:49.247552] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_24.zip\n",
      "[2018-05-12 17:50:51.435163] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 17:50:51.439971] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:50:51.581702] SGDOptimizer > Initial loss [0.6624100804328918]\n",
      "\u001b[2K[2018-05-12 17:52:43.324881] SGDOptimizer > Curr loss: 4.115352E-01, n_evals: 999, Avg. time per updt: 0.110413\n",
      "[2018-05-12 17:52:43.359930] SGDOptimizer > Done training. New loss [0.411312] iter: [999]\n",
      "[2018-05-12 17:52:43.361733] apply_controller > Starting run\n",
      "[2018-05-12 17:52:43.363138] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:52:43.547946] apply_controller > Done. Stopping robot. Value of run [12.076398]\n",
      "[2018-05-12 17:52:43.549328] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:52:43.550558] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:52:43.555742] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 17:52:43.557206] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:52:43.573495] target_dyn_opt > Initial loss [-10.25501592714211]\n",
      "\u001b[2K[2018-05-12 17:53:03.584564] target_dyn_opt > Curr loss: -1.324777E+01 [1798: -1.371686E+01], n_evals: 1999, Avg. time per updt: 0.008438\n",
      "[2018-05-12 17:53:03.600893] target_dyn_opt > Done training. New loss [-13.061468] iter: [2000]\n",
      "[2018-05-12 17:53:03.603519] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:53:03.604951] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_25.zip\n",
      "[2018-05-12 17:53:04.787300] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_25.zip\n",
      "[2018-05-12 17:53:04.880047] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_25.zip\n",
      "[2018-05-12 17:53:07.089054] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 17:53:07.094551] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:53:07.238457] SGDOptimizer > Initial loss [0.43048375844955444]\n",
      "\u001b[2K[2018-05-12 17:55:14.276764] SGDOptimizer > Curr loss: 4.028467E-01, n_evals: 999, Avg. time per updt: 0.125268\n",
      "[2018-05-12 17:55:14.310995] SGDOptimizer > Done training. New loss [0.400396] iter: [999]\n",
      "[2018-05-12 17:55:14.312760] apply_controller > Starting run\n",
      "[2018-05-12 17:55:14.314228] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:55:14.497360] apply_controller > Done. Stopping robot. Value of run [12.427175]\n",
      "[2018-05-12 17:55:14.498727] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:55:14.499935] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:55:14.505393] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 17:55:14.506663] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:55:14.524236] target_dyn_opt > Initial loss [-10.896428014811885]\n",
      "\u001b[2K[2018-05-12 17:55:41.678335] target_dyn_opt > Curr loss: -1.327234E+01 [1286: -1.387971E+01], n_evals: 1999, Avg. time per updt: 0.011557\n",
      "[2018-05-12 17:55:41.692309] target_dyn_opt > Done training. New loss [-13.099115] iter: [2000]\n",
      "[2018-05-12 17:55:41.694911] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:55:41.696588] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_26.zip\n",
      "[2018-05-12 17:55:42.932324] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_26.zip\n",
      "[2018-05-12 17:55:43.025895] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_26.zip\n",
      "[2018-05-12 17:55:45.246252] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 17:55:45.251329] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:55:45.401077] SGDOptimizer > Initial loss [0.4364577531814575]\n",
      "\u001b[2K[2018-05-12 17:57:48.953037] SGDOptimizer > Curr loss: 3.972510E-01, n_evals: 999, Avg. time per updt: 0.122151\n",
      "[2018-05-12 17:57:48.988301] SGDOptimizer > Done training. New loss [0.397165] iter: [999]\n",
      "[2018-05-12 17:57:48.990103] apply_controller > Starting run\n",
      "[2018-05-12 17:57:48.991594] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:57:49.181386] apply_controller > Done. Stopping robot. Value of run [20.010370]\n",
      "[2018-05-12 17:57:49.182992] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:57:49.184274] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:57:49.188623] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 17:57:49.190190] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:57:49.206187] target_dyn_opt > Initial loss [-9.177825366041343]\n",
      "\u001b[2K[2018-05-12 17:58:09.605750] target_dyn_opt > Curr loss: -1.369123E+01 [652: -1.404327E+01], n_evals: 1999, Avg. time per updt: 0.008657\n",
      "[2018-05-12 17:58:09.623100] target_dyn_opt > Done training. New loss [-13.489339] iter: [2000]\n",
      "[2018-05-12 17:58:09.625718] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:58:09.627060] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_27.zip\n",
      "[2018-05-12 17:58:10.905648] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_27.zip\n",
      "[2018-05-12 17:58:10.997690] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_27.zip\n",
      "[2018-05-12 17:58:13.223065] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 17:58:13.228052] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:58:13.409963] SGDOptimizer > Initial loss [0.6895471215248108]\n",
      "\u001b[2K[2018-05-12 18:00:39.456393] SGDOptimizer > Curr loss: 4.078264E-01, n_evals: 999, Avg. time per updt: 0.144685\n",
      "[2018-05-12 18:00:39.501047] SGDOptimizer > Done training. New loss [0.409528] iter: [999]\n",
      "[2018-05-12 18:00:39.504859] apply_controller > Starting run\n",
      "[2018-05-12 18:00:39.506215] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:00:39.749154] apply_controller > Done. Stopping robot. Value of run [12.135168]\n",
      "[2018-05-12 18:00:39.750528] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:00:39.751825] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:00:39.757213] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 18:00:39.758756] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:00:39.775200] target_dyn_opt > Initial loss [-10.520030928777883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:01:02.860788] target_dyn_opt > Curr loss: -1.340658E+01 [1896: -1.396489E+01], n_evals: 1999, Avg. time per updt: 0.010010\n",
      "[2018-05-12 18:01:02.881740] target_dyn_opt > Done training. New loss [-13.573767] iter: [2000]\n",
      "[2018-05-12 18:01:02.885062] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:01:02.886479] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_28.zip\n",
      "[2018-05-12 18:01:04.528831] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_28.zip\n",
      "[2018-05-12 18:01:04.648673] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_28.zip\n",
      "[2018-05-12 18:01:07.500020] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 18:01:07.505604] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:01:07.696139] SGDOptimizer > Initial loss [0.42210742831230164]\n",
      "\u001b[2K[2018-05-12 18:03:13.630384] SGDOptimizer > Curr loss: 3.975329E-01, n_evals: 999, Avg. time per updt: 0.124646\n",
      "[2018-05-12 18:03:13.670506] SGDOptimizer > Done training. New loss [0.398665] iter: [999]\n",
      "[2018-05-12 18:03:13.672171] apply_controller > Starting run\n",
      "[2018-05-12 18:03:13.673712] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:03:13.853054] apply_controller > Done. Stopping robot. Value of run [11.814992]\n",
      "[2018-05-12 18:03:13.854435] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:03:13.855687] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:03:13.861198] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 18:03:13.862466] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:03:13.878924] target_dyn_opt > Initial loss [-11.200814341676647]\n",
      "\u001b[2K[2018-05-12 18:03:36.257391] target_dyn_opt > Curr loss: -1.357847E+01 [1638: -1.422099E+01], n_evals: 1999, Avg. time per updt: 0.009570\n",
      "[2018-05-12 18:03:36.272895] target_dyn_opt > Done training. New loss [-13.184232] iter: [2000]\n",
      "[2018-05-12 18:03:36.275683] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:03:36.277069] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_29.zip\n",
      "[2018-05-12 18:03:37.638665] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_29.zip\n",
      "[2018-05-12 18:03:37.736224] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_29.zip\n",
      "[2018-05-12 18:03:39.961110] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 18:03:39.966741] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:03:40.131188] SGDOptimizer > Initial loss [0.4156937003135681]\n",
      "\u001b[2K[2018-05-12 18:05:43.444851] SGDOptimizer > Curr loss: 3.933279E-01, n_evals: 999, Avg. time per updt: 0.122032\n",
      "[2018-05-12 18:05:43.485568] SGDOptimizer > Done training. New loss [0.395188] iter: [999]\n",
      "[2018-05-12 18:05:43.487592] apply_controller > Starting run\n",
      "[2018-05-12 18:05:43.488970] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:05:43.671091] apply_controller > Done. Stopping robot. Value of run [12.950757]\n",
      "[2018-05-12 18:05:43.672593] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:05:43.673832] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:05:43.679085] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 18:05:43.680366] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:05:43.696409] target_dyn_opt > Initial loss [-9.914838553270588]\n",
      "\u001b[2K[2018-05-12 18:06:04.846382] target_dyn_opt > Curr loss: -1.346829E+01 [1025: -1.416877E+01], n_evals: 1999, Avg. time per updt: 0.009011\n",
      "[2018-05-12 18:06:04.862136] target_dyn_opt > Done training. New loss [-13.619464] iter: [2000]\n",
      "[2018-05-12 18:06:04.864800] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:06:04.866204] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_30.zip\n",
      "[2018-05-12 18:06:06.271768] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_30.zip\n",
      "[2018-05-12 18:06:06.366263] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 2 learn starting from source policy and dynamics\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_002_task_cost_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=False,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, task_cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:07:01.672530] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 18:07:01.696574] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 18:07:01.727029] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 18:07:01.739143] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 18:07:01.746079] Experience > Initialising new experience dataset\n",
      "[2018-05-12 18:07:01.747480] Executing uniformly-random controls\n",
      "[2018-05-12 18:07:01.748745] apply_controller > Starting run\n",
      "[2018-05-12 18:07:01.750224] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:07:01.930016] apply_controller > Done. Stopping robot. Value of run [29.985722]\n",
      "[2018-05-12 18:07:01.931577] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:07:01.933049] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:07:01.935954] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 18:07:01.937289] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "[2018-05-12 18:07:01.983726] target_dyn > Initialising loss function\n",
      "[2018-05-12 18:07:02.136994] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 18:07:04.338008] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 18:07:04.339289] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 18:07:04.400890] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 18:07:05.306381] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 18:07:10.186432] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:07:10.194051] target_dyn_opt > Initial loss [2739.4149668008836]\n",
      "\u001b[2K[2018-05-12 18:07:20.707157] target_dyn_opt > Curr loss: 6.242018E+01 [1926: 5.313988E+01], n_evals: 1999, Avg. time per updt: 0.003635\n",
      "[2018-05-12 18:07:20.714820] target_dyn_opt > Done training. New loss [68.703835] iter: [2000]\n",
      "[2018-05-12 18:07:20.965565] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:07:21.005136] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>})\n",
      "[2018-05-12 18:07:21.178345] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 18:07:21.179758] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 18:07:21.267464] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 18:07:21.268767] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 18:07:21.894826] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 18:07:21.896077] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 18:07:21.986688] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 18:07:21.988065] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 18:07:27.125070] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 18:07:28.483728] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 18:07:28.494426] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 18:07:28.529328] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 18:07:31.651538] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 18:07:51.116366] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_0.zip\n",
      "[2018-05-12 18:07:51.212898] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_0.zip\n",
      "[2018-05-12 18:07:51.324924] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_0.zip\n",
      "[2018-05-12 18:07:51.475703] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 18:07:51.478174] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 18:07:51.484280] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:07:51.984199] SGDOptimizer > Initial loss [69433.765625]\n",
      "\u001b[2K[2018-05-12 18:09:40.977325] SGDOptimizer > Curr loss: 1.463850E+04, n_evals: 999, Avg. time per updt: 0.107645\n",
      "[2018-05-12 18:09:41.000075] SGDOptimizer > Done training. New loss [47538.859375] iter: [999]\n",
      "[2018-05-12 18:09:41.002206] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 18:09:41.087388] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 18:09:41.253766] NNPolicy > Done compiling\n",
      "[2018-05-12 18:09:41.255400] apply_controller > Starting run\n",
      "[2018-05-12 18:09:41.257332] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:09:41.441277] apply_controller > Done. Stopping robot. Value of run [29.884550]\n",
      "[2018-05-12 18:09:41.442936] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:09:41.444441] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:09:41.447484] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 18:09:41.448851] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:09:41.461214] target_dyn_opt > Initial loss [86.12310002248228]\n",
      "\u001b[2K[2018-05-12 18:09:54.839105] target_dyn_opt > Curr loss: 2.913741E+01 [1648: 2.204935E+01], n_evals: 1999, Avg. time per updt: 0.005158\n",
      "[2018-05-12 18:09:54.849303] target_dyn_opt > Done training. New loss [24.445112] iter: [2000]\n",
      "[2018-05-12 18:09:54.851855] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:09:54.853476] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_1.zip\n",
      "[2018-05-12 18:09:55.000338] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_1.zip\n",
      "[2018-05-12 18:09:55.104843] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_1.zip\n",
      "[2018-05-12 18:09:57.776343] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 18:09:57.781382] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:09:57.913607] SGDOptimizer > Initial loss [63934.1171875]\n",
      "\u001b[2K[2018-05-12 18:11:49.084387] SGDOptimizer > Curr loss: 8.841696E+04, n_evals: 999, Avg. time per updt: 0.109826\n",
      "[2018-05-12 18:11:49.109829] SGDOptimizer > Done training. New loss [135481.015625] iter: [999]\n",
      "[2018-05-12 18:11:49.112154] apply_controller > Starting run\n",
      "[2018-05-12 18:11:49.113666] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:11:49.290275] apply_controller > Done. Stopping robot. Value of run [29.942989]\n",
      "[2018-05-12 18:11:49.291856] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:11:49.293467] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:11:49.295965] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 18:11:49.297414] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:11:49.310996] target_dyn_opt > Initial loss [29.044263332244544]\n",
      "\u001b[2K[2018-05-12 18:12:06.094948] target_dyn_opt > Curr loss: 1.182224E+01 [1964: 1.046451E+01], n_evals: 1999, Avg. time per updt: 0.006833\n",
      "[2018-05-12 18:12:06.107143] target_dyn_opt > Done training. New loss [12.355997] iter: [2000]\n",
      "[2018-05-12 18:12:06.109937] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:12:06.111728] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_2.zip\n",
      "[2018-05-12 18:12:06.297919] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_2.zip\n",
      "[2018-05-12 18:12:06.397727] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_2.zip\n",
      "[2018-05-12 18:12:08.910600] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 18:12:08.915874] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:12:09.043701] SGDOptimizer > Initial loss [106089.046875]\n",
      "\u001b[2K[2018-05-12 18:14:00.797915] SGDOptimizer > Curr loss: 2.352675E+04, n_evals: 999, Avg. time per updt: 0.109957\n",
      "[2018-05-12 18:14:00.826936] SGDOptimizer > Done training. New loss [23732.035156] iter: [999]\n",
      "[2018-05-12 18:14:00.831017] apply_controller > Starting run\n",
      "[2018-05-12 18:14:00.832265] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:14:01.070406] apply_controller > Done. Stopping robot. Value of run [29.926685]\n",
      "[2018-05-12 18:14:01.072186] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:14:01.073415] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:14:01.077840] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 18:14:01.079364] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:14:01.116688] target_dyn_opt > Initial loss [12.922963012367134]\n",
      "\u001b[2K[2018-05-12 18:14:19.874141] target_dyn_opt > Curr loss: 6.053292E+00 [1868: 4.915508E+00], n_evals: 1999, Avg. time per updt: 0.007793\n",
      "[2018-05-12 18:14:19.886871] target_dyn_opt > Done training. New loss [6.115399] iter: [2000]\n",
      "[2018-05-12 18:14:19.889464] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:14:19.892571] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_3.zip\n",
      "[2018-05-12 18:14:20.131215] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_3.zip\n",
      "[2018-05-12 18:14:20.248242] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_3.zip\n",
      "[2018-05-12 18:14:22.825066] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 18:14:22.830519] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:14:22.958065] SGDOptimizer > Initial loss [18939.2578125]\n",
      "\u001b[2K[2018-05-12 18:16:14.856275] SGDOptimizer > Curr loss: 2.979494E+04, n_evals: 999, Avg. time per updt: 0.110535\n",
      "[2018-05-12 18:16:14.879949] SGDOptimizer > Done training. New loss [29801.537109] iter: [999]\n",
      "[2018-05-12 18:16:14.882404] apply_controller > Starting run\n",
      "[2018-05-12 18:16:14.886007] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:16:15.095178] apply_controller > Done. Stopping robot. Value of run [28.572929]\n",
      "[2018-05-12 18:16:15.096848] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:16:15.098331] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:16:15.100785] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 18:16:15.102148] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:16:15.119318] target_dyn_opt > Initial loss [9.396487676700705]\n",
      "\u001b[2K[2018-05-12 18:16:34.039386] target_dyn_opt > Curr loss: 2.564275E+00 [1741: 1.668358E+00], n_evals: 1999, Avg. time per updt: 0.007869\n",
      "[2018-05-12 18:16:34.055002] target_dyn_opt > Done training. New loss [2.213652] iter: [2000]\n",
      "[2018-05-12 18:16:34.057801] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:16:34.059895] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_4.zip\n",
      "[2018-05-12 18:16:34.337065] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_4.zip\n",
      "[2018-05-12 18:16:34.439429] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_4.zip\n",
      "[2018-05-12 18:16:36.969381] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 18:16:36.974427] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:16:37.119549] SGDOptimizer > Initial loss [27245.18359375]\n",
      "\u001b[2K[2018-05-12 18:18:30.873856] SGDOptimizer > Curr loss: 2.221213E+04, n_evals: 999, Avg. time per updt: 0.112392\n",
      "[2018-05-12 18:18:30.900528] SGDOptimizer > Done training. New loss [22136.376953] iter: [999]\n",
      "[2018-05-12 18:18:30.902441] apply_controller > Starting run\n",
      "[2018-05-12 18:18:30.904008] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:18:31.079126] apply_controller > Done. Stopping robot. Value of run [29.986776]\n",
      "[2018-05-12 18:18:31.080568] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:18:31.082035] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:18:31.085028] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 18:18:31.086771] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:18:31.101108] target_dyn_opt > Initial loss [4.759038792706319]\n",
      "\u001b[2K[2018-05-12 18:18:52.582437] target_dyn_opt > Curr loss: -7.768030E-01 [1896: -1.114577E+00], n_evals: 1999, Avg. time per updt: 0.009028\n",
      "[2018-05-12 18:18:52.595407] target_dyn_opt > Done training. New loss [-0.396261] iter: [2000]\n",
      "[2018-05-12 18:18:52.598372] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:18:52.599801] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_5.zip\n",
      "[2018-05-12 18:18:52.923354] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_5.zip\n",
      "[2018-05-12 18:18:53.031698] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_5.zip\n",
      "[2018-05-12 18:18:55.575893] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 18:18:55.581661] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:18:55.728596] SGDOptimizer > Initial loss [16146.7490234375]\n",
      "\u001b[2K[2018-05-12 18:20:47.453708] SGDOptimizer > Curr loss: 1.852543E+04, n_evals: 999, Avg. time per updt: 0.110363\n",
      "[2018-05-12 18:20:47.478936] SGDOptimizer > Done training. New loss [25032.130859] iter: [999]\n",
      "[2018-05-12 18:20:47.480988] apply_controller > Starting run\n",
      "[2018-05-12 18:20:47.482785] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:20:47.656831] apply_controller > Done. Stopping robot. Value of run [29.985237]\n",
      "[2018-05-12 18:20:47.658165] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:20:47.659386] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:20:47.662451] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 18:20:47.663823] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:20:47.680779] target_dyn_opt > Initial loss [9.682417066577418]\n",
      "\u001b[2K[2018-05-12 18:21:05.893852] target_dyn_opt > Curr loss: -2.607559E+00 [1977: -2.835589E+00], n_evals: 1999, Avg. time per updt: 0.007577\n",
      "[2018-05-12 18:21:05.907007] target_dyn_opt > Done training. New loss [-2.516647] iter: [2000]\n",
      "[2018-05-12 18:21:05.909999] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:21:05.911418] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_6.zip\n",
      "[2018-05-12 18:21:06.278460] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_6.zip\n",
      "[2018-05-12 18:21:06.381093] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_6.zip\n",
      "[2018-05-12 18:21:08.943450] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 18:21:08.948786] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:21:09.086092] SGDOptimizer > Initial loss [40771.20703125]\n",
      "\u001b[2K[2018-05-12 18:23:05.601072] SGDOptimizer > Curr loss: 3.698182E+04, n_evals: 999, Avg. time per updt: 0.115177\n",
      "[2018-05-12 18:23:05.625212] SGDOptimizer > Done training. New loss [41267.160156] iter: [999]\n",
      "[2018-05-12 18:23:05.626963] apply_controller > Starting run\n",
      "[2018-05-12 18:23:05.628443] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:23:05.816939] apply_controller > Done. Stopping robot. Value of run [28.644251]\n",
      "[2018-05-12 18:23:05.818157] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:23:05.819515] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:23:05.822434] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 18:23:05.824236] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:23:05.840745] target_dyn_opt > Initial loss [1.5595983914641565]\n",
      "\u001b[2K[2018-05-12 18:23:24.444147] target_dyn_opt > Curr loss: -3.268668E+00 [1480: -4.147147E+00], n_evals: 1999, Avg. time per updt: 0.007780\n",
      "[2018-05-12 18:23:24.457965] target_dyn_opt > Done training. New loss [-3.862143] iter: [2000]\n",
      "[2018-05-12 18:23:24.460840] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:23:24.462851] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_7.zip\n",
      "[2018-05-12 18:23:24.881809] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_7.zip\n",
      "[2018-05-12 18:23:24.982100] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_7.zip\n",
      "[2018-05-12 18:23:27.622129] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 18:23:27.627775] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:23:27.777768] SGDOptimizer > Initial loss [36382.3359375]\n",
      "\u001b[2K[2018-05-12 18:25:18.947127] SGDOptimizer > Curr loss: 1.958506E+04, n_evals: 999, Avg. time per updt: 0.109807\n",
      "[2018-05-12 18:25:18.970616] SGDOptimizer > Done training. New loss [16452.753906] iter: [999]\n",
      "[2018-05-12 18:25:18.972836] apply_controller > Starting run\n",
      "[2018-05-12 18:25:18.973988] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:25:19.140482] apply_controller > Done. Stopping robot. Value of run [29.989891]\n",
      "[2018-05-12 18:25:19.142213] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:25:19.143436] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:25:19.146068] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 18:25:19.147488] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:25:19.162035] target_dyn_opt > Initial loss [-3.0789644833969962]\n",
      "\u001b[2K[2018-05-12 18:25:38.451148] target_dyn_opt > Curr loss: -5.051531E+00 [1923: -5.404793E+00], n_evals: 1999, Avg. time per updt: 0.007921\n",
      "[2018-05-12 18:25:38.465483] target_dyn_opt > Done training. New loss [-4.576589] iter: [2000]\n",
      "[2018-05-12 18:25:38.468687] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:25:38.471950] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_8.zip\n",
      "[2018-05-12 18:25:38.943198] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_8.zip\n",
      "[2018-05-12 18:25:39.047282] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_8.zip\n",
      "[2018-05-12 18:25:41.220969] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 18:25:41.226717] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:25:41.358378] SGDOptimizer > Initial loss [19553.89453125]\n",
      "\u001b[2K[2018-05-12 18:27:35.275834] SGDOptimizer > Curr loss: 3.328670E+04, n_evals: 999, Avg. time per updt: 0.112566\n",
      "[2018-05-12 18:27:35.299209] SGDOptimizer > Done training. New loss [31528.052734] iter: [999]\n",
      "[2018-05-12 18:27:35.301048] apply_controller > Starting run\n",
      "[2018-05-12 18:27:35.302333] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:27:35.498533] apply_controller > Done. Stopping robot. Value of run [29.927071]\n",
      "[2018-05-12 18:27:35.500008] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:27:35.501513] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:27:35.504646] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 18:27:35.506017] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:27:35.522199] target_dyn_opt > Initial loss [-3.357338646633936]\n",
      "\u001b[2K[2018-05-12 18:27:53.807654] target_dyn_opt > Curr loss: -5.612216E+00 [1577: -6.248832E+00], n_evals: 1999, Avg. time per updt: 0.007652\n",
      "[2018-05-12 18:27:53.821465] target_dyn_opt > Done training. New loss [-5.569221] iter: [2000]\n",
      "[2018-05-12 18:27:53.824263] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:27:53.825679] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_9.zip\n",
      "[2018-05-12 18:27:54.328472] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_9.zip\n",
      "[2018-05-12 18:27:54.432608] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_9.zip\n",
      "[2018-05-12 18:27:57.023051] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 18:27:57.029044] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:27:57.159151] SGDOptimizer > Initial loss [32656.25]\n",
      "\u001b[2K[2018-05-12 18:29:50.382129] SGDOptimizer > Curr loss: 1.959654E+04, n_evals: 999, Avg. time per updt: 0.111887\n",
      "[2018-05-12 18:29:50.412925] SGDOptimizer > Done training. New loss [18696.605469] iter: [999]\n",
      "[2018-05-12 18:29:50.414763] apply_controller > Starting run\n",
      "[2018-05-12 18:29:50.416106] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:29:50.660929] apply_controller > Done. Stopping robot. Value of run [25.625702]\n",
      "[2018-05-12 18:29:50.662393] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:29:50.663569] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:29:50.666871] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 18:29:50.668262] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:29:50.684591] target_dyn_opt > Initial loss [-4.243365755418555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:30:09.534704] target_dyn_opt > Curr loss: -6.387366E+00 [1939: -6.906607E+00], n_evals: 1999, Avg. time per updt: 0.007931\n",
      "[2018-05-12 18:30:09.550512] target_dyn_opt > Done training. New loss [-6.493181] iter: [2000]\n",
      "[2018-05-12 18:30:09.553331] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:30:09.554765] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_10.zip\n",
      "[2018-05-12 18:30:10.120019] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_10.zip\n",
      "[2018-05-12 18:30:10.225679] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_10.zip\n",
      "[2018-05-12 18:30:12.855644] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 18:30:12.861508] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:30:12.999015] SGDOptimizer > Initial loss [16508.91796875]\n",
      "\u001b[2K[2018-05-12 18:31:57.384987] SGDOptimizer > Curr loss: 1.623779E+04, n_evals: 999, Avg. time per updt: 0.103093\n",
      "[2018-05-12 18:31:57.409894] SGDOptimizer > Done training. New loss [13444.902344] iter: [999]\n",
      "[2018-05-12 18:31:57.412019] apply_controller > Starting run\n",
      "[2018-05-12 18:31:57.413391] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:31:57.575046] apply_controller > Done. Stopping robot. Value of run [29.628450]\n",
      "[2018-05-12 18:31:57.576274] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:31:57.577788] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:31:57.581476] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 18:31:57.582911] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:31:57.599867] target_dyn_opt > Initial loss [-6.13810023739827]\n",
      "\u001b[2K[2018-05-12 18:32:15.289755] target_dyn_opt > Curr loss: -7.014058E+00 [1953: -7.738067E+00], n_evals: 1999, Avg. time per updt: 0.007378\n",
      "[2018-05-12 18:32:15.305186] target_dyn_opt > Done training. New loss [-7.171149] iter: [2000]\n",
      "[2018-05-12 18:32:15.307837] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:32:15.309309] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_11.zip\n",
      "[2018-05-12 18:32:15.870366] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_11.zip\n",
      "[2018-05-12 18:32:15.971294] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_11.zip\n",
      "[2018-05-12 18:32:18.449765] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 18:32:18.455671] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:32:18.586209] SGDOptimizer > Initial loss [12354.9384765625]\n",
      "\u001b[2K[2018-05-12 18:34:00.759118] SGDOptimizer > Curr loss: 3.257018E+04, n_evals: 999, Avg. time per updt: 0.100885\n",
      "[2018-05-12 18:34:00.787218] SGDOptimizer > Done training. New loss [25988.267578] iter: [999]\n",
      "[2018-05-12 18:34:00.789023] apply_controller > Starting run\n",
      "[2018-05-12 18:34:00.790634] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:34:00.984092] apply_controller > Done. Stopping robot. Value of run [24.478720]\n",
      "[2018-05-12 18:34:00.985432] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:34:00.986383] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:34:00.990774] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 18:34:00.992623] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:34:01.008942] target_dyn_opt > Initial loss [-5.030327142060633]\n",
      "\u001b[2K[2018-05-12 18:34:18.817892] target_dyn_opt > Curr loss: -7.570787E+00 [1904: -8.189936E+00], n_evals: 1999, Avg. time per updt: 0.007436\n",
      "[2018-05-12 18:34:18.830551] target_dyn_opt > Done training. New loss [-7.896636] iter: [2000]\n",
      "[2018-05-12 18:34:18.833365] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:34:18.835012] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_12.zip\n",
      "[2018-05-12 18:34:19.443964] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_12.zip\n",
      "[2018-05-12 18:34:19.545318] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_12.zip\n",
      "[2018-05-12 18:34:22.027671] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 18:34:22.032770] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:34:22.164834] SGDOptimizer > Initial loss [48278.390625]\n",
      "\u001b[2K[2018-05-12 18:36:07.870748] SGDOptimizer > Curr loss: 1.456780E+04, n_evals: 999, Avg. time per updt: 0.104401\n",
      "[2018-05-12 18:36:07.899878] SGDOptimizer > Done training. New loss [16969.351562] iter: [999]\n",
      "[2018-05-12 18:36:07.901646] apply_controller > Starting run\n",
      "[2018-05-12 18:36:07.902827] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:36:08.145765] apply_controller > Done. Stopping robot. Value of run [29.068411]\n",
      "[2018-05-12 18:36:08.147136] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:36:08.148396] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:36:08.151867] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 18:36:08.153115] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:36:08.170094] target_dyn_opt > Initial loss [-6.720657154614923]\n",
      "\u001b[2K[2018-05-12 18:36:26.201381] target_dyn_opt > Curr loss: -8.486809E+00 [1772: -8.703479E+00], n_evals: 1999, Avg. time per updt: 0.007533\n",
      "[2018-05-12 18:36:26.215088] target_dyn_opt > Done training. New loss [-8.693795] iter: [2000]\n",
      "[2018-05-12 18:36:26.218068] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:36:26.219587] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_13.zip\n",
      "[2018-05-12 18:36:26.864261] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_13.zip\n",
      "[2018-05-12 18:36:26.965577] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_13.zip\n",
      "[2018-05-12 18:36:29.465888] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 18:36:29.471164] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:36:29.601777] SGDOptimizer > Initial loss [18085.607421875]\n",
      "\u001b[2K[2018-05-12 18:38:14.716386] SGDOptimizer > Curr loss: 3.019063E+04, n_evals: 999, Avg. time per updt: 0.103813\n",
      "[2018-05-12 18:38:14.742625] SGDOptimizer > Done training. New loss [24060.908203] iter: [999]\n",
      "[2018-05-12 18:38:14.744496] apply_controller > Starting run\n",
      "[2018-05-12 18:38:14.745879] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:38:14.926695] apply_controller > Done. Stopping robot. Value of run [28.978449]\n",
      "[2018-05-12 18:38:14.928261] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:38:14.929518] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:38:14.933181] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 18:38:14.934556] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:38:14.951326] target_dyn_opt > Initial loss [-7.030451164308978]\n",
      "\u001b[2K[2018-05-12 18:38:32.954643] target_dyn_opt > Curr loss: -8.888142E+00 [1829: -9.277110E+00], n_evals: 1999, Avg. time per updt: 0.007516\n",
      "[2018-05-12 18:38:32.967781] target_dyn_opt > Done training. New loss [-8.632411] iter: [2000]\n",
      "[2018-05-12 18:38:32.970484] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:38:32.971839] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_14.zip\n",
      "[2018-05-12 18:38:33.660444] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_14.zip\n",
      "[2018-05-12 18:38:33.767305] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_14.zip\n",
      "[2018-05-12 18:38:36.271474] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 18:38:36.277374] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:38:36.423385] SGDOptimizer > Initial loss [24716.794921875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:40:25.483579] SGDOptimizer > Curr loss: 1.258405E+04, n_evals: 999, Avg. time per updt: 0.107769\n",
      "[2018-05-12 18:40:25.508662] SGDOptimizer > Done training. New loss [11852.201172] iter: [999]\n",
      "[2018-05-12 18:40:25.510430] apply_controller > Starting run\n",
      "[2018-05-12 18:40:25.511905] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:40:25.684192] apply_controller > Done. Stopping robot. Value of run [28.420656]\n",
      "[2018-05-12 18:40:25.685524] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:40:25.686885] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:40:25.690083] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 18:40:25.691584] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:40:25.706010] target_dyn_opt > Initial loss [-7.930185625377785]\n",
      "\u001b[2K[2018-05-12 18:40:43.822502] target_dyn_opt > Curr loss: -9.295877E+00 [1970: -9.622886E+00], n_evals: 1999, Avg. time per updt: 0.007581\n",
      "[2018-05-12 18:40:43.835192] target_dyn_opt > Done training. New loss [-8.727267] iter: [2000]\n",
      "[2018-05-12 18:40:43.837695] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:40:43.839136] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_15.zip\n",
      "[2018-05-12 18:40:44.574735] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_15.zip\n",
      "[2018-05-12 18:40:44.676748] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_15.zip\n",
      "[2018-05-12 18:40:49.061839] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 18:40:49.067087] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:40:49.196752] SGDOptimizer > Initial loss [9133.998046875]\n",
      "\u001b[2K[2018-05-12 18:42:32.199078] SGDOptimizer > Curr loss: 3.745184E+04, n_evals: 999, Avg. time per updt: 0.101707\n",
      "[2018-05-12 18:42:32.223292] SGDOptimizer > Done training. New loss [30301.699219] iter: [999]\n",
      "[2018-05-12 18:42:32.225122] apply_controller > Starting run\n",
      "[2018-05-12 18:42:32.226445] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:42:32.397070] apply_controller > Done. Stopping robot. Value of run [24.272949]\n",
      "[2018-05-12 18:42:32.398294] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:42:32.399683] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:42:32.405081] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 18:42:32.406481] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:42:32.421111] target_dyn_opt > Initial loss [-8.02787181355709]\n",
      "\u001b[2K[2018-05-12 18:42:50.102291] target_dyn_opt > Curr loss: -9.713243E+00 [1417: -1.002886E+01], n_evals: 1999, Avg. time per updt: 0.007363\n",
      "[2018-05-12 18:42:50.117740] target_dyn_opt > Done training. New loss [-9.242538] iter: [2000]\n",
      "[2018-05-12 18:42:50.120558] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:42:50.122397] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_16.zip\n",
      "[2018-05-12 18:42:50.902189] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_16.zip\n",
      "[2018-05-12 18:42:51.005064] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_16.zip\n",
      "[2018-05-12 18:42:53.516711] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 18:42:53.522578] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:42:53.651255] SGDOptimizer > Initial loss [38324.515625]\n",
      "\u001b[2K[2018-05-12 18:44:39.986224] SGDOptimizer > Curr loss: 1.255081E+04, n_evals: 999, Avg. time per updt: 0.105036\n",
      "[2018-05-12 18:44:40.010960] SGDOptimizer > Done training. New loss [12891.431641] iter: [999]\n",
      "[2018-05-12 18:44:40.013051] apply_controller > Starting run\n",
      "[2018-05-12 18:44:40.014369] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:44:40.190575] apply_controller > Done. Stopping robot. Value of run [26.283020]\n",
      "[2018-05-12 18:44:40.192012] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:44:40.193329] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:44:40.197220] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 18:44:40.198475] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:44:40.213056] target_dyn_opt > Initial loss [-6.1859179971689695]\n",
      "\u001b[2K[2018-05-12 18:45:00.275332] target_dyn_opt > Curr loss: -9.727232E+00 [1604: -1.030686E+01], n_evals: 1999, Avg. time per updt: 0.008504\n",
      "[2018-05-12 18:45:00.289190] target_dyn_opt > Done training. New loss [-10.055898] iter: [2000]\n",
      "[2018-05-12 18:45:00.292080] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:45:00.293773] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_17.zip\n",
      "[2018-05-12 18:45:01.104715] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_17.zip\n",
      "[2018-05-12 18:45:01.208121] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_17.zip\n",
      "[2018-05-12 18:45:03.711705] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 18:45:03.716967] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:45:03.851586] SGDOptimizer > Initial loss [21477.474609375]\n",
      "\u001b[2K[2018-05-12 18:46:53.272408] SGDOptimizer > Curr loss: 1.595699E+04, n_evals: 999, Avg. time per updt: 0.108064\n",
      "[2018-05-12 18:46:53.297240] SGDOptimizer > Done training. New loss [17262.632812] iter: [999]\n",
      "[2018-05-12 18:46:53.299074] apply_controller > Starting run\n",
      "[2018-05-12 18:46:53.300582] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:46:53.477545] apply_controller > Done. Stopping robot. Value of run [29.721409]\n",
      "[2018-05-12 18:46:53.479159] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:46:53.480733] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:46:53.484743] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 18:46:53.486074] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:46:53.502805] target_dyn_opt > Initial loss [-8.500170460602982]\n",
      "\u001b[2K[2018-05-12 18:47:11.468478] target_dyn_opt > Curr loss: -1.010357E+01 [1619: -1.067989E+01], n_evals: 1999, Avg. time per updt: 0.007506\n",
      "[2018-05-12 18:47:11.481638] target_dyn_opt > Done training. New loss [-10.229236] iter: [2000]\n",
      "[2018-05-12 18:47:11.484417] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:47:11.486114] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_18.zip\n",
      "[2018-05-12 18:47:12.341445] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_18.zip\n",
      "[2018-05-12 18:47:12.444212] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_18.zip\n",
      "[2018-05-12 18:47:14.943784] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 18:47:14.949181] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:47:15.077936] SGDOptimizer > Initial loss [20440.314453125]\n",
      "\u001b[2K[2018-05-12 18:49:03.978402] SGDOptimizer > Curr loss: 1.235183E+04, n_evals: 999, Avg. time per updt: 0.107577\n",
      "[2018-05-12 18:49:04.006392] SGDOptimizer > Done training. New loss [10672.977539] iter: [999]\n",
      "[2018-05-12 18:49:04.008047] apply_controller > Starting run\n",
      "[2018-05-12 18:49:04.009349] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:49:04.174406] apply_controller > Done. Stopping robot. Value of run [29.464809]\n",
      "[2018-05-12 18:49:04.175905] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:49:04.177190] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:49:04.181283] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 18:49:04.182553] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:49:04.199022] target_dyn_opt > Initial loss [-8.209677924858084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:49:22.005316] target_dyn_opt > Curr loss: -1.073867E+01 [1839: -1.108668E+01], n_evals: 1999, Avg. time per updt: 0.007419\n",
      "[2018-05-12 18:49:22.018121] target_dyn_opt > Done training. New loss [-10.245923] iter: [2000]\n",
      "[2018-05-12 18:49:22.021046] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:49:22.022408] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_19.zip\n",
      "[2018-05-12 18:49:22.927869] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_19.zip\n",
      "[2018-05-12 18:49:23.029309] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_19.zip\n",
      "[2018-05-12 18:49:25.549078] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 18:49:25.554235] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:49:25.684238] SGDOptimizer > Initial loss [18763.236328125]\n",
      "\u001b[2K[2018-05-12 18:51:09.051585] SGDOptimizer > Curr loss: 2.384082E+04, n_evals: 999, Avg. time per updt: 0.102074\n",
      "[2018-05-12 18:51:09.078842] SGDOptimizer > Done training. New loss [14840.610352] iter: [999]\n",
      "[2018-05-12 18:51:09.080650] apply_controller > Starting run\n",
      "[2018-05-12 18:51:09.081924] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:51:09.300268] apply_controller > Done. Stopping robot. Value of run [29.905176]\n",
      "[2018-05-12 18:51:09.301698] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:51:09.302871] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:51:09.307178] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 18:51:09.308440] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:51:09.324748] target_dyn_opt > Initial loss [-9.271064153959598]\n",
      "\u001b[2K[2018-05-12 18:51:31.174961] target_dyn_opt > Curr loss: -1.106888E+01 [1770: -1.129142E+01], n_evals: 1999, Avg. time per updt: 0.009363\n",
      "[2018-05-12 18:51:31.198010] target_dyn_opt > Done training. New loss [-10.738486] iter: [2000]\n",
      "[2018-05-12 18:51:31.201615] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:51:31.203219] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_20.zip\n",
      "[2018-05-12 18:51:32.366470] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_20.zip\n",
      "[2018-05-12 18:51:32.470012] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_20.zip\n",
      "[2018-05-12 18:51:35.118910] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 18:51:35.124382] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:51:35.253816] SGDOptimizer > Initial loss [15092.8056640625]\n",
      "\u001b[2K[2018-05-12 18:53:26.100599] SGDOptimizer > Curr loss: 2.395182E+04, n_evals: 999, Avg. time per updt: 0.109540\n",
      "[2018-05-12 18:53:26.125314] SGDOptimizer > Done training. New loss [23158.564453] iter: [999]\n",
      "[2018-05-12 18:53:26.127161] apply_controller > Starting run\n",
      "[2018-05-12 18:53:26.128441] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:53:26.303979] apply_controller > Done. Stopping robot. Value of run [29.815540]\n",
      "[2018-05-12 18:53:26.305298] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:53:26.306513] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:53:26.310926] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 18:53:26.312569] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:53:26.326680] target_dyn_opt > Initial loss [-8.919259407910808]\n",
      "\u001b[2K[2018-05-12 18:53:44.192124] target_dyn_opt > Curr loss: -1.119882E+01 [1619: -1.164348E+01], n_evals: 1999, Avg. time per updt: 0.007475\n",
      "[2018-05-12 18:53:44.205071] target_dyn_opt > Done training. New loss [-11.321265] iter: [2000]\n",
      "[2018-05-12 18:53:44.207826] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:53:44.209724] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_21.zip\n",
      "[2018-05-12 18:53:45.187119] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_21.zip\n",
      "[2018-05-12 18:53:45.289712] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_21.zip\n",
      "[2018-05-12 18:53:47.804838] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 18:53:47.810572] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:53:47.956379] SGDOptimizer > Initial loss [25904.072265625]\n",
      "\u001b[2K[2018-05-12 18:55:36.527194] SGDOptimizer > Curr loss: 1.152047E+04, n_evals: 999, Avg. time per updt: 0.107213\n",
      "[2018-05-12 18:55:36.552280] SGDOptimizer > Done training. New loss [10554.502930] iter: [999]\n",
      "[2018-05-12 18:55:36.554416] apply_controller > Starting run\n",
      "[2018-05-12 18:55:36.555884] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:55:36.734759] apply_controller > Done. Stopping robot. Value of run [22.585712]\n",
      "[2018-05-12 18:55:36.736270] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:55:36.737496] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:55:36.741920] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 18:55:36.743286] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:55:36.757552] target_dyn_opt > Initial loss [-7.074496658845641]\n",
      "\u001b[2K[2018-05-12 18:55:54.571885] target_dyn_opt > Curr loss: -1.162786E+01 [1720: -1.175572E+01], n_evals: 1999, Avg. time per updt: 0.007424\n",
      "[2018-05-12 18:55:54.584639] target_dyn_opt > Done training. New loss [-11.192965] iter: [2000]\n",
      "[2018-05-12 18:55:54.587518] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:55:54.589251] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_22.zip\n",
      "[2018-05-12 18:55:55.608997] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_22.zip\n",
      "[2018-05-12 18:55:55.711433] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_22.zip\n",
      "[2018-05-12 18:55:58.239933] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 18:55:58.245372] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:55:58.376001] SGDOptimizer > Initial loss [14708.9794921875]\n",
      "\u001b[2K[2018-05-12 18:57:47.117418] SGDOptimizer > Curr loss: 3.378782E+04, n_evals: 999, Avg. time per updt: 0.107393\n",
      "[2018-05-12 18:57:47.144136] SGDOptimizer > Done training. New loss [31941.712891] iter: [999]\n",
      "[2018-05-12 18:57:47.146232] apply_controller > Starting run\n",
      "[2018-05-12 18:57:47.147791] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:57:47.322763] apply_controller > Done. Stopping robot. Value of run [29.871780]\n",
      "[2018-05-12 18:57:47.324098] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:57:47.325421] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:57:47.329847] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 18:57:47.331247] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:57:47.347916] target_dyn_opt > Initial loss [-9.929558729881357]\n",
      "\u001b[2K[2018-05-12 18:58:05.644748] target_dyn_opt > Curr loss: -1.159093E+01 [1943: -1.201631E+01], n_evals: 1999, Avg. time per updt: 0.007673\n",
      "[2018-05-12 18:58:05.658713] target_dyn_opt > Done training. New loss [-11.364474] iter: [2000]\n",
      "[2018-05-12 18:58:05.661428] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:58:05.663231] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_23.zip\n",
      "[2018-05-12 18:58:06.730562] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_23.zip\n",
      "[2018-05-12 18:58:06.835815] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_23.zip\n",
      "[2018-05-12 18:58:09.345729] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 18:58:09.351477] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:58:09.501060] SGDOptimizer > Initial loss [31288.822265625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 19:00:00.537035] SGDOptimizer > Curr loss: 2.311229E+04, n_evals: 999, Avg. time per updt: 0.109729\n",
      "[2018-05-12 19:00:00.563348] SGDOptimizer > Done training. New loss [14469.771484] iter: [999]\n",
      "[2018-05-12 19:00:00.565282] apply_controller > Starting run\n",
      "[2018-05-12 19:00:00.566809] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:00:00.735036] apply_controller > Done. Stopping robot. Value of run [28.099049]\n",
      "[2018-05-12 19:00:00.736433] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:00:00.737978] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:00:00.742253] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 19:00:00.743542] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:00:00.757698] target_dyn_opt > Initial loss [-9.43703396492991]\n",
      "\u001b[2K[2018-05-12 19:00:18.373511] target_dyn_opt > Curr loss: -1.205195E+01 [1556: -1.218129E+01], n_evals: 1999, Avg. time per updt: 0.007344\n",
      "[2018-05-12 19:00:18.386648] target_dyn_opt > Done training. New loss [-11.371996] iter: [2000]\n",
      "[2018-05-12 19:00:18.391324] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:00:18.392946] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_24.zip\n",
      "[2018-05-12 19:00:19.512717] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_24.zip\n",
      "[2018-05-12 19:00:19.619589] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_24.zip\n",
      "[2018-05-12 19:00:22.161176] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 19:00:22.166236] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:00:22.303272] SGDOptimizer > Initial loss [19297.72265625]\n",
      "\u001b[2K[2018-05-12 19:02:13.821858] SGDOptimizer > Curr loss: 1.870514E+04, n_evals: 999, Avg. time per updt: 0.110164\n",
      "[2018-05-12 19:02:13.848035] SGDOptimizer > Done training. New loss [18553.951172] iter: [999]\n",
      "[2018-05-12 19:02:13.849795] apply_controller > Starting run\n",
      "[2018-05-12 19:02:13.851034] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:02:14.025675] apply_controller > Done. Stopping robot. Value of run [29.793797]\n",
      "[2018-05-12 19:02:14.026885] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:02:14.028408] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:02:14.033140] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 19:02:14.034424] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:02:14.051520] target_dyn_opt > Initial loss [-9.988703667267721]\n",
      "\u001b[2K[2018-05-12 19:02:35.482169] target_dyn_opt > Curr loss: -1.188268E+01 [1859: -1.246441E+01], n_evals: 1999, Avg. time per updt: 0.009151\n",
      "[2018-05-12 19:02:35.495988] target_dyn_opt > Done training. New loss [-12.227940] iter: [2000]\n",
      "[2018-05-12 19:02:35.498464] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:02:35.499785] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_25.zip\n",
      "[2018-05-12 19:02:36.659892] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_25.zip\n",
      "[2018-05-12 19:02:36.763508] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_25.zip\n",
      "[2018-05-12 19:02:39.284289] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 19:02:39.289494] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:02:39.433958] SGDOptimizer > Initial loss [20726.474609375]\n",
      "\u001b[2K[2018-05-12 19:04:28.738422] SGDOptimizer > Curr loss: 1.323460E+04, n_evals: 999, Avg. time per updt: 0.108001\n",
      "[2018-05-12 19:04:28.768743] SGDOptimizer > Done training. New loss [13043.127930] iter: [999]\n",
      "[2018-05-12 19:04:28.770577] apply_controller > Starting run\n",
      "[2018-05-12 19:04:28.771876] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:04:29.020685] apply_controller > Done. Stopping robot. Value of run [29.094303]\n",
      "[2018-05-12 19:04:29.021971] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:04:29.023251] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:04:29.028252] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 19:04:29.029565] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:04:29.047176] target_dyn_opt > Initial loss [-9.307435519241587]\n",
      "\u001b[2K[2018-05-12 19:04:47.008788] target_dyn_opt > Curr loss: -1.195579E+01 [1987: -1.261471E+01], n_evals: 1999, Avg. time per updt: 0.007513\n",
      "[2018-05-12 19:04:47.024768] target_dyn_opt > Done training. New loss [-12.201139] iter: [2000]\n",
      "[2018-05-12 19:04:47.028084] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:04:47.029781] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_26.zip\n",
      "[2018-05-12 19:04:48.384875] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_26.zip\n",
      "[2018-05-12 19:04:48.491253] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_26.zip\n",
      "[2018-05-12 19:04:51.145184] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 19:04:51.150954] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:04:51.304598] SGDOptimizer > Initial loss [13051.51171875]\n",
      "\u001b[2K[2018-05-12 19:06:40.418506] SGDOptimizer > Curr loss: 1.282300E+04, n_evals: 999, Avg. time per updt: 0.107831\n",
      "[2018-05-12 19:06:40.444913] SGDOptimizer > Done training. New loss [12875.144531] iter: [999]\n",
      "[2018-05-12 19:06:40.447114] apply_controller > Starting run\n",
      "[2018-05-12 19:06:40.448465] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:06:40.626485] apply_controller > Done. Stopping robot. Value of run [28.837791]\n",
      "[2018-05-12 19:06:40.627931] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:06:40.629263] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:06:40.634893] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 19:06:40.636312] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:06:40.651531] target_dyn_opt > Initial loss [-10.940624673451696]\n",
      "\u001b[2K[2018-05-12 19:06:58.679896] target_dyn_opt > Curr loss: -1.259073E+01 [1472: -1.286045E+01], n_evals: 1999, Avg. time per updt: 0.007548\n",
      "[2018-05-12 19:06:58.693053] target_dyn_opt > Done training. New loss [-12.349292] iter: [2000]\n",
      "[2018-05-12 19:06:58.695669] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:06:58.697163] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_27.zip\n",
      "[2018-05-12 19:06:59.933847] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_27.zip\n",
      "[2018-05-12 19:07:00.037917] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_27.zip\n",
      "[2018-05-12 19:07:02.568959] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 19:07:02.574142] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:07:02.708408] SGDOptimizer > Initial loss [11901.240234375]\n",
      "\u001b[2K[2018-05-12 19:08:50.901633] SGDOptimizer > Curr loss: 1.981585E+04, n_evals: 999, Avg. time per updt: 0.106889\n",
      "[2018-05-12 19:08:50.926194] SGDOptimizer > Done training. New loss [23344.783203] iter: [999]\n",
      "[2018-05-12 19:08:50.927974] apply_controller > Starting run\n",
      "[2018-05-12 19:08:50.929582] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:08:51.111096] apply_controller > Done. Stopping robot. Value of run [29.880968]\n",
      "[2018-05-12 19:08:51.112449] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:08:51.113919] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:08:51.118482] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 19:08:51.119736] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:08:51.134470] target_dyn_opt > Initial loss [-9.652976512838062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 19:09:08.939753] target_dyn_opt > Curr loss: -1.243961E+01 [1791: -1.305509E+01], n_evals: 1999, Avg. time per updt: 0.007441\n",
      "[2018-05-12 19:09:08.952958] target_dyn_opt > Done training. New loss [-12.592446] iter: [2000]\n",
      "[2018-05-12 19:09:08.955653] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:09:08.957064] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_28.zip\n",
      "[2018-05-12 19:09:10.251176] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_28.zip\n",
      "[2018-05-12 19:09:10.354843] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_28.zip\n",
      "[2018-05-12 19:09:12.904812] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 19:09:12.911156] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:09:13.066821] SGDOptimizer > Initial loss [17912.044921875]\n",
      "\u001b[2K[2018-05-12 19:11:02.820308] SGDOptimizer > Curr loss: 2.382416E+04, n_evals: 999, Avg. time per updt: 0.108422\n",
      "[2018-05-12 19:11:02.845654] SGDOptimizer > Done training. New loss [22898.125000] iter: [999]\n",
      "[2018-05-12 19:11:02.847598] apply_controller > Starting run\n",
      "[2018-05-12 19:11:02.848960] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:11:03.053739] apply_controller > Done. Stopping robot. Value of run [29.859039]\n",
      "[2018-05-12 19:11:03.054956] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:11:03.056298] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:11:03.061534] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 19:11:03.062856] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:11:03.079419] target_dyn_opt > Initial loss [-9.89231672643245]\n",
      "\u001b[2K[2018-05-12 19:11:26.251295] target_dyn_opt > Curr loss: -1.256907E+01 [1445: -1.319573E+01], n_evals: 1999, Avg. time per updt: 0.009886\n",
      "[2018-05-12 19:11:26.264403] target_dyn_opt > Done training. New loss [-12.636573] iter: [2000]\n",
      "[2018-05-12 19:11:26.267085] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:11:26.268786] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_29.zip\n",
      "[2018-05-12 19:11:27.591943] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_29.zip\n",
      "[2018-05-12 19:11:27.694832] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_29.zip\n",
      "[2018-05-12 19:11:30.226362] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 19:11:30.231463] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:11:30.361664] SGDOptimizer > Initial loss [20568.310546875]\n",
      "\u001b[2K[2018-05-12 19:13:19.163142] SGDOptimizer > Curr loss: 2.426105E+04, n_evals: 999, Avg. time per updt: 0.107434\n",
      "[2018-05-12 19:13:19.193581] SGDOptimizer > Done training. New loss [24274.386719] iter: [999]\n",
      "[2018-05-12 19:13:19.195253] apply_controller > Starting run\n",
      "[2018-05-12 19:13:19.196702] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:13:19.439194] apply_controller > Done. Stopping robot. Value of run [29.973801]\n",
      "[2018-05-12 19:13:19.440785] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:13:19.442139] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:13:19.446815] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 19:13:19.448139] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:13:19.465445] target_dyn_opt > Initial loss [-5.348768560321498]\n",
      "\u001b[2K[2018-05-12 19:13:37.332065] target_dyn_opt > Curr loss: -1.272342E+01 [1952: -1.323914E+01], n_evals: 1999, Avg. time per updt: 0.007465\n",
      "[2018-05-12 19:13:37.345132] target_dyn_opt > Done training. New loss [-12.863421] iter: [2000]\n",
      "[2018-05-12 19:13:37.347662] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:13:37.349255] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_30.zip\n",
      "[2018-05-12 19:13:38.707634] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_30.zip\n",
      "[2018-05-12 19:13:38.810372] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 3 learn starting from scratch, using klqp imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_003_il_klqp_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:13:07.022654] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 20:13:07.045435] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 20:13:07.076419] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 20:13:07.089706] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 20:13:07.095354] Experience > Initialising new experience dataset\n",
      "[2018-05-12 20:13:07.096943] Executing uniformly-random controls\n",
      "[2018-05-12 20:13:07.098647] apply_controller > Starting run\n",
      "[2018-05-12 20:13:07.100083] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:13:07.265401] apply_controller > Done. Stopping robot. Value of run [29.808973]\n",
      "[2018-05-12 20:13:07.266742] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:13:07.267972] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:13:07.270836] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 20:13:07.272224] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "[2018-05-12 20:13:07.304038] target_dyn > Initialising loss function\n",
      "[2018-05-12 20:13:07.449808] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 20:13:07.735924] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 20:13:07.737459] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 20:13:07.794441] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 20:13:08.718419] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 20:13:13.567093] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:13:13.574570] target_dyn_opt > Initial loss [1449.0460819028094]\n",
      "\u001b[2K[2018-05-12 20:13:23.726167] target_dyn_opt > Curr loss: 5.120722E+01 [1969: 4.795866E+01], n_evals: 1999, Avg. time per updt: 0.003513\n",
      "[2018-05-12 20:13:23.732170] target_dyn_opt > Done training. New loss [54.190578] iter: [2000]\n",
      "[2018-05-12 20:13:23.958062] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:13:23.996217] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>})\n",
      "[2018-05-12 20:13:24.155916] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 20:13:24.157103] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 20:13:24.241057] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 20:13:24.242331] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 20:13:24.797464] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 20:13:24.798709] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 20:13:24.885539] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 20:13:24.886886] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 20:13:30.795284] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 20:13:33.979528] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 20:13:33.989546] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 20:13:34.021916] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 20:13:36.985656] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 20:13:55.246334] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_0.zip\n",
      "[2018-05-12 20:13:55.344798] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_0.zip\n",
      "[2018-05-12 20:13:55.453342] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_0.zip\n",
      "[2018-05-12 20:13:55.592438] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 20:13:55.594297] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 20:13:55.600376] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:13:55.814462] SGDOptimizer > Initial loss [1809.6915283203125]\n",
      "\u001b[2K[2018-05-12 20:15:35.430577] SGDOptimizer > Curr loss: 4.369022E+01, n_evals: 999, Avg. time per updt: 0.098318\n",
      "[2018-05-12 20:15:35.458804] SGDOptimizer > Done training. New loss [110.390114] iter: [999]\n",
      "[2018-05-12 20:15:35.461164] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 20:15:35.540221] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 20:15:35.692238] NNPolicy > Done compiling\n",
      "[2018-05-12 20:15:35.693672] apply_controller > Starting run\n",
      "[2018-05-12 20:15:35.694917] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:15:36.074634] apply_controller > Done. Stopping robot. Value of run [26.841860]\n",
      "[2018-05-12 20:15:36.075872] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:15:36.077211] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:15:36.079655] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 20:15:36.087313] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:15:36.098548] target_dyn_opt > Initial loss [156.75030500114923]\n",
      "\u001b[2K[2018-05-12 20:15:48.759590] target_dyn_opt > Curr loss: 2.502083E+01 [1983: 2.290967E+01], n_evals: 1999, Avg. time per updt: 0.004833\n",
      "[2018-05-12 20:15:48.768349] target_dyn_opt > Done training. New loss [24.500931] iter: [2000]\n",
      "[2018-05-12 20:15:48.771099] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:15:48.772927] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_1.zip\n",
      "[2018-05-12 20:15:48.916921] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_1.zip\n",
      "[2018-05-12 20:15:49.023452] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_1.zip\n",
      "[2018-05-12 20:15:51.819620] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 20:15:51.824978] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:15:51.956453] SGDOptimizer > Initial loss [489.1590576171875]\n",
      "\u001b[2K[2018-05-12 20:17:26.029032] SGDOptimizer > Curr loss: 1.518364E+02, n_evals: 999, Avg. time per updt: 0.092771\n",
      "[2018-05-12 20:17:26.053182] SGDOptimizer > Done training. New loss [109.822807] iter: [999]\n",
      "[2018-05-12 20:17:26.055070] apply_controller > Starting run\n",
      "[2018-05-12 20:17:26.056433] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:17:26.306159] apply_controller > Done. Stopping robot. Value of run [27.152744]\n",
      "[2018-05-12 20:17:26.307540] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:17:26.308845] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:17:26.311088] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 20:17:26.312558] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:17:26.325776] target_dyn_opt > Initial loss [135.39488375698346]\n",
      "\u001b[2K[2018-05-12 20:17:42.755637] target_dyn_opt > Curr loss: 1.579651E+01 [1931: 1.322955E+01], n_evals: 1999, Avg. time per updt: 0.006716\n",
      "[2018-05-12 20:17:42.767384] target_dyn_opt > Done training. New loss [14.415502] iter: [2000]\n",
      "[2018-05-12 20:17:42.770241] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:17:42.771759] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_2.zip\n",
      "[2018-05-12 20:17:42.958098] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_2.zip\n",
      "[2018-05-12 20:17:43.059182] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_2.zip\n",
      "[2018-05-12 20:17:45.822069] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 20:17:45.827005] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:17:45.942741] SGDOptimizer > Initial loss [300.6897888183594]\n",
      "\u001b[2K[2018-05-12 20:19:20.402095] SGDOptimizer > Curr loss: 7.409200E+01, n_evals: 999, Avg. time per updt: 0.093154\n",
      "[2018-05-12 20:19:20.430645] SGDOptimizer > Done training. New loss [98.809341] iter: [999]\n",
      "[2018-05-12 20:19:20.432639] apply_controller > Starting run\n",
      "[2018-05-12 20:19:20.433957] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:19:20.651922] apply_controller > Done. Stopping robot. Value of run [29.182371]\n",
      "[2018-05-12 20:19:20.653254] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:19:20.654598] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:19:20.657001] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 20:19:20.658577] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:19:20.672665] target_dyn_opt > Initial loss [51.6355578030293]\n",
      "\u001b[2K[2018-05-12 20:19:38.390340] target_dyn_opt > Curr loss: 9.046230E+00 [1731: 7.585209E+00], n_evals: 1999, Avg. time per updt: 0.007346\n",
      "[2018-05-12 20:19:38.402554] target_dyn_opt > Done training. New loss [8.581415] iter: [2000]\n",
      "[2018-05-12 20:19:38.405340] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:19:38.406808] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_3.zip\n",
      "[2018-05-12 20:19:38.631067] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_3.zip\n",
      "[2018-05-12 20:19:38.735720] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_3.zip\n",
      "[2018-05-12 20:19:41.515402] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 20:19:41.520758] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:19:41.638247] SGDOptimizer > Initial loss [206.2925262451172]\n",
      "\u001b[2K[2018-05-12 20:21:17.990694] SGDOptimizer > Curr loss: 6.084954E+01, n_evals: 999, Avg. time per updt: 0.095054\n",
      "[2018-05-12 20:21:18.014843] SGDOptimizer > Done training. New loss [53.010418] iter: [999]\n",
      "[2018-05-12 20:21:18.016628] apply_controller > Starting run\n",
      "[2018-05-12 20:21:18.017907] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:21:18.264860] apply_controller > Done. Stopping robot. Value of run [28.167542]\n",
      "[2018-05-12 20:21:18.266461] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:21:18.267746] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:21:18.270398] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 20:21:18.272081] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:21:18.288474] target_dyn_opt > Initial loss [33.07630306505598]\n",
      "\u001b[2K[2018-05-12 20:21:36.640217] target_dyn_opt > Curr loss: 7.188378E+00 [1855: 4.112478E+00], n_evals: 1999, Avg. time per updt: 0.007603\n",
      "[2018-05-12 20:21:36.652971] target_dyn_opt > Done training. New loss [4.618518] iter: [2000]\n",
      "[2018-05-12 20:21:36.655521] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:21:36.656885] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_4.zip\n",
      "[2018-05-12 20:21:36.944474] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_4.zip\n",
      "[2018-05-12 20:21:37.046030] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_4.zip\n",
      "[2018-05-12 20:21:40.147284] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 20:21:40.153056] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:21:40.297570] SGDOptimizer > Initial loss [187.55487060546875]\n",
      "\u001b[2K[2018-05-12 20:23:23.936250] SGDOptimizer > Curr loss: 1.369909E+02, n_evals: 999, Avg. time per updt: 0.102307\n",
      "[2018-05-12 20:23:23.969967] SGDOptimizer > Done training. New loss [131.286987] iter: [999]\n",
      "[2018-05-12 20:23:23.974067] apply_controller > Starting run\n",
      "[2018-05-12 20:23:23.975467] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:23:24.265974] apply_controller > Done. Stopping robot. Value of run [28.956675]\n",
      "[2018-05-12 20:23:24.266959] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:23:24.267741] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:23:24.274696] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 20:23:24.276638] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:23:24.321608] target_dyn_opt > Initial loss [10.952441990602997]\n",
      "\u001b[2K[2018-05-12 20:23:43.744304] target_dyn_opt > Curr loss: 2.908167E+00 [1994: 1.429534E+00], n_evals: 1999, Avg. time per updt: 0.008055\n",
      "[2018-05-12 20:23:43.760418] target_dyn_opt > Done training. New loss [2.724225] iter: [2000]\n",
      "[2018-05-12 20:23:43.763163] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:23:43.766360] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_5.zip\n",
      "[2018-05-12 20:23:44.148828] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_5.zip\n",
      "[2018-05-12 20:23:44.272551] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_5.zip\n",
      "[2018-05-12 20:23:47.592825] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 20:23:47.598005] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:23:47.752621] SGDOptimizer > Initial loss [183.74156188964844]\n",
      "\u001b[2K[2018-05-12 20:25:35.594984] SGDOptimizer > Curr loss: 9.030720E+01, n_evals: 999, Avg. time per updt: 0.106446\n",
      "[2018-05-12 20:25:35.620236] SGDOptimizer > Done training. New loss [88.412155] iter: [999]\n",
      "[2018-05-12 20:25:35.622412] apply_controller > Starting run\n",
      "[2018-05-12 20:25:35.623761] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:25:35.806487] apply_controller > Done. Stopping robot. Value of run [29.997684]\n",
      "[2018-05-12 20:25:35.807713] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:25:35.808982] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:25:35.812052] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 20:25:35.813794] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:25:35.830479] target_dyn_opt > Initial loss [5.547990425266188]\n",
      "\u001b[2K[2018-05-12 20:25:53.594466] target_dyn_opt > Curr loss: 7.135745E-01 [1566: -3.422650E-01], n_evals: 1999, Avg. time per updt: 0.0073343\n",
      "[2018-05-12 20:25:53.609665] target_dyn_opt > Done training. New loss [1.333639] iter: [2000]\n",
      "[2018-05-12 20:25:53.612649] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:25:53.614100] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_6.zip\n",
      "[2018-05-12 20:25:54.021297] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_6.zip\n",
      "[2018-05-12 20:25:54.129343] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_6.zip\n",
      "[2018-05-12 20:25:57.200105] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 20:25:57.205470] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:25:57.325275] SGDOptimizer > Initial loss [116.95795440673828]\n",
      "\u001b[2K[2018-05-12 20:27:37.160601] SGDOptimizer > Curr loss: 7.166201E+01, n_evals: 999, Avg. time per updt: 0.098490\n",
      "[2018-05-12 20:27:37.184538] SGDOptimizer > Done training. New loss [65.098305] iter: [999]\n",
      "[2018-05-12 20:27:37.186698] apply_controller > Starting run\n",
      "[2018-05-12 20:27:37.188053] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:27:37.409493] apply_controller > Done. Stopping robot. Value of run [28.743435]\n",
      "[2018-05-12 20:27:37.410701] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:27:37.413630] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:27:37.416299] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 20:27:37.418154] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:27:37.432501] target_dyn_opt > Initial loss [13.578265984734351]\n",
      "\u001b[2K[2018-05-12 20:27:54.513754] target_dyn_opt > Curr loss: -1.136976E+00 [1274: -1.611615E+00], n_evals: 1999, Avg. time per updt: 0.007065\n",
      "[2018-05-12 20:27:54.526700] target_dyn_opt > Done training. New loss [-0.532303] iter: [2000]\n",
      "[2018-05-12 20:27:54.529278] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:27:54.530606] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_7.zip\n",
      "[2018-05-12 20:27:54.918391] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_7.zip\n",
      "[2018-05-12 20:27:55.013753] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_7.zip\n",
      "[2018-05-12 20:27:57.782139] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 20:27:57.787456] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:27:57.910145] SGDOptimizer > Initial loss [161.6786651611328]\n",
      "\u001b[2K[2018-05-12 20:29:30.681287] SGDOptimizer > Curr loss: 1.887861E+02, n_evals: 999, Avg. time per updt: 0.091491\n",
      "[2018-05-12 20:29:30.704178] SGDOptimizer > Done training. New loss [236.822723] iter: [999]\n",
      "[2018-05-12 20:29:30.706285] apply_controller > Starting run\n",
      "[2018-05-12 20:29:30.707669] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:29:30.897058] apply_controller > Done. Stopping robot. Value of run [29.897728]\n",
      "[2018-05-12 20:29:30.898393] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:29:30.899689] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:29:30.902242] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 20:29:30.903624] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:29:30.917594] target_dyn_opt > Initial loss [3.8736015477314076]\n",
      "\u001b[2K[2018-05-12 20:29:48.426993] target_dyn_opt > Curr loss: -1.598387E+00 [1582: -2.750037E+00], n_evals: 1999, Avg. time per updt: 0.007300\n",
      "[2018-05-12 20:29:48.441330] target_dyn_opt > Done training. New loss [-1.803476] iter: [2000]\n",
      "[2018-05-12 20:29:48.443937] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:29:48.445347] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_8.zip\n",
      "[2018-05-12 20:29:48.920257] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_8.zip\n",
      "[2018-05-12 20:29:49.017543] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_8.zip\n",
      "[2018-05-12 20:29:51.808706] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 20:29:51.814217] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:29:51.937895] SGDOptimizer > Initial loss [108.95458984375]\n",
      "\u001b[2K[2018-05-12 20:31:27.088706] SGDOptimizer > Curr loss: 7.760637E+01, n_evals: 999, Avg. time per updt: 0.093841\n",
      "[2018-05-12 20:31:27.112885] SGDOptimizer > Done training. New loss [58.210728] iter: [999]\n",
      "[2018-05-12 20:31:27.114745] apply_controller > Starting run\n",
      "[2018-05-12 20:31:27.115585] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:31:27.306177] apply_controller > Done. Stopping robot. Value of run [28.128326]\n",
      "[2018-05-12 20:31:27.307796] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:31:27.308756] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:31:27.312060] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 20:31:27.315894] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:31:27.331579] target_dyn_opt > Initial loss [-1.8946908533187772]\n",
      "\u001b[2K[2018-05-12 20:31:44.798805] target_dyn_opt > Curr loss: -3.101903E+00 [1713: -3.818303E+00], n_evals: 1999, Avg. time per updt: 0.007258\n",
      "[2018-05-12 20:31:44.816615] target_dyn_opt > Done training. New loss [-3.105309] iter: [2000]\n",
      "[2018-05-12 20:31:44.819221] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:31:44.820881] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_9.zip\n",
      "[2018-05-12 20:31:45.320258] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_9.zip\n",
      "[2018-05-12 20:31:45.421682] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_9.zip\n",
      "[2018-05-12 20:31:48.437659] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 20:31:48.442910] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:31:48.573479] SGDOptimizer > Initial loss [51.32132339477539]\n",
      "\u001b[2K[2018-05-12 20:33:26.698792] SGDOptimizer > Curr loss: 7.202946E+01, n_evals: 999, Avg. time per updt: 0.096835\n",
      "[2018-05-12 20:33:26.721935] SGDOptimizer > Done training. New loss [54.434517] iter: [999]\n",
      "[2018-05-12 20:33:26.723589] apply_controller > Starting run\n",
      "[2018-05-12 20:33:26.724878] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:33:26.926562] apply_controller > Done. Stopping robot. Value of run [29.890650]\n",
      "[2018-05-12 20:33:26.927896] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:33:26.928850] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:33:26.932251] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 20:33:26.933222] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:33:26.946573] target_dyn_opt > Initial loss [-0.3213394027331784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:33:46.041886] target_dyn_opt > Curr loss: -3.845105E+00 [1941: -4.612096E+00], n_evals: 1999, Avg. time per updt: 0.008042\n",
      "[2018-05-12 20:33:46.054923] target_dyn_opt > Done training. New loss [-3.908500] iter: [2000]\n",
      "[2018-05-12 20:33:46.057763] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:33:46.059285] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_10.zip\n",
      "[2018-05-12 20:33:46.578953] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_10.zip\n",
      "[2018-05-12 20:33:46.677389] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_10.zip\n",
      "[2018-05-12 20:33:49.482247] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 20:33:49.487934] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:33:49.614617] SGDOptimizer > Initial loss [85.52481079101562]\n",
      "\u001b[2K[2018-05-12 20:35:25.287344] SGDOptimizer > Curr loss: 7.315050E+01, n_evals: 999, Avg. time per updt: 0.094382\n",
      "[2018-05-12 20:35:25.311706] SGDOptimizer > Done training. New loss [79.855682] iter: [999]\n",
      "[2018-05-12 20:35:25.313370] apply_controller > Starting run\n",
      "[2018-05-12 20:35:25.314656] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:35:25.497937] apply_controller > Done. Stopping robot. Value of run [29.374386]\n",
      "[2018-05-12 20:35:25.499279] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:35:25.500778] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:35:25.504044] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 20:35:25.505431] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:35:25.521143] target_dyn_opt > Initial loss [-4.064233961568653]\n",
      "\u001b[2K[2018-05-12 20:35:43.074435] target_dyn_opt > Curr loss: -4.710786E+00 [1936: -5.622435E+00], n_evals: 1999, Avg. time per updt: 0.007301\n",
      "[2018-05-12 20:35:43.087177] target_dyn_opt > Done training. New loss [-4.884670] iter: [2000]\n",
      "[2018-05-12 20:35:43.090265] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:35:43.091877] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_11.zip\n",
      "[2018-05-12 20:35:43.656348] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_11.zip\n",
      "[2018-05-12 20:35:43.753910] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_11.zip\n",
      "[2018-05-12 20:35:46.562500] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 20:35:46.567623] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:35:46.710143] SGDOptimizer > Initial loss [99.30023956298828]\n",
      "\u001b[2K[2018-05-12 20:37:22.434797] SGDOptimizer > Curr loss: 7.271214E+01, n_evals: 999, Avg. time per updt: 0.094416\n",
      "[2018-05-12 20:37:22.460444] SGDOptimizer > Done training. New loss [66.544167] iter: [999]\n",
      "[2018-05-12 20:37:22.462410] apply_controller > Starting run\n",
      "[2018-05-12 20:37:22.463953] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:37:22.659869] apply_controller > Done. Stopping robot. Value of run [27.098261]\n",
      "[2018-05-12 20:37:22.661368] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:37:22.662682] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:37:22.666444] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 20:37:22.667872] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:37:22.683865] target_dyn_opt > Initial loss [-4.39454162794731]\n",
      "\u001b[2K[2018-05-12 20:37:41.544293] target_dyn_opt > Curr loss: -5.564897E+00 [1898: -6.305591E+00], n_evals: 1999, Avg. time per updt: 0.007901\n",
      "[2018-05-12 20:37:41.557509] target_dyn_opt > Done training. New loss [-5.960584] iter: [2000]\n",
      "[2018-05-12 20:37:41.560682] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:37:41.562164] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_12.zip\n",
      "[2018-05-12 20:37:42.150433] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_12.zip\n",
      "[2018-05-12 20:37:42.245406] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_12.zip\n",
      "[2018-05-12 20:37:45.027046] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 20:37:45.032001] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:37:45.152270] SGDOptimizer > Initial loss [64.31504821777344]\n",
      "\u001b[2K[2018-05-12 20:39:23.754914] SGDOptimizer > Curr loss: 8.437412E+01, n_evals: 999, Avg. time per updt: 0.097318\n",
      "[2018-05-12 20:39:23.786345] SGDOptimizer > Done training. New loss [91.379051] iter: [999]\n",
      "[2018-05-12 20:39:23.788077] apply_controller > Starting run\n",
      "[2018-05-12 20:39:23.789274] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:39:24.012045] apply_controller > Done. Stopping robot. Value of run [29.190010]\n",
      "[2018-05-12 20:39:24.013684] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:39:24.014959] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:39:24.018126] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 20:39:24.019667] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:39:24.034287] target_dyn_opt > Initial loss [-4.075117544605961]\n",
      "\u001b[2K[2018-05-12 20:39:41.972257] target_dyn_opt > Curr loss: -6.111131E+00 [992: -6.830262E+00], n_evals: 1999, Avg. time per updt: 0.007497\n",
      "[2018-05-12 20:39:41.985400] target_dyn_opt > Done training. New loss [-6.536750] iter: [2000]\n",
      "[2018-05-12 20:39:41.988204] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:39:41.989532] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_13.zip\n",
      "[2018-05-12 20:39:42.626781] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_13.zip\n",
      "[2018-05-12 20:39:42.721607] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_13.zip\n",
      "[2018-05-12 20:39:45.521374] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 20:39:45.526416] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:39:45.650388] SGDOptimizer > Initial loss [99.39570617675781]\n",
      "\u001b[2K[2018-05-12 20:41:24.435499] SGDOptimizer > Curr loss: 1.389257E+02, n_evals: 999, Avg. time per updt: 0.097490\n",
      "[2018-05-12 20:41:24.462094] SGDOptimizer > Done training. New loss [253.574905] iter: [999]\n",
      "[2018-05-12 20:41:24.463748] apply_controller > Starting run\n",
      "[2018-05-12 20:41:24.464950] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:41:24.650845] apply_controller > Done. Stopping robot. Value of run [28.766054]\n",
      "[2018-05-12 20:41:24.652530] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:41:24.655861] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:41:24.665664] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 20:41:24.666935] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:41:24.683860] target_dyn_opt > Initial loss [-5.984883029878825]\n",
      "\u001b[2K[2018-05-12 20:41:42.672928] target_dyn_opt > Curr loss: -6.785939E+00 [1742: -7.443015E+00], n_evals: 1999, Avg. time per updt: 0.007510\n",
      "[2018-05-12 20:41:42.686322] target_dyn_opt > Done training. New loss [-6.654930] iter: [2000]\n",
      "[2018-05-12 20:41:42.689105] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:41:42.690466] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_14.zip\n",
      "[2018-05-12 20:41:43.372293] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_14.zip\n",
      "[2018-05-12 20:41:43.468864] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_14.zip\n",
      "[2018-05-12 20:41:46.270002] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 20:41:46.275105] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:41:46.419965] SGDOptimizer > Initial loss [97.5036392211914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:43:26.496291] SGDOptimizer > Curr loss: 9.777536E+01, n_evals: 999, Avg. time per updt: 0.098778\n",
      "[2018-05-12 20:43:26.522299] SGDOptimizer > Done training. New loss [89.084068] iter: [999]\n",
      "[2018-05-12 20:43:26.524153] apply_controller > Starting run\n",
      "[2018-05-12 20:43:26.525455] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:43:26.709600] apply_controller > Done. Stopping robot. Value of run [29.969034]\n",
      "[2018-05-12 20:43:26.710988] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:43:26.712875] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:43:26.716548] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 20:43:26.717837] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:43:26.734353] target_dyn_opt > Initial loss [-5.8900237881161015]\n",
      "\u001b[2K[2018-05-12 20:43:44.551802] target_dyn_opt > Curr loss: -7.737148E+00 [1270: -7.983390E+00], n_evals: 1999, Avg. time per updt: 0.007422\n",
      "[2018-05-12 20:43:44.564506] target_dyn_opt > Done training. New loss [-7.297037] iter: [2000]\n",
      "[2018-05-12 20:43:44.567045] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:43:44.568436] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_15.zip\n",
      "[2018-05-12 20:43:45.291219] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_15.zip\n",
      "[2018-05-12 20:43:45.388251] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_15.zip\n",
      "[2018-05-12 20:43:48.199170] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 20:43:48.205084] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:43:48.338214] SGDOptimizer > Initial loss [88.7794189453125]\n",
      "\u001b[2K[2018-05-12 20:45:28.102958] SGDOptimizer > Curr loss: 9.147955E+01, n_evals: 999, Avg. time per updt: 0.098469\n",
      "[2018-05-12 20:45:28.128943] SGDOptimizer > Done training. New loss [144.481461] iter: [999]\n",
      "[2018-05-12 20:45:28.130606] apply_controller > Starting run\n",
      "[2018-05-12 20:45:28.132087] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:45:28.309625] apply_controller > Done. Stopping robot. Value of run [28.207523]\n",
      "[2018-05-12 20:45:28.310953] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:45:28.312179] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:45:28.315679] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 20:45:28.317385] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:45:28.332143] target_dyn_opt > Initial loss [-6.848559504680894]\n",
      "\u001b[2K[2018-05-12 20:45:52.557109] target_dyn_opt > Curr loss: -8.417477E+00 [1927: -8.452904E+00], n_evals: 1999, Avg. time per updt: 0.010521\n",
      "[2018-05-12 20:45:52.575100] target_dyn_opt > Done training. New loss [-7.892199] iter: [2000]\n",
      "[2018-05-12 20:45:52.578570] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:45:52.580388] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_16.zip\n",
      "[2018-05-12 20:45:53.459384] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_16.zip\n",
      "[2018-05-12 20:45:53.557733] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_16.zip\n",
      "[2018-05-12 20:45:56.401847] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 20:45:56.406375] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:45:56.551486] SGDOptimizer > Initial loss [94.7374267578125]\n",
      "\u001b[2K[2018-05-12 20:47:39.012450] SGDOptimizer > Curr loss: 7.941199E+01, n_evals: 999, Avg. time per updt: 0.101169\n",
      "[2018-05-12 20:47:39.039451] SGDOptimizer > Done training. New loss [78.915039] iter: [999]\n",
      "[2018-05-12 20:47:39.041089] apply_controller > Starting run\n",
      "[2018-05-12 20:47:39.042573] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:47:39.221450] apply_controller > Done. Stopping robot. Value of run [26.909536]\n",
      "[2018-05-12 20:47:39.222914] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:47:39.223967] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:47:39.228229] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 20:47:39.229737] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:47:39.246335] target_dyn_opt > Initial loss [-6.005824927711624]\n",
      "\u001b[2K[2018-05-12 20:47:56.969108] target_dyn_opt > Curr loss: -8.413984E+00 [1875: -8.859416E+00], n_evals: 1999, Avg. time per updt: 0.007403\n",
      "[2018-05-12 20:47:56.983254] target_dyn_opt > Done training. New loss [-8.389574] iter: [2000]\n",
      "[2018-05-12 20:47:56.985926] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:47:56.987511] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_17.zip\n",
      "[2018-05-12 20:47:57.806924] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_17.zip\n",
      "[2018-05-12 20:47:57.905240] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_17.zip\n",
      "[2018-05-12 20:48:00.718993] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 20:48:00.724284] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:48:00.844587] SGDOptimizer > Initial loss [75.63398742675781]\n",
      "\u001b[2K[2018-05-12 20:49:46.358760] SGDOptimizer > Curr loss: 6.201745E+01, n_evals: 999, Avg. time per updt: 0.104200\n",
      "[2018-05-12 20:49:46.385484] SGDOptimizer > Done training. New loss [62.506218] iter: [999]\n",
      "[2018-05-12 20:49:46.387918] apply_controller > Starting run\n",
      "[2018-05-12 20:49:46.389960] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:49:46.615307] apply_controller > Done. Stopping robot. Value of run [28.899960]\n",
      "[2018-05-12 20:49:46.616542] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:49:46.617874] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:49:46.622428] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 20:49:46.623711] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:49:46.638093] target_dyn_opt > Initial loss [-6.095444916164377]\n",
      "\u001b[2K[2018-05-12 20:50:04.764360] target_dyn_opt > Curr loss: -8.746287E+00 [1204: -9.208214E+00], n_evals: 1999, Avg. time per updt: 0.007580\n",
      "[2018-05-12 20:50:04.779649] target_dyn_opt > Done training. New loss [-8.647629] iter: [2000]\n",
      "[2018-05-12 20:50:04.782206] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:50:04.783829] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_18.zip\n",
      "[2018-05-12 20:50:05.639115] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_18.zip\n",
      "[2018-05-12 20:50:05.738025] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_18.zip\n",
      "[2018-05-12 20:50:10.491725] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 20:50:10.497413] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:50:10.639479] SGDOptimizer > Initial loss [84.66505432128906]\n",
      "\u001b[2K[2018-05-12 20:51:57.295989] SGDOptimizer > Curr loss: 8.429072E+01, n_evals: 999, Avg. time per updt: 0.105250\n",
      "[2018-05-12 20:51:57.321634] SGDOptimizer > Done training. New loss [115.934105] iter: [999]\n",
      "[2018-05-12 20:51:57.323561] apply_controller > Starting run\n",
      "[2018-05-12 20:51:57.324824] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:51:57.589210] apply_controller > Done. Stopping robot. Value of run [29.242113]\n",
      "[2018-05-12 20:51:57.590496] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:51:57.591870] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:51:57.595878] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 20:51:57.597302] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:51:57.611106] target_dyn_opt > Initial loss [-8.706030629421102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:52:20.171100] target_dyn_opt > Curr loss: -8.872998E+00 [1169: -9.725033E+00], n_evals: 1999, Avg. time per updt: 0.009548\n",
      "[2018-05-12 20:52:20.184300] target_dyn_opt > Done training. New loss [-9.178159] iter: [2000]\n",
      "[2018-05-12 20:52:20.186897] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:52:20.188462] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_19.zip\n",
      "[2018-05-12 20:52:21.092353] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_19.zip\n",
      "[2018-05-12 20:52:21.191756] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_19.zip\n",
      "[2018-05-12 20:52:24.028651] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 20:52:24.034044] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:52:24.156794] SGDOptimizer > Initial loss [123.30403900146484]\n",
      "\u001b[2K[2018-05-12 20:54:11.551068] SGDOptimizer > Curr loss: 9.723950E+01, n_evals: 999, Avg. time per updt: 0.105971\n",
      "[2018-05-12 20:54:11.576977] SGDOptimizer > Done training. New loss [150.924759] iter: [999]\n",
      "[2018-05-12 20:54:11.578977] apply_controller > Starting run\n",
      "[2018-05-12 20:54:11.580538] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:54:11.758628] apply_controller > Done. Stopping robot. Value of run [29.998886]\n",
      "[2018-05-12 20:54:11.759844] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:54:11.761175] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:54:11.765683] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 20:54:11.767111] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:54:11.782074] target_dyn_opt > Initial loss [-7.56185535868792]\n",
      "\u001b[2K[2018-05-12 20:54:29.703637] target_dyn_opt > Curr loss: -9.135219E+00 [1720: -1.003726E+01], n_evals: 1999, Avg. time per updt: 0.007493\n",
      "[2018-05-12 20:54:29.719068] target_dyn_opt > Done training. New loss [-9.224328] iter: [2000]\n",
      "[2018-05-12 20:54:29.721739] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:54:29.723079] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_20.zip\n",
      "[2018-05-12 20:54:30.668848] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_20.zip\n",
      "[2018-05-12 20:54:30.767067] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_20.zip\n",
      "[2018-05-12 20:54:33.590006] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 20:54:33.595418] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:54:33.727349] SGDOptimizer > Initial loss [554.4725341796875]\n",
      "\u001b[2K[2018-05-12 20:56:26.322714] SGDOptimizer > Curr loss: 1.440446E+02, n_evals: 999, Avg. time per updt: 0.111186\n",
      "[2018-05-12 20:56:26.353056] SGDOptimizer > Done training. New loss [79.807121] iter: [999]\n",
      "[2018-05-12 20:56:26.355022] apply_controller > Starting run\n",
      "[2018-05-12 20:56:26.356548] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:56:26.569337] apply_controller > Done. Stopping robot. Value of run [27.030294]\n",
      "[2018-05-12 20:56:26.570560] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:56:26.571776] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:56:26.576066] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 20:56:26.577512] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:56:26.591632] target_dyn_opt > Initial loss [-8.233392474139372]\n",
      "\u001b[2K[2018-05-12 20:56:44.535987] target_dyn_opt > Curr loss: -9.839159E+00 [1713: -1.031727E+01], n_evals: 1999, Avg. time per updt: 0.007507\n",
      "[2018-05-12 20:56:44.548866] target_dyn_opt > Done training. New loss [-9.786186] iter: [2000]\n",
      "[2018-05-12 20:56:44.551340] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:56:44.552727] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_21.zip\n",
      "[2018-05-12 20:56:45.533467] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_21.zip\n",
      "[2018-05-12 20:56:45.631726] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_21.zip\n",
      "[2018-05-12 20:56:48.473196] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 20:56:48.478254] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:56:48.614592] SGDOptimizer > Initial loss [86.18090057373047]\n",
      "\u001b[2K[2018-05-12 20:58:37.155642] SGDOptimizer > Curr loss: 1.059604E+02, n_evals: 999, Avg. time per updt: 0.107206\n",
      "[2018-05-12 20:58:37.183831] SGDOptimizer > Done training. New loss [91.429619] iter: [999]\n",
      "[2018-05-12 20:58:37.185936] apply_controller > Starting run\n",
      "[2018-05-12 20:58:37.187256] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:58:37.364069] apply_controller > Done. Stopping robot. Value of run [28.339367]\n",
      "[2018-05-12 20:58:37.365403] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:58:37.366911] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:58:37.373687] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 20:58:37.374967] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:58:37.391302] target_dyn_opt > Initial loss [-9.15780636502885]\n",
      "\u001b[2K[2018-05-12 20:58:55.412850] target_dyn_opt > Curr loss: -1.024699E+01 [586: -1.063787E+01], n_evals: 1999, Avg. time per updt: 0.007531\n",
      "[2018-05-12 20:58:55.428268] target_dyn_opt > Done training. New loss [-10.315668] iter: [2000]\n",
      "[2018-05-12 20:58:55.431060] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:58:55.432369] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_22.zip\n",
      "[2018-05-12 20:58:56.453956] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_22.zip\n",
      "[2018-05-12 20:58:56.552658] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_22.zip\n",
      "[2018-05-12 20:58:59.389343] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 20:58:59.394206] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:58:59.540270] SGDOptimizer > Initial loss [73.01078033447266]\n",
      "\u001b[2K[2018-05-12 21:00:49.212468] SGDOptimizer > Curr loss: 8.012540E+01, n_evals: 999, Avg. time per updt: 0.108297\n",
      "[2018-05-12 21:00:49.239831] SGDOptimizer > Done training. New loss [76.835129] iter: [999]\n",
      "[2018-05-12 21:00:49.241662] apply_controller > Starting run\n",
      "[2018-05-12 21:00:49.242940] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:00:49.411342] apply_controller > Done. Stopping robot. Value of run [29.982616]\n",
      "[2018-05-12 21:00:49.412929] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:00:49.414317] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:00:49.418250] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 21:00:49.419723] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:00:49.433835] target_dyn_opt > Initial loss [-8.576063050706496]\n",
      "\u001b[2K[2018-05-12 21:01:07.398612] target_dyn_opt > Curr loss: -1.022615E+01 [1503: -1.101882E+01], n_evals: 1999, Avg. time per updt: 0.007503\n",
      "[2018-05-12 21:01:07.411679] target_dyn_opt > Done training. New loss [-10.637498] iter: [2000]\n",
      "[2018-05-12 21:01:07.414513] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:01:07.416359] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_23.zip\n",
      "[2018-05-12 21:01:08.481268] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_23.zip\n",
      "[2018-05-12 21:01:08.580484] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_23.zip\n",
      "[2018-05-12 21:01:11.435191] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 21:01:11.440023] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:01:11.588141] SGDOptimizer > Initial loss [86.83418273925781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 21:02:57.038370] SGDOptimizer > Curr loss: 1.110953E+02, n_evals: 999, Avg. time per updt: 0.104143\n",
      "[2018-05-12 21:02:57.066327] SGDOptimizer > Done training. New loss [109.132835] iter: [999]\n",
      "[2018-05-12 21:02:57.068489] apply_controller > Starting run\n",
      "[2018-05-12 21:02:57.069875] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:02:57.260728] apply_controller > Done. Stopping robot. Value of run [28.661507]\n",
      "[2018-05-12 21:02:57.261949] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:02:57.263204] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:02:57.267930] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 21:02:57.269470] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:02:57.284307] target_dyn_opt > Initial loss [-9.025384691131526]\n",
      "\u001b[2K[2018-05-12 21:03:15.225636] target_dyn_opt > Curr loss: -1.077499E+01 [1967: -1.117132E+01], n_evals: 1999, Avg. time per updt: 0.007520\n",
      "[2018-05-12 21:03:15.239337] target_dyn_opt > Done training. New loss [-10.699543] iter: [2000]\n",
      "[2018-05-12 21:03:15.242047] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:03:15.243663] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_24.zip\n",
      "[2018-05-12 21:03:16.350765] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_24.zip\n",
      "[2018-05-12 21:03:16.451196] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_24.zip\n",
      "[2018-05-12 21:03:19.282995] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 21:03:19.288055] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:03:19.425023] SGDOptimizer > Initial loss [95.45222473144531]\n",
      "\u001b[2K[2018-05-12 21:05:04.225784] SGDOptimizer > Curr loss: 5.852072E+01, n_evals: 999, Avg. time per updt: 0.103509\n",
      "[2018-05-12 21:05:04.256141] SGDOptimizer > Done training. New loss [76.083855] iter: [999]\n",
      "[2018-05-12 21:05:04.257902] apply_controller > Starting run\n",
      "[2018-05-12 21:05:04.259191] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:05:04.439316] apply_controller > Done. Stopping robot. Value of run [29.998867]\n",
      "[2018-05-12 21:05:04.440535] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:05:04.442012] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:05:04.446293] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 21:05:04.447669] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:05:04.461661] target_dyn_opt > Initial loss [-5.858701338818598]\n",
      "\u001b[2K[2018-05-12 21:05:22.530707] target_dyn_opt > Curr loss: -1.102693E+01 [1412: -1.137432E+01], n_evals: 1999, Avg. time per updt: 0.007555\n",
      "[2018-05-12 21:05:22.543376] target_dyn_opt > Done training. New loss [-10.956538] iter: [2000]\n",
      "[2018-05-12 21:05:22.545929] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:05:22.547613] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_25.zip\n",
      "[2018-05-12 21:05:23.732695] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_25.zip\n",
      "[2018-05-12 21:05:23.834967] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_25.zip\n",
      "[2018-05-12 21:05:26.704566] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 21:05:26.710175] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:05:26.856851] SGDOptimizer > Initial loss [61.19783401489258]\n",
      "\u001b[2K[2018-05-12 21:07:06.104754] SGDOptimizer > Curr loss: 7.713223E+01, n_evals: 999, Avg. time per updt: 0.097950\n",
      "[2018-05-12 21:07:06.132396] SGDOptimizer > Done training. New loss [72.173195] iter: [999]\n",
      "[2018-05-12 21:07:06.134350] apply_controller > Starting run\n",
      "[2018-05-12 21:07:06.135646] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:07:06.325979] apply_controller > Done. Stopping robot. Value of run [28.123980]\n",
      "[2018-05-12 21:07:06.327191] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:07:06.328509] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:07:06.333487] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 21:07:06.334853] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:07:06.350931] target_dyn_opt > Initial loss [-8.681667634582155]\n",
      "\u001b[2K[2018-05-12 21:07:09.802160] target_dyn_opt > Curr loss: -1.108758E+01 [308: -1.142932E+01], n_evals: 385, Avg. time per updt: 0.007476"
     ]
    }
   ],
   "source": [
    "# experiment 4 learn starting from scratch, using klpq imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_004_il_klpq_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 5 learn starting from source params, using klqp imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_005_il_klqp_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 6 learn starting from source, using klpq imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_006_il_klpq_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 7 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_007_taskplusil_klqp_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 8 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_008_taskplusil_klpq_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 9 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_009_taskplusil_klqp_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 8 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_010_taskplusil_klpq_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
