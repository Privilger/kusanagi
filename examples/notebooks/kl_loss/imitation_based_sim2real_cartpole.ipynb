{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib qt\n",
    "import copy\n",
    "import dill\n",
    "import os\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from kusanagi import utils\n",
    "from kusanagi.base import apply_controller, ExperienceDataset\n",
    "from kusanagi.ghost import control, regression\n",
    "from kusanagi.shell import cartpole, arduino\n",
    "from kusanagi.shell.cost import gaussian_kl_loss, mmd_loss, convert_angle_dimensions\n",
    "from kusanagi.shell.experiment_utils import run_pilco_experiment, setup_mc_pilco_experiment, plot_rollout\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# np.random.seed(1337)\n",
    "np.set_printoptions(linewidth=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "output_dir = utils.get_output_dir()\n",
    "sim2real_output_dir = '/localdata/juan/sim2real_results'\n",
    "\n",
    "\n",
    "params = cartpole.default_params()\n",
    "params['optimizer']['min_method'] = 'adam'\n",
    "params['optimizer']['max_evals'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "params['crn_dropout'] = True\n",
    "params['min_steps'] = 30\n",
    "n_samples = 100                     # number of MC samples for bayesian nn\n",
    "n_demo = 10                          # number of example trajectories\n",
    "pol_adjustment = False\n",
    "\n",
    "H = params['min_steps']\n",
    "gamma = params['discount']\n",
    "angle_dims = params['angle_dims']\n",
    "\n",
    "# initial state distribution\n",
    "p0 = params['state0_dist']\n",
    "D = p0.mean.size\n",
    "\n",
    "dyn_path = os.path.join(output_dir, 'cartpole_kl_loss/dynamics_21')\n",
    "pol_path = os.path.join(output_dir, 'cartpole_kl_loss/policy_21')\n",
    "exp_path = None #os.path.join(output_dir, 'cartpole_kl_loss/experience_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dyn(params, dyn_path=None, copy_params=True):\n",
    "\n",
    "    dyn_spec = dict(\n",
    "        hidden_dims=[200]*2,\n",
    "        p=True, p_input=True,\n",
    "        nonlinearities=regression.nonlinearities.rectify,\n",
    "        W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "        dropout_class=regression.layers.DenseLogNormalDropoutLayer,\n",
    "        build_fn=regression.dropout_mlp)\n",
    "    \n",
    "    if dyn_path is not None:\n",
    "        # load dynamics model\n",
    "        source_dyn = regression.BNN(\n",
    "            filename=dyn_path, name='source_dyn', **params['dynamics_model'])\n",
    "    else:\n",
    "        # init dynamics model\n",
    "        source_dyn = regression.BNN(network_spec=dyn_spec, name='source_dyn', **params['dynamics_model'])\n",
    "        \n",
    "    if copy_params and dyn_path is not None:\n",
    "        target_dyn = regression.BNN(\n",
    "            filename=dyn_path, name='target_dyn', **params['dynamics_model'])\n",
    "    else:\n",
    "        target_dyn = regression.BNN(network_spec=dyn_spec, name='target_dyn', **params['dynamics_model'])\n",
    "\n",
    "    return source_dyn, target_dyn\n",
    "\n",
    "def init_pol(params,  pol_path=None, adjustment=False, copy_params=True):\n",
    "    pol_spec = dict(\n",
    "        hidden_dims=[200]*2,\n",
    "        p=0.1, p_input=0.0,\n",
    "        nonlinearities=regression.nonlinearities.rectify,\n",
    "        W_init=lasagne.init.GlorotNormal(gain='relu'),\n",
    "        dropout_class=regression.layers.DenseDropoutLayer,\n",
    "        build_fn=regression.dropout_mlp)\n",
    "\n",
    "    if pol_path is not None:\n",
    "        # load policy\n",
    "        source_pol = control.NNPolicy(params['dynamics_model']['odims'], filename=pol_path, **params['policy'])\n",
    "    else:\n",
    "        # init policy\n",
    "        source_pol = control.NNPolicy(\n",
    "            params['dynamics_model']['odims'], network_spec=pol_spec, heteroscedastic=False, **params['policy'])\n",
    "    if pol_adjustment:\n",
    "        # init adjustment model\n",
    "        target_pol = control.AdjustedPolicy(\n",
    "            source_pol, maxU=source_pol.maxU, angle_dims=source_pol.angle_dims,\n",
    "            adjustment_model_class=regression.BNN)\n",
    "        target_pol.adjustment_model.trained = True\n",
    "    else:\n",
    "        if copy_params and pol_path is not None:\n",
    "            target_pol = control.NNPolicy(\n",
    "                params['dynamics_model']['odims'], filename=pol_path, **params['policy'])\n",
    "        else:\n",
    "            target_pol = control.NNPolicy(\n",
    "                params['dynamics_model']['odims'], network_spec=pol_spec, heteroscedastic=False, **params['policy'])\n",
    "            \n",
    "    return source_pol, target_pol\n",
    "\n",
    "# init task cost\n",
    "task_cost = partial(cartpole.cartpole_loss, **params['cost'])\n",
    "\n",
    "# init source environment\n",
    "params['source'] = params['plant']\n",
    "params['source']['name'] = 'Cartpole_src'\n",
    "source_env = cartpole.Cartpole(**params['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-14 23:39:54.609339] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-14 23:39:54.624844] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-14 23:39:55.267093] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-14 23:39:55.280389] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-14 23:39:55.404550] Experience > Initialising new experience dataset\n",
      "[2018-05-14 23:39:55.406597] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-14 23:39:55.482727] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-14 23:39:55.729136] NNPolicy > Done compiling\n",
      "[2018-05-14 23:39:55.739449] apply_controller > Starting run\n",
      "[2018-05-14 23:39:55.740777] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:56.299104] apply_controller > Done. Stopping robot. Value of run [8.518587]\n",
      "[2018-05-14 23:39:56.300359] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:56.301881] apply_controller > Starting run\n",
      "[2018-05-14 23:39:56.303413] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:56.712527] apply_controller > Done. Stopping robot. Value of run [8.595913]\n",
      "[2018-05-14 23:39:56.714558] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:56.716106] apply_controller > Starting run\n",
      "[2018-05-14 23:39:56.717477] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:57.110474] apply_controller > Done. Stopping robot. Value of run [8.862134]\n",
      "[2018-05-14 23:39:57.112000] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:57.114833] apply_controller > Starting run\n",
      "[2018-05-14 23:39:57.116217] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:57.444154] apply_controller > Done. Stopping robot. Value of run [7.677794]\n",
      "[2018-05-14 23:39:57.445728] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:57.446908] apply_controller > Starting run\n",
      "[2018-05-14 23:39:57.448918] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:57.835599] apply_controller > Done. Stopping robot. Value of run [8.425447]\n",
      "[2018-05-14 23:39:57.837075] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:57.839042] apply_controller > Starting run\n",
      "[2018-05-14 23:39:57.840315] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:58.164938] apply_controller > Done. Stopping robot. Value of run [7.640776]\n",
      "[2018-05-14 23:39:58.166644] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:58.168274] apply_controller > Starting run\n",
      "[2018-05-14 23:39:58.169599] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:58.586209] apply_controller > Done. Stopping robot. Value of run [7.849203]\n",
      "[2018-05-14 23:39:58.587780] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:58.589386] apply_controller > Starting run\n",
      "[2018-05-14 23:39:58.590624] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:58.985203] apply_controller > Done. Stopping robot. Value of run [7.841958]\n",
      "[2018-05-14 23:39:58.986438] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:58.987993] apply_controller > Starting run\n",
      "[2018-05-14 23:39:58.989274] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:59.386343] apply_controller > Done. Stopping robot. Value of run [9.124444]\n",
      "[2018-05-14 23:39:59.388333] Cartpole_src > Stopping robot\n",
      "[2018-05-14 23:39:59.389912] apply_controller > Starting run\n",
      "[2018-05-14 23:39:59.391218] apply_controller > Running for 3.100000 seconds\n",
      "[2018-05-14 23:39:59.727663] apply_controller > Done. Stopping robot. Value of run [10.283633]\n",
      "[2018-05-14 23:39:59.728897] Cartpole_src > Stopping robot\n"
     ]
    }
   ],
   "source": [
    "# collect example trajectory data on sim environment\n",
    "source_pol = init_pol(params, pol_path)[0]\n",
    "if exp_path is not None:\n",
    "    source_exp = ExperienceDataset(filename=exp_path)\n",
    "else:\n",
    "    source_exp = ExperienceDataset()\n",
    "\n",
    "# init expert trajectory variables\n",
    "n_episodes = source_exp.n_episodes()\n",
    "if n_demo > n_episodes:\n",
    "    # function to execute before applying policy\n",
    "    def gTrig(state):\n",
    "        return utils.gTrig_np(state, angle_dims).flatten()\n",
    "\n",
    "    # function to execute after applying policy\n",
    "    def step_cb(state, action, cost, info, env=None):\n",
    "        env.render()\n",
    "\n",
    "    # apply controller\n",
    "    callback = partial(step_cb, env=source_env)\n",
    "\n",
    "    for i in range(n_demo-n_episodes):\n",
    "        ret = apply_controller(source_env, source_pol, H+1, gTrig, callback)\n",
    "        source_exp.append_episode(*ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source trajectory\n",
    "trajs = np.array(source_exp.states)\n",
    "tr_shape = trajs.shape\n",
    "\n",
    "trajs = utils.gTrig_np(trajs.reshape((tr_shape[0]*tr_shape[1], tr_shape[2])), angle_dims)\n",
    "trajectories = trajs.reshape((tr_shape[0], tr_shape[1], trajs.shape[-1])).astype(theano.config.floatX)\n",
    "\n",
    "traj_mean = trajectories.mean(0)\n",
    "trajc = trajectories[:, :, :, None]\n",
    "trajmm = traj_mean[:, :, None]\n",
    "N = (trajc.shape[0]-1.0)\n",
    "traj_cov = (trajc*trajc.swapaxes(2,3)).sum(0)/N\n",
    "traj_cov -= (trajmm*trajmm.swapaxes(1,2))\n",
    "\n",
    "trajs = theano.shared(trajectories, name='trajs')\n",
    "target_mean = theano.shared(traj_mean, name='target_mean')\n",
    "target_cov = theano.shared(traj_cov, name='target_cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_shared = [trajs, target_mean, target_cov]\n",
    "rollout_fn = None\n",
    "target_exp = None\n",
    "fig = None\n",
    "axarr = None\n",
    "\n",
    "\n",
    "def learning_iteration_cb(exp, dyn, pol, polopt, params, rollout_fn_in):\n",
    "    global rollout_fn\n",
    "    global target_exp\n",
    "    i = exp.curr_episode\n",
    "    # setup output directory\n",
    "    exp.save(None, 'experience_%d' % (i))\n",
    "    pol.save(None, 'policy_%d' % (i))\n",
    "    dyn.save(None, 'dynamics_%d' % (i))\n",
    "    with open(os.path.join(utils.get_output_dir(), 'config.dill'), 'wb') as f:\n",
    "        dill.dump(params, f)\n",
    "    rollout_fn = rollout_fn_in\n",
    "    target_exp = exp\n",
    "\n",
    "counter = 0\n",
    "def minimize_cb(*args, **kwargs):\n",
    "    global fig\n",
    "    global axarr\n",
    "    global counter\n",
    "    if counter % 500 == 0:\n",
    "        p0 = params['state0_dist']\n",
    "        m0, S0 = p0.mean, p0.cov\n",
    "        fig, axarr = plot_rollout(rollout_fn, source_exp, m0, S0, H, 1.0,\n",
    "                                  fig=fig, axarr=axarr, n_exp=n_demo, name='Rollout during optimization')\n",
    "        plt.waitforbuttonpress(0.01)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "# define cost as sum of task cost and deviation form expert demonstration\n",
    "def task_plus_il_cost(t, mx, Sx, weights=[1, 1e-4], loss_type=utils.ImitationLossType.KLQP):\n",
    "    '''\n",
    "        The IL term will penalize rollout predictive distributions that \n",
    "        are too different from the target distribution\n",
    "    '''\n",
    "    mxa, Sxa = convert_angle_dimensions(mx, Sx, angle_dims)\n",
    "    mt, St = target_mean[t], target_cov[t]\n",
    "\n",
    "    if loss_type == utils.ImitationLossType.KLQP:\n",
    "        imitation_loss = gaussian_kl_loss(mxa, Sxa, mt, St)\n",
    "    elif loss_type == utils.ImitationLossType.KLPQ:\n",
    "        imitation_loss = gaussian_kl_loss(mt, St, mxa, Sxa)\n",
    "    elif loss_type == utils.ImitationLossType.KLSYM:\n",
    "        imitation_loss = 0.5*(gaussian_kl_loss(mt, St, mxa, Sxa) + gaussian_kl_loss(mxa, Sxa, mt, St))\n",
    "    elif loss_type == utils.ImitationLossType.MMD:\n",
    "        mmd = mmd_loss(mxa, Sxa, trajs[:, t, :])\n",
    "        imitation_loss = theano.tensor.sqrt(mmd)\n",
    "    return weights[0]*task_cost(mx, Sx)[0] + weights[1]*imitation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['target'] = copy.deepcopy(params['plant'])\n",
    "params['target']['pole_mass'] *= 2\n",
    "params['target']['name'] = 'target_2x_mass'\n",
    "target_env = cartpole.Cartpole(**params['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['target'] = copy.deepcopy(params['plant'])\n",
    "params['target']['pole_length'] *= 2\n",
    "params['target']['name'] = 'target_2x_length'\n",
    "target_env = cartpole.Cartpole(**params['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 15:54:22.429103] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 15:54:22.451849] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 15:54:22.480726] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 15:54:22.493210] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 15:54:22.499046] Experience > Initialising new experience dataset\n",
      "[2018-05-12 15:54:22.500763] Executing uniformly-random controls\n",
      "[2018-05-12 15:54:22.502218] apply_controller > Starting run\n",
      "[2018-05-12 15:54:22.503510] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:54:22.667749] apply_controller > Done. Stopping robot. Value of run [29.996679]\n",
      "[2018-05-12 15:54:22.669485] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:54:22.670841] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:54:22.673648] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 15:54:22.675294] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781690>})\n",
      "[2018-05-12 15:54:22.707433] target_dyn > Initialising loss function\n",
      "[2018-05-12 15:54:22.864353] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 15:54:23.145299] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 15:54:23.146511] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 15:54:23.216382] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 15:54:24.130883] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 15:54:30.560563] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:54:30.570183] target_dyn_opt > Initial loss [6680.729931462471]\n",
      "\u001b[2K[2018-05-12 15:54:40.093248] target_dyn_opt > Curr loss: 6.614115E+01 [1582: 5.576927E+01], n_evals: 1999, Avg. time per updt: 0.003255\n",
      "[2018-05-12 15:54:40.100234] target_dyn_opt > Done training. New loss [61.648689] iter: [2000]\n",
      "[2018-05-12 15:54:40.329352] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:54:40.365362] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8ca9781610>})\n",
      "[2018-05-12 15:54:40.526931] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 15:54:40.528146] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 15:54:40.618289] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 15:54:40.619538] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 15:54:41.087795] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 15:54:41.089035] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 15:54:41.181472] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 15:54:41.183264] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 15:54:46.790113] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 15:54:47.682534] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 15:54:47.692359] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 15:54:47.722888] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 15:54:51.311553] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 15:55:07.834267] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_0.zip\n",
      "[2018-05-12 15:55:07.903521] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_0.zip\n",
      "[2018-05-12 15:55:07.982366] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_0.zip\n",
      "[2018-05-12 15:55:08.090997] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 15:55:08.092789] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 15:55:08.097873] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:55:08.239651] SGDOptimizer > Initial loss [0.996991753578186]\n",
      "\u001b[2K[2018-05-12 15:56:33.102718] SGDOptimizer > Curr loss: 8.589609E-01, n_evals: 999, Avg. time per updt: 0.083514\n",
      "[2018-05-12 15:56:33.129142] SGDOptimizer > Done training. New loss [0.910608] iter: [999]\n",
      "[2018-05-12 15:56:33.131208] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 15:56:33.210818] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 15:56:33.364007] NNPolicy > Done compiling\n",
      "[2018-05-12 15:56:33.365593] apply_controller > Starting run\n",
      "[2018-05-12 15:56:33.368855] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:56:33.577236] apply_controller > Done. Stopping robot. Value of run [29.406206]\n",
      "[2018-05-12 15:56:33.578505] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:56:33.579738] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:56:33.582315] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 15:56:33.583698] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 15:56:33.598963] target_dyn_opt > Initial loss [196.87817812073425]\n",
      "\u001b[2K[2018-05-12 15:56:46.483913] target_dyn_opt > Curr loss: 2.487258E+01 [1720: 2.168714E+01], n_evals: 1999, Avg. time per updt: 0.004921\n",
      "[2018-05-12 15:56:46.492488] target_dyn_opt > Done training. New loss [23.101507] iter: [2000]\n",
      "[2018-05-12 15:56:46.495014] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:56:46.496376] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_1.zip\n",
      "[2018-05-12 15:56:46.613623] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_1.zip\n",
      "[2018-05-12 15:56:46.689021] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_1.zip\n",
      "[2018-05-12 15:56:48.088281] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 15:56:48.093368] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:56:48.199887] SGDOptimizer > Initial loss [0.9666119813919067]\n",
      "\u001b[2K[2018-05-12 15:58:12.793353] SGDOptimizer > Curr loss: 8.108242E-01, n_evals: 999, Avg. time per updt: 0.083266\n",
      "[2018-05-12 15:58:12.821772] SGDOptimizer > Done training. New loss [0.816964] iter: [999]\n",
      "[2018-05-12 15:58:12.823729] apply_controller > Starting run\n",
      "[2018-05-12 15:58:12.824903] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:58:13.052633] apply_controller > Done. Stopping robot. Value of run [26.188398]\n",
      "[2018-05-12 15:58:13.053845] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:58:13.055404] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:58:13.057702] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 15:58:13.059097] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:58:13.071762] target_dyn_opt > Initial loss [28.16285134718657]\n",
      "\u001b[2K[2018-05-12 15:58:29.390715] target_dyn_opt > Curr loss: 1.268149E+01 [1843: 1.088499E+01], n_evals: 1999, Avg. time per updt: 0.006636\n",
      "[2018-05-12 15:58:29.404673] target_dyn_opt > Done training. New loss [11.506210] iter: [2000]\n",
      "[2018-05-12 15:58:29.407450] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 15:58:29.408803] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_2.zip\n",
      "[2018-05-12 15:58:29.567255] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_2.zip\n",
      "[2018-05-12 15:58:29.641351] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_2.zip\n",
      "[2018-05-12 15:58:31.310925] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 15:58:31.316038] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 15:58:31.422628] SGDOptimizer > Initial loss [0.9062098264694214]\n",
      "\u001b[2K[2018-05-12 15:59:57.894523] SGDOptimizer > Curr loss: 8.198906E-01, n_evals: 999, Avg. time per updt: 0.085126\n",
      "[2018-05-12 15:59:57.917962] SGDOptimizer > Done training. New loss [0.816083] iter: [999]\n",
      "[2018-05-12 15:59:57.920037] apply_controller > Starting run\n",
      "[2018-05-12 15:59:57.921298] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 15:59:58.101218] apply_controller > Done. Stopping robot. Value of run [25.714014]\n",
      "[2018-05-12 15:59:58.102815] target_2x_mass > Stopping robot\n",
      "[2018-05-12 15:59:58.104101] train_dynamics > Training dynamics model\n",
      "[2018-05-12 15:59:58.107067] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 15:59:58.108327] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 15:59:58.123630] target_dyn_opt > Initial loss [14.526789581685142]\n",
      "\u001b[2K[2018-05-12 16:00:15.858973] target_dyn_opt > Curr loss: 6.003786E+00 [1897: 5.110294E+00], n_evals: 1999, Avg. time per updt: 0.007335\n",
      "[2018-05-12 16:00:15.871927] target_dyn_opt > Done training. New loss [5.697748] iter: [2000]\n",
      "[2018-05-12 16:00:15.874535] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:00:15.875918] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_3.zip\n",
      "[2018-05-12 16:00:16.081283] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_3.zip\n",
      "[2018-05-12 16:00:16.156858] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_3.zip\n",
      "[2018-05-12 16:00:17.844487] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 16:00:17.850016] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:00:17.960042] SGDOptimizer > Initial loss [0.9002598524093628]\n",
      "\u001b[2K[2018-05-12 16:01:46.136104] SGDOptimizer > Curr loss: 8.457360E-01, n_evals: 999, Avg. time per updt: 0.086852\n",
      "[2018-05-12 16:01:46.158964] SGDOptimizer > Done training. New loss [0.845662] iter: [999]\n",
      "[2018-05-12 16:01:46.160661] apply_controller > Starting run\n",
      "[2018-05-12 16:01:46.161979] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:01:46.377873] apply_controller > Done. Stopping robot. Value of run [24.415106]\n",
      "[2018-05-12 16:01:46.380399] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:01:46.381787] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:01:46.384781] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 16:01:46.386300] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:01:46.403138] target_dyn_opt > Initial loss [18.001908555011873]\n",
      "\u001b[2K[2018-05-12 16:02:04.619841] target_dyn_opt > Curr loss: 2.175640E+00 [1945: 1.684306E+00], n_evals: 1999, Avg. time per updt: 0.007544\n",
      "[2018-05-12 16:02:04.633090] target_dyn_opt > Done training. New loss [2.177034] iter: [2000]\n",
      "[2018-05-12 16:02:04.635776] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:02:04.637179] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_4.zip\n",
      "[2018-05-12 16:02:04.909643] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_4.zip\n",
      "[2018-05-12 16:02:04.984933] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_4.zip\n",
      "[2018-05-12 16:02:06.699086] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 16:02:06.704070] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:02:06.816811] SGDOptimizer > Initial loss [0.9224860668182373]\n",
      "\u001b[2K[2018-05-12 16:03:33.813123] SGDOptimizer > Curr loss: 7.669514E-01, n_evals: 999, Avg. time per updt: 0.085638\n",
      "[2018-05-12 16:03:33.834641] SGDOptimizer > Done training. New loss [0.738872] iter: [999]\n",
      "[2018-05-12 16:03:33.836273] apply_controller > Starting run\n",
      "[2018-05-12 16:03:33.837595] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:03:34.024990] apply_controller > Done. Stopping robot. Value of run [24.237082]\n",
      "[2018-05-12 16:03:34.026519] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:03:34.027877] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:03:34.030151] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 16:03:34.031730] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:03:34.045748] target_dyn_opt > Initial loss [2.850281277623285]\n",
      "\u001b[2K[2018-05-12 16:03:51.892236] target_dyn_opt > Curr loss: -2.799526E-01 [1972: -7.647247E-01], n_evals: 1999, Avg. time per updt: 0.007366\n",
      "[2018-05-12 16:03:51.904489] target_dyn_opt > Done training. New loss [-0.221255] iter: [2000]\n",
      "[2018-05-12 16:03:51.907271] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:03:51.908596] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_5.zip\n",
      "[2018-05-12 16:03:52.206777] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_5.zip\n",
      "[2018-05-12 16:03:52.283388] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_5.zip\n",
      "[2018-05-12 16:03:55.292070] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 16:03:55.297525] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:03:55.415911] SGDOptimizer > Initial loss [0.8053287267684937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 16:05:21.333019] SGDOptimizer > Curr loss: 6.946740E-01, n_evals: 999, Avg. time per updt: 0.084595\n",
      "[2018-05-12 16:05:21.356317] SGDOptimizer > Done training. New loss [0.714920] iter: [999]\n",
      "[2018-05-12 16:05:21.358078] apply_controller > Starting run\n",
      "[2018-05-12 16:05:21.359390] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:05:21.582548] apply_controller > Done. Stopping robot. Value of run [22.796093]\n",
      "[2018-05-12 16:05:21.584227] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:05:21.585468] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:05:21.588266] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 16:05:21.589721] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:05:21.603583] target_dyn_opt > Initial loss [3.0791926721473377]\n",
      "\u001b[2K[2018-05-12 16:05:39.782419] target_dyn_opt > Curr loss: -2.215102E+00 [1806: -2.733445E+00], n_evals: 1999, Avg. time per updt: 0.007560\n",
      "[2018-05-12 16:05:39.795991] target_dyn_opt > Done training. New loss [-2.365056] iter: [2000]\n",
      "[2018-05-12 16:05:39.799409] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:05:39.800821] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_6.zip\n",
      "[2018-05-12 16:05:40.137386] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_6.zip\n",
      "[2018-05-12 16:05:40.215434] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_6.zip\n",
      "[2018-05-12 16:05:41.900141] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 16:05:41.905422] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:05:42.014940] SGDOptimizer > Initial loss [0.9103012681007385]\n",
      "\u001b[2K[2018-05-12 16:07:07.219015] SGDOptimizer > Curr loss: 5.426455E-01, n_evals: 999, Avg. time per updt: 0.083865\n",
      "[2018-05-12 16:07:07.242964] SGDOptimizer > Done training. New loss [0.527927] iter: [999]\n",
      "[2018-05-12 16:07:07.244924] apply_controller > Starting run\n",
      "[2018-05-12 16:07:07.246274] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:07:07.467814] apply_controller > Done. Stopping robot. Value of run [14.235567]\n",
      "[2018-05-12 16:07:07.469228] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:07:07.470482] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:07:07.473732] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 16:07:07.475050] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:07:07.494418] target_dyn_opt > Initial loss [0.8324918304590092]\n",
      "\u001b[2K[2018-05-12 16:07:25.766572] target_dyn_opt > Curr loss: -3.936918E+00 [1981: -4.171124E+00], n_evals: 1999, Avg. time per updt: 0.007611\n",
      "[2018-05-12 16:07:25.779595] target_dyn_opt > Done training. New loss [-3.571067] iter: [2000]\n",
      "[2018-05-12 16:07:25.782400] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:07:25.783955] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_7.zip\n",
      "[2018-05-12 16:07:26.167292] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_7.zip\n",
      "[2018-05-12 16:07:26.246468] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_7.zip\n",
      "[2018-05-12 16:07:27.939763] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 16:07:27.945381] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:07:28.058361] SGDOptimizer > Initial loss [0.6074377298355103]\n",
      "\u001b[2K[2018-05-12 16:08:53.009261] SGDOptimizer > Curr loss: 5.067383E-01, n_evals: 999, Avg. time per updt: 0.083632\n",
      "[2018-05-12 16:08:53.032318] SGDOptimizer > Done training. New loss [0.536229] iter: [999]\n",
      "[2018-05-12 16:08:53.033999] apply_controller > Starting run\n",
      "[2018-05-12 16:08:53.035326] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:08:53.224607] apply_controller > Done. Stopping robot. Value of run [17.202480]\n",
      "[2018-05-12 16:08:53.226085] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:08:53.227562] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:08:53.230699] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 16:08:53.231977] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:08:53.247516] target_dyn_opt > Initial loss [-2.979046790289668]\n",
      "\u001b[2K[2018-05-12 16:09:11.641490] target_dyn_opt > Curr loss: -4.637620E+00 [1668: -5.299921E+00], n_evals: 1999, Avg. time per updt: 0.007666\n",
      "[2018-05-12 16:09:11.656955] target_dyn_opt > Done training. New loss [-4.776088] iter: [2000]\n",
      "[2018-05-12 16:09:11.659604] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:09:11.660937] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_8.zip\n",
      "[2018-05-12 16:09:12.110165] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_8.zip\n",
      "[2018-05-12 16:09:12.189705] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_8.zip\n",
      "[2018-05-12 16:09:13.892991] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 16:09:13.898110] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:09:14.019104] SGDOptimizer > Initial loss [0.7862829566001892]\n",
      "\u001b[2K[2018-05-12 16:10:39.307868] SGDOptimizer > Curr loss: 5.205716E-01, n_evals: 999, Avg. time per updt: 0.083955\n",
      "[2018-05-12 16:10:39.330913] SGDOptimizer > Done training. New loss [0.494929] iter: [999]\n",
      "[2018-05-12 16:10:39.332585] apply_controller > Starting run\n",
      "[2018-05-12 16:10:39.334136] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:10:39.515652] apply_controller > Done. Stopping robot. Value of run [14.324215]\n",
      "[2018-05-12 16:10:39.517031] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:10:39.518409] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:10:39.521550] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 16:10:39.523399] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:10:39.537319] target_dyn_opt > Initial loss [-4.3257115140878435]\n",
      "\u001b[2K[2018-05-12 16:10:57.611454] target_dyn_opt > Curr loss: -5.389552E+00 [1952: -6.511031E+00], n_evals: 1999, Avg. time per updt: 0.007496\n",
      "[2018-05-12 16:10:57.625496] target_dyn_opt > Done training. New loss [-5.978143] iter: [2000]\n",
      "[2018-05-12 16:10:57.628410] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:10:57.630124] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_9.zip\n",
      "[2018-05-12 16:10:58.121366] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_9.zip\n",
      "[2018-05-12 16:10:58.204587] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_9.zip\n",
      "[2018-05-12 16:10:59.959787] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 16:10:59.964743] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:11:00.087675] SGDOptimizer > Initial loss [0.8145965933799744]\n",
      "\u001b[2K[2018-05-12 16:12:27.113606] SGDOptimizer > Curr loss: 5.435282E-01, n_evals: 999, Avg. time per updt: 0.085674\n",
      "[2018-05-12 16:12:27.140677] SGDOptimizer > Done training. New loss [0.552734] iter: [999]\n",
      "[2018-05-12 16:12:27.142731] apply_controller > Starting run\n",
      "[2018-05-12 16:12:27.143950] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:12:27.358839] apply_controller > Done. Stopping robot. Value of run [15.382326]\n",
      "[2018-05-12 16:12:27.360055] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:12:27.361390] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:12:27.364712] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 16:12:27.366158] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:12:27.383377] target_dyn_opt > Initial loss [-5.310978428726333]\n",
      "\u001b[2K[2018-05-12 16:12:45.447432] target_dyn_opt > Curr loss: -6.583827E+00 [1887: -7.109356E+00], n_evals: 1999, Avg. time per updt: 0.007503\n",
      "[2018-05-12 16:12:45.462921] target_dyn_opt > Done training. New loss [-6.602919] iter: [2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:12:45.465630] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:12:45.467167] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_10.zip\n",
      "[2018-05-12 16:12:46.000982] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_10.zip\n",
      "[2018-05-12 16:12:46.085452] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_10.zip\n",
      "[2018-05-12 16:12:47.950014] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 16:12:47.955059] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:12:48.087515] SGDOptimizer > Initial loss [0.5894615650177002]\n",
      "\u001b[2K[2018-05-12 16:14:14.796930] SGDOptimizer > Curr loss: 4.647201E-01, n_evals: 999, Avg. time per updt: 0.085369\n",
      "[2018-05-12 16:14:14.820512] SGDOptimizer > Done training. New loss [0.461924] iter: [999]\n",
      "[2018-05-12 16:14:14.822207] apply_controller > Starting run\n",
      "[2018-05-12 16:14:14.823692] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:14:15.009753] apply_controller > Done. Stopping robot. Value of run [15.191338]\n",
      "[2018-05-12 16:14:15.011363] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:14:15.012415] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:14:15.015647] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 16:14:15.017055] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:14:15.033146] target_dyn_opt > Initial loss [-6.28331089201758]\n",
      "\u001b[2K[2018-05-12 16:14:33.115095] target_dyn_opt > Curr loss: -7.046298E+00 [1775: -7.853820E+00], n_evals: 1999, Avg. time per updt: 0.007523\n",
      "[2018-05-12 16:14:33.130554] target_dyn_opt > Done training. New loss [-7.340509] iter: [2000]\n",
      "[2018-05-12 16:14:33.134117] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:14:33.135909] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_11.zip\n",
      "[2018-05-12 16:14:33.794483] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_11.zip\n",
      "[2018-05-12 16:14:33.880834] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_11.zip\n",
      "[2018-05-12 16:14:35.708806] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 16:14:35.714188] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:14:35.835405] SGDOptimizer > Initial loss [0.583663284778595]\n",
      "\u001b[2K[2018-05-12 16:16:05.106724] SGDOptimizer > Curr loss: 4.449430E-01, n_evals: 999, Avg. time per updt: 0.087933\n",
      "[2018-05-12 16:16:05.131215] SGDOptimizer > Done training. New loss [0.446292] iter: [999]\n",
      "[2018-05-12 16:16:05.132886] apply_controller > Starting run\n",
      "[2018-05-12 16:16:05.134082] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:16:05.320866] apply_controller > Done. Stopping robot. Value of run [13.530364]\n",
      "[2018-05-12 16:16:05.322491] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:16:05.323890] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:16:05.327222] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 16:16:05.328704] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:16:05.344919] target_dyn_opt > Initial loss [-6.539858841018589]\n",
      "\u001b[2K[2018-05-12 16:16:23.641966] target_dyn_opt > Curr loss: -7.957913E+00 [1788: -8.391265E+00], n_evals: 1999, Avg. time per updt: 0.007617\n",
      "[2018-05-12 16:16:23.655599] target_dyn_opt > Done training. New loss [-7.957363] iter: [2000]\n",
      "[2018-05-12 16:16:23.658238] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:16:23.659568] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_12.zip\n",
      "[2018-05-12 16:16:24.280140] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_12.zip\n",
      "[2018-05-12 16:16:24.360777] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_12.zip\n",
      "[2018-05-12 16:16:26.174709] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 16:16:26.180167] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:16:26.299221] SGDOptimizer > Initial loss [0.7275120615959167]\n",
      "\u001b[2K[2018-05-12 16:17:52.492495] SGDOptimizer > Curr loss: 4.513001E-01, n_evals: 999, Avg. time per updt: 0.084861\n",
      "[2018-05-12 16:17:52.515102] SGDOptimizer > Done training. New loss [0.451197] iter: [999]\n",
      "[2018-05-12 16:17:52.517209] apply_controller > Starting run\n",
      "[2018-05-12 16:17:52.518593] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:17:52.703460] apply_controller > Done. Stopping robot. Value of run [12.671826]\n",
      "[2018-05-12 16:17:52.704789] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:17:52.706374] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:17:52.710454] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 16:17:52.711713] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:17:52.725990] target_dyn_opt > Initial loss [-6.913726246470741]\n",
      "\u001b[2K[2018-05-12 16:18:10.717859] target_dyn_opt > Curr loss: -8.072589E+00 [1926: -8.970943E+00], n_evals: 1999, Avg. time per updt: 0.007490\n",
      "[2018-05-12 16:18:10.733067] target_dyn_opt > Done training. New loss [-8.154395] iter: [2000]\n",
      "[2018-05-12 16:18:10.735925] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:18:10.737361] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_13.zip\n",
      "[2018-05-12 16:18:11.385973] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_13.zip\n",
      "[2018-05-12 16:18:11.465130] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_13.zip\n",
      "[2018-05-12 16:18:13.191879] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 16:18:13.197284] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:18:13.313797] SGDOptimizer > Initial loss [0.8377482295036316]\n",
      "\u001b[2K[2018-05-12 16:19:40.451774] SGDOptimizer > Curr loss: 4.433659E-01, n_evals: 999, Avg. time per updt: 0.085809\n",
      "[2018-05-12 16:19:40.483077] SGDOptimizer > Done training. New loss [0.549982] iter: [999]\n",
      "[2018-05-12 16:19:40.485161] apply_controller > Starting run\n",
      "[2018-05-12 16:19:40.486624] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:19:40.662366] apply_controller > Done. Stopping robot. Value of run [11.986037]\n",
      "[2018-05-12 16:19:40.663700] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:19:40.664683] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:19:40.668538] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 16:19:40.670198] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:19:40.684557] target_dyn_opt > Initial loss [-8.018091110182905]\n",
      "\u001b[2K[2018-05-12 16:20:00.680799] target_dyn_opt > Curr loss: -8.750321E+00 [1814: -9.396071E+00], n_evals: 1999, Avg. time per updt: 0.008462\n",
      "[2018-05-12 16:20:00.704877] target_dyn_opt > Done training. New loss [-8.804405] iter: [2000]\n",
      "[2018-05-12 16:20:00.710294] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:20:00.711811] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_14.zip\n",
      "[2018-05-12 16:20:01.662609] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_14.zip\n",
      "[2018-05-12 16:20:01.753061] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_14.zip\n",
      "[2018-05-12 16:20:03.645135] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 16:20:03.650119] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:20:03.762546] SGDOptimizer > Initial loss [0.7987380623817444]\n",
      "\u001b[2K[2018-05-12 16:21:33.162697] SGDOptimizer > Curr loss: 4.346551E-01, n_evals: 999, Avg. time per updt: 0.088072\n",
      "[2018-05-12 16:21:33.191266] SGDOptimizer > Done training. New loss [0.432401] iter: [999]\n",
      "[2018-05-12 16:21:33.193352] apply_controller > Starting run\n",
      "[2018-05-12 16:21:33.194610] apply_controller > Running for 3.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:21:33.370308] apply_controller > Done. Stopping robot. Value of run [23.538347]\n",
      "[2018-05-12 16:21:33.371786] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:21:33.373087] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:21:33.376251] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 16:21:33.377630] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:21:33.392611] target_dyn_opt > Initial loss [-6.725470505590582]\n",
      "\u001b[2K[2018-05-12 16:21:55.476629] target_dyn_opt > Curr loss: -9.423353E+00 [1672: -9.679023E+00], n_evals: 1999, Avg. time per updt: 0.009358\n",
      "[2018-05-12 16:21:55.489449] target_dyn_opt > Done training. New loss [-9.322177] iter: [2000]\n",
      "[2018-05-12 16:21:55.491991] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:21:55.493929] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_15.zip\n",
      "[2018-05-12 16:21:56.224672] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_15.zip\n",
      "[2018-05-12 16:21:56.302211] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_15.zip\n",
      "[2018-05-12 16:21:58.010822] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 16:21:58.016491] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:21:58.136582] SGDOptimizer > Initial loss [0.4488633871078491]\n",
      "\u001b[2K[2018-05-12 16:23:29.074788] SGDOptimizer > Curr loss: 4.151183E-01, n_evals: 999, Avg. time per updt: 0.089571\n",
      "[2018-05-12 16:23:29.105559] SGDOptimizer > Done training. New loss [0.414394] iter: [999]\n",
      "[2018-05-12 16:23:29.107324] apply_controller > Starting run\n",
      "[2018-05-12 16:23:29.108797] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:23:29.291502] apply_controller > Done. Stopping robot. Value of run [21.323595]\n",
      "[2018-05-12 16:23:29.292883] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:23:29.294155] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:23:29.297612] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 16:23:29.298924] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:23:29.315539] target_dyn_opt > Initial loss [-6.938327069245052]\n",
      "\u001b[2K[2018-05-12 16:23:47.380066] target_dyn_opt > Curr loss: -9.664986E+00 [1782: -1.002174E+01], n_evals: 1999, Avg. time per updt: 0.007522\n",
      "[2018-05-12 16:23:47.393293] target_dyn_opt > Done training. New loss [-9.364713] iter: [2000]\n",
      "[2018-05-12 16:23:47.396232] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:23:47.397719] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_16.zip\n",
      "[2018-05-12 16:23:48.175456] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_16.zip\n",
      "[2018-05-12 16:23:48.255600] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_16.zip\n",
      "[2018-05-12 16:23:49.990658] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 16:23:49.996114] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:23:50.120891] SGDOptimizer > Initial loss [0.6435902118682861]\n",
      "\u001b[2K[2018-05-12 16:25:19.461742] SGDOptimizer > Curr loss: 4.130366E-01, n_evals: 999, Avg. time per updt: 0.087989\n",
      "[2018-05-12 16:25:19.488698] SGDOptimizer > Done training. New loss [0.413840] iter: [999]\n",
      "[2018-05-12 16:25:19.490278] apply_controller > Starting run\n",
      "[2018-05-12 16:25:19.491561] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:25:19.672965] apply_controller > Done. Stopping robot. Value of run [13.039907]\n",
      "[2018-05-12 16:25:19.674663] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:25:19.675970] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:25:19.681322] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 16:25:19.682859] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:25:19.699565] target_dyn_opt > Initial loss [-8.446266184621615]\n",
      "\u001b[2K[2018-05-12 16:25:38.114046] target_dyn_opt > Curr loss: -9.881607E+00 [1152: -1.036036E+01], n_evals: 1999, Avg. time per updt: 0.007689\n",
      "[2018-05-12 16:25:38.126975] target_dyn_opt > Done training. New loss [-9.942652] iter: [2000]\n",
      "[2018-05-12 16:25:38.129763] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:25:38.131692] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_17.zip\n",
      "[2018-05-12 16:25:38.957410] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_17.zip\n",
      "[2018-05-12 16:25:39.039252] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_17.zip\n",
      "[2018-05-12 16:25:40.777230] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 16:25:40.782403] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:25:40.900957] SGDOptimizer > Initial loss [0.6621149778366089]\n",
      "\u001b[2K[2018-05-12 16:27:10.045658] SGDOptimizer > Curr loss: 4.123432E-01, n_evals: 999, Avg. time per updt: 0.087797\n",
      "[2018-05-12 16:27:10.076768] SGDOptimizer > Done training. New loss [0.914717] iter: [999]\n",
      "[2018-05-12 16:27:10.078579] apply_controller > Starting run\n",
      "[2018-05-12 16:27:10.079758] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:27:10.328471] apply_controller > Done. Stopping robot. Value of run [11.824644]\n",
      "[2018-05-12 16:27:10.329711] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:27:10.331191] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:27:10.335140] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 16:27:10.336946] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:27:10.352619] target_dyn_opt > Initial loss [-8.886890855004264]\n",
      "\u001b[2K[2018-05-12 16:27:28.738145] target_dyn_opt > Curr loss: -1.009981E+01 [1738: -1.075862E+01], n_evals: 1999, Avg. time per updt: 0.007683\n",
      "[2018-05-12 16:27:28.751867] target_dyn_opt > Done training. New loss [-10.416551] iter: [2000]\n",
      "[2018-05-12 16:27:28.754625] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:27:28.756119] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_18.zip\n",
      "[2018-05-12 16:27:29.644807] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_18.zip\n",
      "[2018-05-12 16:27:29.728197] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_18.zip\n",
      "[2018-05-12 16:27:31.479889] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 16:27:31.484940] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:27:31.598514] SGDOptimizer > Initial loss [0.9239051342010498]\n",
      "\u001b[2K[2018-05-12 16:29:02.011055] SGDOptimizer > Curr loss: 4.042665E-01, n_evals: 999, Avg. time per updt: 0.089089\n",
      "[2018-05-12 16:29:02.039721] SGDOptimizer > Done training. New loss [0.404029] iter: [999]\n",
      "[2018-05-12 16:29:02.041820] apply_controller > Starting run\n",
      "[2018-05-12 16:29:02.043096] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:29:02.244211] apply_controller > Done. Stopping robot. Value of run [12.204680]\n",
      "[2018-05-12 16:29:02.245809] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:29:02.246499] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:29:02.250088] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 16:29:02.251363] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:29:02.266598] target_dyn_opt > Initial loss [-9.130418600964134]\n",
      "\u001b[2K[2018-05-12 16:29:20.897445] target_dyn_opt > Curr loss: -1.045332E+01 [1767: -1.103362E+01], n_evals: 1999, Avg. time per updt: 0.007748\n",
      "[2018-05-12 16:29:20.910325] target_dyn_opt > Done training. New loss [-10.775248] iter: [2000]\n",
      "[2018-05-12 16:29:20.912863] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:29:20.914260] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_19.zip\n",
      "[2018-05-12 16:29:21.833713] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_19.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:29:21.915939] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_19.zip\n",
      "[2018-05-12 16:29:23.690466] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 16:29:23.695736] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:29:23.814728] SGDOptimizer > Initial loss [0.6612314581871033]\n",
      "\u001b[2K[2018-05-12 16:30:53.828263] SGDOptimizer > Curr loss: 4.069581E-01, n_evals: 999, Avg. time per updt: 0.088693\n",
      "[2018-05-12 16:30:53.853326] SGDOptimizer > Done training. New loss [0.403314] iter: [999]\n",
      "[2018-05-12 16:30:53.855186] apply_controller > Starting run\n",
      "[2018-05-12 16:30:53.856561] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:30:54.031195] apply_controller > Done. Stopping robot. Value of run [12.916805]\n",
      "[2018-05-12 16:30:54.032896] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:30:54.034244] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:30:54.038782] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 16:30:54.040448] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:30:54.054396] target_dyn_opt > Initial loss [-9.561625983278544]\n",
      "\u001b[2K[2018-05-12 16:31:13.065832] target_dyn_opt > Curr loss: -1.077188E+01 [1186: -1.131254E+01], n_evals: 1999, Avg. time per updt: 0.008006\n",
      "[2018-05-12 16:31:13.081301] target_dyn_opt > Done training. New loss [-10.891156] iter: [2000]\n",
      "[2018-05-12 16:31:13.084055] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:31:13.085870] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_20.zip\n",
      "[2018-05-12 16:31:14.082485] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_20.zip\n",
      "[2018-05-12 16:31:14.165046] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_20.zip\n",
      "[2018-05-12 16:31:15.903644] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 16:31:15.909271] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:31:16.026849] SGDOptimizer > Initial loss [0.5692761540412903]\n",
      "\u001b[2K[2018-05-12 16:32:48.480549] SGDOptimizer > Curr loss: 3.958789E-01, n_evals: 999, Avg. time per updt: 0.091111\n",
      "[2018-05-12 16:32:48.506534] SGDOptimizer > Done training. New loss [0.396587] iter: [999]\n",
      "[2018-05-12 16:32:48.508324] apply_controller > Starting run\n",
      "[2018-05-12 16:32:48.509541] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:32:48.689465] apply_controller > Done. Stopping robot. Value of run [11.502531]\n",
      "[2018-05-12 16:32:48.690716] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:32:48.692243] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:32:48.696182] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 16:32:48.697554] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:32:48.711728] target_dyn_opt > Initial loss [-9.53167524779665]\n",
      "\u001b[2K[2018-05-12 16:33:07.281576] target_dyn_opt > Curr loss: -1.119185E+01 [1237: -1.152511E+01], n_evals: 1999, Avg. time per updt: 0.007720\n",
      "[2018-05-12 16:33:07.296939] target_dyn_opt > Done training. New loss [-10.933733] iter: [2000]\n",
      "[2018-05-12 16:33:07.299542] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:33:07.300992] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_21.zip\n",
      "[2018-05-12 16:33:08.351429] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_21.zip\n",
      "[2018-05-12 16:33:08.438524] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_21.zip\n",
      "[2018-05-12 16:33:10.198286] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 16:33:10.203770] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:33:10.338858] SGDOptimizer > Initial loss [0.7624673247337341]\n",
      "\u001b[2K[2018-05-12 16:34:40.873973] SGDOptimizer > Curr loss: 4.132390E-01, n_evals: 999, Avg. time per updt: 0.089215\n",
      "[2018-05-12 16:34:40.900200] SGDOptimizer > Done training. New loss [0.394949] iter: [999]\n",
      "[2018-05-12 16:34:40.902597] apply_controller > Starting run\n",
      "[2018-05-12 16:34:40.903855] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:34:41.081053] apply_controller > Done. Stopping robot. Value of run [11.550950]\n",
      "[2018-05-12 16:34:41.082396] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:34:41.083914] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:34:41.089262] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 16:34:41.090591] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:34:41.108567] target_dyn_opt > Initial loss [-9.863526495902434]\n",
      "\u001b[2K[2018-05-12 16:34:59.525628] target_dyn_opt > Curr loss: -1.120978E+01 [1781: -1.170081E+01], n_evals: 1999, Avg. time per updt: 0.007653\n",
      "[2018-05-12 16:34:59.539516] target_dyn_opt > Done training. New loss [-11.338870] iter: [2000]\n",
      "[2018-05-12 16:34:59.542293] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:34:59.543716] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_22.zip\n",
      "[2018-05-12 16:35:00.591636] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_22.zip\n",
      "[2018-05-12 16:35:00.671632] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_22.zip\n",
      "[2018-05-12 16:35:02.428546] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 16:35:02.434342] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:35:02.553323] SGDOptimizer > Initial loss [0.8416908979415894]\n",
      "\u001b[2K[2018-05-12 16:36:36.302705] SGDOptimizer > Curr loss: 4.071636E-01, n_evals: 999, Avg. time per updt: 0.092430\n",
      "[2018-05-12 16:36:36.327050] SGDOptimizer > Done training. New loss [0.411444] iter: [999]\n",
      "[2018-05-12 16:36:36.328924] apply_controller > Starting run\n",
      "[2018-05-12 16:36:36.330307] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:36:36.504938] apply_controller > Done. Stopping robot. Value of run [12.853815]\n",
      "[2018-05-12 16:36:36.506156] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:36:36.507693] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:36:36.512044] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 16:36:36.513471] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:36:36.529241] target_dyn_opt > Initial loss [-10.042172753262793]\n",
      "\u001b[2K[2018-05-12 16:36:55.180123] target_dyn_opt > Curr loss: -1.151457E+01 [1732: -1.188537E+01], n_evals: 1999, Avg. time per updt: 0.007783\n",
      "[2018-05-12 16:36:55.193493] target_dyn_opt > Done training. New loss [-11.622420] iter: [2000]\n",
      "[2018-05-12 16:36:55.196611] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:36:55.198137] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_23.zip\n",
      "[2018-05-12 16:36:56.286645] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_23.zip\n",
      "[2018-05-12 16:36:56.367606] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_23.zip\n",
      "[2018-05-12 16:36:58.111703] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 16:36:58.116779] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:36:58.246142] SGDOptimizer > Initial loss [0.7352240681648254]\n",
      "\u001b[2K[2018-05-12 16:38:31.880100] SGDOptimizer > Curr loss: 3.953906E-01, n_evals: 999, Avg. time per updt: 0.092278\n",
      "[2018-05-12 16:38:31.905850] SGDOptimizer > Done training. New loss [0.396038] iter: [999]\n",
      "[2018-05-12 16:38:31.908036] apply_controller > Starting run\n",
      "[2018-05-12 16:38:31.909392] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:38:32.084291] apply_controller > Done. Stopping robot. Value of run [12.880498]\n",
      "[2018-05-12 16:38:32.085618] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:38:32.087253] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:38:32.092390] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:38:32.093783] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:38:32.108932] target_dyn_opt > Initial loss [-10.190879085063933]\n",
      "\u001b[2K[2018-05-12 16:38:50.328376] target_dyn_opt > Curr loss: -1.164239E+01 [1642: -1.206825E+01], n_evals: 1999, Avg. time per updt: 0.007624\n",
      "[2018-05-12 16:38:50.341468] target_dyn_opt > Done training. New loss [-11.568586] iter: [2000]\n",
      "[2018-05-12 16:38:50.344299] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:38:50.350676] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_24.zip\n",
      "[2018-05-12 16:38:51.478282] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_24.zip\n",
      "[2018-05-12 16:38:51.560647] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_24.zip\n",
      "[2018-05-12 16:38:53.318351] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 16:38:53.323465] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:38:53.443430] SGDOptimizer > Initial loss [0.45506635308265686]\n",
      "\u001b[2K[2018-05-12 16:40:29.162289] SGDOptimizer > Curr loss: 3.982220E-01, n_evals: 999, Avg. time per updt: 0.094378\n",
      "[2018-05-12 16:40:29.189837] SGDOptimizer > Done training. New loss [0.398812] iter: [999]\n",
      "[2018-05-12 16:40:29.191888] apply_controller > Starting run\n",
      "[2018-05-12 16:40:29.193101] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:40:29.438184] apply_controller > Done. Stopping robot. Value of run [11.732679]\n",
      "[2018-05-12 16:40:29.439623] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:40:29.440954] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:40:29.446230] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 16:40:29.447654] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:40:29.464503] target_dyn_opt > Initial loss [-10.371524787905678]\n",
      "\u001b[2K[2018-05-12 16:40:47.963747] target_dyn_opt > Curr loss: -1.165584E+01 [1767: -1.226230E+01], n_evals: 1999, Avg. time per updt: 0.007707\n",
      "[2018-05-12 16:40:47.977421] target_dyn_opt > Done training. New loss [-11.693893] iter: [2000]\n",
      "[2018-05-12 16:40:47.980424] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:40:47.982109] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_25.zip\n",
      "[2018-05-12 16:40:49.146539] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_25.zip\n",
      "[2018-05-12 16:40:49.227669] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_25.zip\n",
      "[2018-05-12 16:40:50.975253] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 16:40:50.980434] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:40:51.100720] SGDOptimizer > Initial loss [0.46670040488243103]\n",
      "\u001b[2K[2018-05-12 16:42:33.242386] SGDOptimizer > Curr loss: 3.921075E-01, n_evals: 999, Avg. time per updt: 0.100737\n",
      "[2018-05-12 16:42:33.271248] SGDOptimizer > Done training. New loss [0.391837] iter: [999]\n",
      "[2018-05-12 16:42:33.273098] apply_controller > Starting run\n",
      "[2018-05-12 16:42:33.274415] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:42:33.446961] apply_controller > Done. Stopping robot. Value of run [22.300606]\n",
      "[2018-05-12 16:42:33.448171] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:42:33.449543] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:42:33.453962] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 16:42:33.455627] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:42:33.471766] target_dyn_opt > Initial loss [-8.777333464659037]\n",
      "\u001b[2K[2018-05-12 16:43:03.369361] target_dyn_opt > Curr loss: -1.171248E+01 [1810: -1.249146E+01], n_evals: 1999, Avg. time per updt: 0.012940\n",
      "[2018-05-12 16:43:03.384455] target_dyn_opt > Done training. New loss [-11.919639] iter: [2000]\n",
      "[2018-05-12 16:43:03.387505] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:43:03.389053] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_26.zip\n",
      "[2018-05-12 16:43:04.603780] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_26.zip\n",
      "[2018-05-12 16:43:04.685652] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_26.zip\n",
      "[2018-05-12 16:43:05.951779] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 16:43:05.958356] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:43:06.076696] SGDOptimizer > Initial loss [0.7397891283035278]\n",
      "\u001b[2K[2018-05-12 16:44:48.930810] SGDOptimizer > Curr loss: 3.906748E-01, n_evals: 999, Avg. time per updt: 0.101484\n",
      "[2018-05-12 16:44:48.959331] SGDOptimizer > Done training. New loss [0.390253] iter: [999]\n",
      "[2018-05-12 16:44:48.961153] apply_controller > Starting run\n",
      "[2018-05-12 16:44:48.962588] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:44:49.147462] apply_controller > Done. Stopping robot. Value of run [14.087741]\n",
      "[2018-05-12 16:44:49.148883] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:44:49.150207] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:44:49.155410] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 16:44:49.157385] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:44:49.171756] target_dyn_opt > Initial loss [-10.497926295317452]\n",
      "\u001b[2K[2018-05-12 16:45:13.251996] target_dyn_opt > Curr loss: -1.207246E+01 [1952: -1.262481E+01], n_evals: 1999, Avg. time per updt: 0.010298\n",
      "[2018-05-12 16:45:13.272984] target_dyn_opt > Done training. New loss [-11.953260] iter: [2000]\n",
      "[2018-05-12 16:45:13.276555] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:45:13.278209] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_27.zip\n",
      "[2018-05-12 16:45:14.681443] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_27.zip\n",
      "[2018-05-12 16:45:14.760927] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_27.zip\n",
      "[2018-05-12 16:45:16.507866] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 16:45:16.513124] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:45:16.633139] SGDOptimizer > Initial loss [0.49476340413093567]\n",
      "\u001b[2K[2018-05-12 16:46:53.668497] SGDOptimizer > Curr loss: 3.867943E-01, n_evals: 999, Avg. time per updt: 0.095714\n",
      "[2018-05-12 16:46:53.698689] SGDOptimizer > Done training. New loss [0.388752] iter: [999]\n",
      "[2018-05-12 16:46:53.700671] apply_controller > Starting run\n",
      "[2018-05-12 16:46:53.702005] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:46:53.876183] apply_controller > Done. Stopping robot. Value of run [14.012474]\n",
      "[2018-05-12 16:46:53.877962] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:46:53.879221] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:46:53.884184] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 16:46:53.885493] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:46:53.900322] target_dyn_opt > Initial loss [-10.003723355592644]\n",
      "\u001b[2K[2018-05-12 16:47:13.615353] target_dyn_opt > Curr loss: -1.188452E+01 [687: -1.274567E+01], n_evals: 1999, Avg. time per updt: 0.008329\n",
      "[2018-05-12 16:47:13.631451] target_dyn_opt > Done training. New loss [-12.389182] iter: [2000]\n",
      "[2018-05-12 16:47:13.634322] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:47:13.635766] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_28.zip\n",
      "[2018-05-12 16:47:14.955053] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_28.zip\n",
      "[2018-05-12 16:47:15.040032] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_28.zip\n",
      "[2018-05-12 16:47:16.798291] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 16:47:16.804166] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:47:16.933906] SGDOptimizer > Initial loss [0.817743182182312]\n",
      "\u001b[2K[2018-05-12 16:48:53.999075] SGDOptimizer > Curr loss: 3.867545E-01, n_evals: 999, Avg. time per updt: 0.095736\n",
      "[2018-05-12 16:48:54.031433] SGDOptimizer > Done training. New loss [0.729472] iter: [999]\n",
      "[2018-05-12 16:48:54.033400] apply_controller > Starting run\n",
      "[2018-05-12 16:48:54.034705] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:48:54.222518] apply_controller > Done. Stopping robot. Value of run [12.085616]\n",
      "[2018-05-12 16:48:54.224002] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:48:54.225281] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:48:54.229871] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 16:48:54.231179] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:48:54.248269] target_dyn_opt > Initial loss [-10.706662858525911]\n",
      "\u001b[2K[2018-05-12 16:49:13.598108] target_dyn_opt > Curr loss: -1.233316E+01 [1634: -1.292781E+01], n_evals: 1999, Avg. time per updt: 0.008155\n",
      "[2018-05-12 16:49:13.614031] target_dyn_opt > Done training. New loss [-12.223246] iter: [2000]\n",
      "[2018-05-12 16:49:13.618777] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:49:13.620476] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_29.zip\n",
      "[2018-05-12 16:49:15.034375] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_29.zip\n",
      "[2018-05-12 16:49:15.120803] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_29.zip\n",
      "[2018-05-12 16:49:16.897996] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 16:49:16.903031] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:49:17.024133] SGDOptimizer > Initial loss [0.906024158000946]\n",
      "\u001b[2K[2018-05-12 16:50:57.332738] SGDOptimizer > Curr loss: 4.054628E-01, n_evals: 999, Avg. time per updt: 0.098958\n",
      "[2018-05-12 16:50:57.361663] SGDOptimizer > Done training. New loss [0.404846] iter: [999]\n",
      "[2018-05-12 16:50:57.363576] apply_controller > Starting run\n",
      "[2018-05-12 16:50:57.364826] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:50:57.561478] apply_controller > Done. Stopping robot. Value of run [11.698903]\n",
      "[2018-05-12 16:50:57.565520] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:50:57.568108] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:50:57.573233] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 16:50:57.574509] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:50:57.591777] target_dyn_opt > Initial loss [-11.025957715789787]\n",
      "\u001b[2K[2018-05-12 16:51:16.953181] target_dyn_opt > Curr loss: -1.234534E+01 [1835: -1.312031E+01], n_evals: 1999, Avg. time per updt: 0.008160\n",
      "[2018-05-12 16:51:16.967683] target_dyn_opt > Done training. New loss [-12.505176] iter: [2000]\n",
      "[2018-05-12 16:51:16.970415] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:51:16.971815] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/experience_30.zip\n",
      "[2018-05-12 16:51:18.372492] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/policy_30.zip\n",
      "[2018-05-12 16:51:18.457142] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_001_no_transfer/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 1 learn from scratch\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_001_no_transfer')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=False,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, task_cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:51:20.497790] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 16:51:20.534702] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 16:51:20.567159] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 16:51:20.589777] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 16:51:20.637248] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 16:51:20.653636] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 16:51:20.660297] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 16:51:20.675688] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 16:51:20.686612] Experience > Initialising new experience dataset\n",
      "[2018-05-12 16:51:20.688150] Executing initial policy\n",
      "[2018-05-12 16:51:20.689608] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 16:51:20.792805] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 16:51:20.995632] NNPolicy > Done compiling\n",
      "[2018-05-12 16:51:20.997207] apply_controller > Starting run\n",
      "[2018-05-12 16:51:20.998464] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:51:21.272605] apply_controller > Done. Stopping robot. Value of run [29.357145]\n",
      "[2018-05-12 16:51:21.273530] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:51:21.274435] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:51:21.276344] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 16:51:21.277372] target_dyn > Initialising loss function\n",
      "[2018-05-12 16:51:21.447626] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 16:51:21.786553] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 16:51:21.787826] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 16:51:21.855146] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 16:51:22.863898] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 16:51:29.234731] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:51:29.241630] target_dyn_opt > Initial loss [1650.8427462475054]\n",
      "\u001b[2K[2018-05-12 16:51:40.433155] target_dyn_opt > Curr loss: 4.138493E+01 [1923: 4.088250E+01], n_evals: 1999, Avg. time per updt: 0.003958\n",
      "[2018-05-12 16:51:40.441137] target_dyn_opt > Done training. New loss [41.601050] iter: [2000]\n",
      "[2018-05-12 16:51:40.674309] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:51:40.872081] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 16:51:40.873332] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 16:51:40.963419] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 16:51:40.964717] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 16:51:41.457177] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 16:51:41.458406] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 16:51:41.542573] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 16:51:41.543953] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 16:51:44.526701] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 16:51:45.421740] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 16:51:45.432449] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 16:51:45.465154] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 16:51:48.101891] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 16:52:05.007587] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_0.zip\n",
      "[2018-05-12 16:52:05.094177] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_0.zip\n",
      "[2018-05-12 16:52:05.185267] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_0.zip\n",
      "[2018-05-12 16:52:05.330763] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 16:52:05.332210] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 16:52:05.337830] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:52:05.551273] SGDOptimizer > Initial loss [0.9696505069732666]\n",
      "\u001b[2K[2018-05-12 16:54:09.127583] SGDOptimizer > Curr loss: 5.708410E-01, n_evals: 999, Avg. time per updt: 0.122194\n",
      "[2018-05-12 16:54:09.160266] SGDOptimizer > Done training. New loss [0.759420] iter: [999]\n",
      "[2018-05-12 16:54:09.162602] apply_controller > Starting run\n",
      "[2018-05-12 16:54:09.164087] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:54:09.369762] apply_controller > Done. Stopping robot. Value of run [25.767223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 16:54:09.371597] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:54:09.373750] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:54:09.376520] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 16:54:09.377812] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:54:09.390318] target_dyn_opt > Initial loss [75.53877804659564]\n",
      "\u001b[2K[2018-05-12 16:54:23.136133] target_dyn_opt > Curr loss: 1.404247E+01 [1977: 1.374613E+01], n_evals: 1999, Avg. time per updt: 0.005315\n",
      "[2018-05-12 16:54:23.146592] target_dyn_opt > Done training. New loss [14.228373] iter: [2000]\n",
      "[2018-05-12 16:54:23.149583] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:54:23.150953] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_1.zip\n",
      "[2018-05-12 16:54:23.280492] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_1.zip\n",
      "[2018-05-12 16:54:23.369710] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_1.zip\n",
      "[2018-05-12 16:54:25.523160] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 16:54:25.528144] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:54:25.662423] SGDOptimizer > Initial loss [0.932483971118927]\n",
      "\u001b[2K[2018-05-12 16:56:17.067790] SGDOptimizer > Curr loss: 8.588750E-01, n_evals: 999, Avg. time per updt: 0.110031\n",
      "[2018-05-12 16:56:17.100013] SGDOptimizer > Done training. New loss [0.834917] iter: [999]\n",
      "[2018-05-12 16:56:17.101752] apply_controller > Starting run\n",
      "[2018-05-12 16:56:17.102947] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:56:17.310249] apply_controller > Done. Stopping robot. Value of run [26.054157]\n",
      "[2018-05-12 16:56:17.311842] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:56:17.313217] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:56:17.315355] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 16:56:17.317106] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:56:17.330335] target_dyn_opt > Initial loss [27.61830285568347]\n",
      "\u001b[2K[2018-05-12 16:56:35.342598] target_dyn_opt > Curr loss: 4.234750E+00 [1921: 4.170052E+00], n_evals: 1999, Avg. time per updt: 0.007443\n",
      "[2018-05-12 16:56:35.356996] target_dyn_opt > Done training. New loss [4.321399] iter: [2000]\n",
      "[2018-05-12 16:56:35.359868] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:56:35.361212] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_2.zip\n",
      "[2018-05-12 16:56:35.535246] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_2.zip\n",
      "[2018-05-12 16:56:35.620865] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_2.zip\n",
      "[2018-05-12 16:56:37.775714] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 16:56:37.781316] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:56:37.928086] SGDOptimizer > Initial loss [0.8669836521148682]\n",
      "\u001b[2K[2018-05-12 16:58:29.365069] SGDOptimizer > Curr loss: 6.383805E-01, n_evals: 999, Avg. time per updt: 0.110158\n",
      "[2018-05-12 16:58:29.401133] SGDOptimizer > Done training. New loss [0.670397] iter: [999]\n",
      "[2018-05-12 16:58:29.403046] apply_controller > Starting run\n",
      "[2018-05-12 16:58:29.404403] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 16:58:29.595625] apply_controller > Done. Stopping robot. Value of run [27.469084]\n",
      "[2018-05-12 16:58:29.596868] target_2x_mass > Stopping robot\n",
      "[2018-05-12 16:58:29.598155] train_dynamics > Training dynamics model\n",
      "[2018-05-12 16:58:29.600717] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 16:58:29.602115] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 16:58:29.619819] target_dyn_opt > Initial loss [23.285630660581177]\n",
      "\u001b[2K[2018-05-12 16:58:49.071925] target_dyn_opt > Curr loss: -1.826612E-01 [1898: -6.858972E-01], n_evals: 1999, Avg. time per updt: 0.008174\n",
      "[2018-05-12 16:58:49.086814] target_dyn_opt > Done training. New loss [0.103309] iter: [2000]\n",
      "[2018-05-12 16:58:49.090138] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 16:58:49.091922] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_3.zip\n",
      "[2018-05-12 16:58:49.307318] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_3.zip\n",
      "[2018-05-12 16:58:49.394404] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_3.zip\n",
      "[2018-05-12 16:58:51.557446] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 16:58:51.562451] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 16:58:51.697688] SGDOptimizer > Initial loss [0.8911036849021912]\n",
      "\u001b[2K[2018-05-12 17:00:42.135750] SGDOptimizer > Curr loss: 4.686151E-01, n_evals: 999, Avg. time per updt: 0.109097\n",
      "[2018-05-12 17:00:42.169606] SGDOptimizer > Done training. New loss [0.482879] iter: [999]\n",
      "[2018-05-12 17:00:42.171243] apply_controller > Starting run\n",
      "[2018-05-12 17:00:42.172693] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:00:42.391945] apply_controller > Done. Stopping robot. Value of run [16.315678]\n",
      "[2018-05-12 17:00:42.393498] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:00:42.394881] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:00:42.397890] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 17:00:42.399226] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:00:42.417111] target_dyn_opt > Initial loss [6.628444227473489]\n",
      "\u001b[2K[2018-05-12 17:01:03.729722] target_dyn_opt > Curr loss: -3.009000E+00 [1845: -3.606079E+00], n_evals: 1999, Avg. time per updt: 0.009008\n",
      "[2018-05-12 17:01:03.748654] target_dyn_opt > Done training. New loss [-3.372504] iter: [2000]\n",
      "[2018-05-12 17:01:03.751379] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:01:03.758175] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_4.zip\n",
      "[2018-05-12 17:01:04.036863] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_4.zip\n",
      "[2018-05-12 17:01:04.128491] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_4.zip\n",
      "[2018-05-12 17:01:06.376926] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 17:01:06.382696] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:01:06.537199] SGDOptimizer > Initial loss [0.8303786516189575]\n",
      "\u001b[2K[2018-05-12 17:03:04.349239] SGDOptimizer > Curr loss: 4.430756E-01, n_evals: 999, Avg. time per updt: 0.116492\n",
      "[2018-05-12 17:03:04.385178] SGDOptimizer > Done training. New loss [0.441728] iter: [999]\n",
      "[2018-05-12 17:03:04.387096] apply_controller > Starting run\n",
      "[2018-05-12 17:03:04.388330] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:03:04.576761] apply_controller > Done. Stopping robot. Value of run [12.309449]\n",
      "[2018-05-12 17:03:04.578140] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:03:04.582475] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:03:04.585691] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 17:03:04.587326] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:03:04.603323] target_dyn_opt > Initial loss [-1.3675252248843517]\n",
      "\u001b[2K[2018-05-12 17:03:26.324875] target_dyn_opt > Curr loss: -5.298388E+00 [1959: -5.633589E+00], n_evals: 1999, Avg. time per updt: 0.009284\n",
      "[2018-05-12 17:03:26.341938] target_dyn_opt > Done training. New loss [-5.262766] iter: [2000]\n",
      "[2018-05-12 17:03:26.344629] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:03:26.346060] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_5.zip\n",
      "[2018-05-12 17:03:26.651799] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:03:26.738427] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_5.zip\n",
      "[2018-05-12 17:03:28.906829] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 17:03:28.911590] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:03:29.100702] SGDOptimizer > Initial loss [0.4596257507801056]\n",
      "\u001b[2K[2018-05-12 17:05:42.244139] SGDOptimizer > Curr loss: 4.473623E-01, n_evals: 999, Avg. time per updt: 0.131875\n",
      "[2018-05-12 17:05:42.288190] SGDOptimizer > Done training. New loss [0.442795] iter: [999]\n",
      "[2018-05-12 17:05:42.289929] apply_controller > Starting run\n",
      "[2018-05-12 17:05:42.291144] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:05:42.482667] apply_controller > Done. Stopping robot. Value of run [13.155147]\n",
      "[2018-05-12 17:05:42.483926] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:05:42.485186] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:05:42.488359] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 17:05:42.489717] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:05:42.507971] target_dyn_opt > Initial loss [-3.4581469162344343]\n",
      "\u001b[2K[2018-05-12 17:06:03.436592] target_dyn_opt > Curr loss: -6.332025E+00 [1771: -7.041620E+00], n_evals: 1999, Avg. time per updt: 0.008938\n",
      "[2018-05-12 17:06:03.451403] target_dyn_opt > Done training. New loss [-6.575892] iter: [2000]\n",
      "[2018-05-12 17:06:03.454413] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:06:03.455910] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_6.zip\n",
      "[2018-05-12 17:06:03.806328] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_6.zip\n",
      "[2018-05-12 17:06:03.896645] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_6.zip\n",
      "[2018-05-12 17:06:06.065053] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 17:06:06.070352] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:06:06.215567] SGDOptimizer > Initial loss [0.7908809781074524]\n",
      "\u001b[2K[2018-05-12 17:08:09.696968] SGDOptimizer > Curr loss: 6.657990E-01, n_evals: 999, Avg. time per updt: 0.122175\n",
      "[2018-05-12 17:08:09.745474] SGDOptimizer > Done training. New loss [0.812294] iter: [999]\n",
      "[2018-05-12 17:08:09.747506] apply_controller > Starting run\n",
      "[2018-05-12 17:08:09.749015] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:08:09.950129] apply_controller > Done. Stopping robot. Value of run [13.250772]\n",
      "[2018-05-12 17:08:09.951349] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:08:09.952706] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:08:09.955885] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 17:08:09.957200] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:08:09.973414] target_dyn_opt > Initial loss [-4.840738253089889]\n",
      "\u001b[2K[2018-05-12 17:08:30.695387] target_dyn_opt > Curr loss: -7.392769E+00 [1773: -8.179483E+00], n_evals: 1999, Avg. time per updt: 0.008835\n",
      "[2018-05-12 17:08:30.709502] target_dyn_opt > Done training. New loss [-7.740361] iter: [2000]\n",
      "[2018-05-12 17:08:30.712312] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:08:30.713809] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_7.zip\n",
      "[2018-05-12 17:08:31.112205] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_7.zip\n",
      "[2018-05-12 17:08:31.202212] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_7.zip\n",
      "[2018-05-12 17:08:33.379442] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 17:08:33.384833] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:08:33.524002] SGDOptimizer > Initial loss [0.7224271297454834]\n",
      "\u001b[2K[2018-05-12 17:10:18.336508] SGDOptimizer > Curr loss: 4.539546E-01, n_evals: 999, Avg. time per updt: 0.103476\n",
      "[2018-05-12 17:10:18.371434] SGDOptimizer > Done training. New loss [0.453065] iter: [999]\n",
      "[2018-05-12 17:10:18.373527] apply_controller > Starting run\n",
      "[2018-05-12 17:10:18.375278] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:10:18.594222] apply_controller > Done. Stopping robot. Value of run [15.922234]\n",
      "[2018-05-12 17:10:18.595508] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:10:18.596824] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:10:18.601122] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 17:10:18.603643] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:10:18.623201] target_dyn_opt > Initial loss [-6.02898797655471]\n",
      "\u001b[2K[2018-05-12 17:10:38.847216] target_dyn_opt > Curr loss: -8.662624E+00 [1317: -8.824895E+00], n_evals: 1999, Avg. time per updt: 0.008612\n",
      "[2018-05-12 17:10:38.861776] target_dyn_opt > Done training. New loss [-8.602093] iter: [2000]\n",
      "[2018-05-12 17:10:38.864622] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:10:38.865972] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_8.zip\n",
      "[2018-05-12 17:10:39.309733] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_8.zip\n",
      "[2018-05-12 17:10:39.402856] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_8.zip\n",
      "[2018-05-12 17:10:41.583969] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 17:10:41.588953] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:10:41.731945] SGDOptimizer > Initial loss [0.491035521030426]\n",
      "\u001b[2K[2018-05-12 17:12:36.256561] SGDOptimizer > Curr loss: 4.426951E-01, n_evals: 999, Avg. time per updt: 0.113223\n",
      "[2018-05-12 17:12:36.295455] SGDOptimizer > Done training. New loss [0.426930] iter: [999]\n",
      "[2018-05-12 17:12:36.297394] apply_controller > Starting run\n",
      "[2018-05-12 17:12:36.298911] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:12:36.501971] apply_controller > Done. Stopping robot. Value of run [14.040269]\n",
      "[2018-05-12 17:12:36.503200] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:12:36.504413] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:12:36.507283] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 17:12:36.508289] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:12:36.526566] target_dyn_opt > Initial loss [-5.103829019645165]\n",
      "\u001b[2K[2018-05-12 17:12:57.080495] target_dyn_opt > Curr loss: -8.960094E+00 [1908: -9.577222E+00], n_evals: 1999, Avg. time per updt: 0.008770\n",
      "[2018-05-12 17:12:57.097457] target_dyn_opt > Done training. New loss [-9.249247] iter: [2000]\n",
      "[2018-05-12 17:12:57.100103] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:12:57.101743] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_9.zip\n",
      "[2018-05-12 17:12:57.583709] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_9.zip\n",
      "[2018-05-12 17:12:57.673530] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_9.zip\n",
      "[2018-05-12 17:12:59.870184] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 17:12:59.875124] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:13:00.059816] SGDOptimizer > Initial loss [0.44236525893211365]\n",
      "\u001b[2K[2018-05-12 17:15:23.967806] SGDOptimizer > Curr loss: 4.456660E-01, n_evals: 999, Avg. time per updt: 0.142597\n",
      "[2018-05-12 17:15:24.017853] SGDOptimizer > Done training. New loss [0.432991] iter: [999]\n",
      "[2018-05-12 17:15:24.019651] apply_controller > Starting run\n",
      "[2018-05-12 17:15:24.020963] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:15:24.210286] apply_controller > Done. Stopping robot. Value of run [11.943687]\n",
      "[2018-05-12 17:15:24.211539] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:15:24.212954] train_dynamics > Training dynamics model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:15:24.216665] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 17:15:24.217917] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:15:24.238609] target_dyn_opt > Initial loss [-8.527793052428194]\n",
      "\u001b[2K[2018-05-12 17:15:45.492051] target_dyn_opt > Curr loss: -9.501811E+00 [1678: -1.011010E+01], n_evals: 1999, Avg. time per updt: 0.009128\n",
      "[2018-05-12 17:15:45.534376] target_dyn_opt > Done training. New loss [-9.623624] iter: [2000]\n",
      "[2018-05-12 17:15:45.540950] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:15:45.543022] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_10.zip\n",
      "[2018-05-12 17:15:46.166306] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_10.zip\n",
      "[2018-05-12 17:15:46.260506] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_10.zip\n",
      "[2018-05-12 17:15:48.714374] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 17:15:48.719187] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:15:48.881040] SGDOptimizer > Initial loss [0.434078574180603]\n",
      "\u001b[2K[2018-05-12 17:17:57.539373] SGDOptimizer > Curr loss: 4.171840E-01, n_evals: 999, Avg. time per updt: 0.127358\n",
      "[2018-05-12 17:17:57.577763] SGDOptimizer > Done training. New loss [0.413443] iter: [999]\n",
      "[2018-05-12 17:17:57.579639] apply_controller > Starting run\n",
      "[2018-05-12 17:17:57.581212] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:17:57.764311] apply_controller > Done. Stopping robot. Value of run [11.866219]\n",
      "[2018-05-12 17:17:57.765574] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:17:57.766911] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:17:57.771233] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 17:17:57.772745] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:17:57.788863] target_dyn_opt > Initial loss [-8.07676002623021]\n",
      "\u001b[2K[2018-05-12 17:18:17.584833] target_dyn_opt > Curr loss: -1.006716E+01 [1861: -1.060481E+01], n_evals: 1999, Avg. time per updt: 0.008413\n",
      "[2018-05-12 17:18:17.600494] target_dyn_opt > Done training. New loss [-9.725331] iter: [2000]\n",
      "[2018-05-12 17:18:17.603339] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:18:17.604942] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_11.zip\n",
      "[2018-05-12 17:18:18.223585] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_11.zip\n",
      "[2018-05-12 17:18:18.315227] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_11.zip\n",
      "[2018-05-12 17:18:20.604765] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 17:18:20.609539] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:18:20.759489] SGDOptimizer > Initial loss [0.4417686462402344]\n",
      "\u001b[2K[2018-05-12 17:20:27.609653] SGDOptimizer > Curr loss: 4.277354E-01, n_evals: 999, Avg. time per updt: 0.125539\n",
      "[2018-05-12 17:20:27.647813] SGDOptimizer > Done training. New loss [0.409942] iter: [999]\n",
      "[2018-05-12 17:20:27.649740] apply_controller > Starting run\n",
      "[2018-05-12 17:20:27.651198] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:20:27.847382] apply_controller > Done. Stopping robot. Value of run [11.255022]\n",
      "[2018-05-12 17:20:27.849121] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:20:27.850401] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:20:27.854911] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 17:20:27.856220] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:20:27.872146] target_dyn_opt > Initial loss [-9.1585997320929]\n",
      "\u001b[2K[2018-05-12 17:20:48.495744] target_dyn_opt > Curr loss: -1.034206E+01 [1507: -1.101070E+01], n_evals: 1999, Avg. time per updt: 0.008791\n",
      "[2018-05-12 17:20:48.511825] target_dyn_opt > Done training. New loss [-10.329329] iter: [2000]\n",
      "[2018-05-12 17:20:48.514437] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:20:48.515877] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_12.zip\n",
      "[2018-05-12 17:20:49.133501] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_12.zip\n",
      "[2018-05-12 17:20:49.223460] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_12.zip\n",
      "[2018-05-12 17:20:51.398767] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 17:20:51.404132] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:20:51.545658] SGDOptimizer > Initial loss [0.4230128228664398]\n",
      "\u001b[2K[2018-05-12 17:22:47.352097] SGDOptimizer > Curr loss: 4.122142E-01, n_evals: 999, Avg. time per updt: 0.114454\n",
      "[2018-05-12 17:22:47.385735] SGDOptimizer > Done training. New loss [0.408531] iter: [999]\n",
      "[2018-05-12 17:22:47.387767] apply_controller > Starting run\n",
      "[2018-05-12 17:22:47.389357] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:22:47.594470] apply_controller > Done. Stopping robot. Value of run [26.830193]\n",
      "[2018-05-12 17:22:47.595832] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:22:47.597375] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:22:47.601821] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 17:22:47.603334] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:22:47.621406] target_dyn_opt > Initial loss [16.777019733131812]\n",
      "\u001b[2K[2018-05-12 17:23:07.707513] target_dyn_opt > Curr loss: -1.065493E+01 [1475: -1.128197E+01], n_evals: 1999, Avg. time per updt: 0.008527\n",
      "[2018-05-12 17:23:07.722589] target_dyn_opt > Done training. New loss [-10.795560] iter: [2000]\n",
      "[2018-05-12 17:23:07.725089] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:23:07.726833] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_13.zip\n",
      "[2018-05-12 17:23:08.419254] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_13.zip\n",
      "[2018-05-12 17:23:08.513168] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_13.zip\n",
      "[2018-05-12 17:23:10.854213] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 17:23:10.858752] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:23:11.046565] SGDOptimizer > Initial loss [0.6666689515113831]\n",
      "\u001b[2K[2018-05-12 17:25:30.358491] SGDOptimizer > Curr loss: 4.286476E-01, n_evals: 999, Avg. time per updt: 0.137943\n",
      "[2018-05-12 17:25:30.406762] SGDOptimizer > Done training. New loss [0.423145] iter: [999]\n",
      "[2018-05-12 17:25:30.408669] apply_controller > Starting run\n",
      "[2018-05-12 17:25:30.411947] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:25:30.619225] apply_controller > Done. Stopping robot. Value of run [13.198034]\n",
      "[2018-05-12 17:25:30.620963] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:25:30.622319] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:25:30.626005] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 17:25:30.627286] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:25:30.646032] target_dyn_opt > Initial loss [-8.475280188143937]\n",
      "\u001b[2K[2018-05-12 17:25:51.731120] target_dyn_opt > Curr loss: -1.107234E+01 [1697: -1.167606E+01], n_evals: 1999, Avg. time per updt: 0.009007\n",
      "[2018-05-12 17:25:51.748101] target_dyn_opt > Done training. New loss [-11.424143] iter: [2000]\n",
      "[2018-05-12 17:25:51.750911] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:25:51.752483] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_14.zip\n",
      "[2018-05-12 17:25:52.443427] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_14.zip\n",
      "[2018-05-12 17:25:52.536145] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:25:54.723339] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 17:25:54.728714] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:25:54.934577] SGDOptimizer > Initial loss [0.440027117729187]\n",
      "\u001b[2K[2018-05-12 17:28:19.372399] SGDOptimizer > Curr loss: 4.150839E-01, n_evals: 999, Avg. time per updt: 0.143137\n",
      "[2018-05-12 17:28:19.422012] SGDOptimizer > Done training. New loss [0.413236] iter: [999]\n",
      "[2018-05-12 17:28:19.423858] apply_controller > Starting run\n",
      "[2018-05-12 17:28:19.425226] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:28:19.607488] apply_controller > Done. Stopping robot. Value of run [12.009007]\n",
      "[2018-05-12 17:28:19.608740] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:28:19.610076] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:28:19.614198] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 17:28:19.615983] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:28:19.634866] target_dyn_opt > Initial loss [-8.683484556474562]\n",
      "\u001b[2K[2018-05-12 17:28:39.822179] target_dyn_opt > Curr loss: -1.161714E+01 [1450: -1.192039E+01], n_evals: 1999, Avg. time per updt: 0.008582\n",
      "[2018-05-12 17:28:39.837805] target_dyn_opt > Done training. New loss [-11.505696] iter: [2000]\n",
      "[2018-05-12 17:28:39.840379] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:28:39.842103] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_15.zip\n",
      "[2018-05-12 17:28:40.612359] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_15.zip\n",
      "[2018-05-12 17:28:40.704022] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_15.zip\n",
      "[2018-05-12 17:28:42.921347] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 17:28:42.926668] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:28:43.094240] SGDOptimizer > Initial loss [0.5070917010307312]\n",
      "\u001b[2K[2018-05-12 17:30:49.394367] SGDOptimizer > Curr loss: 4.453478E-01, n_evals: 999, Avg. time per updt: 0.124971\n",
      "[2018-05-12 17:30:49.433950] SGDOptimizer > Done training. New loss [0.430968] iter: [999]\n",
      "[2018-05-12 17:30:49.435615] apply_controller > Starting run\n",
      "[2018-05-12 17:30:49.436846] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:30:49.626719] apply_controller > Done. Stopping robot. Value of run [11.240334]\n",
      "[2018-05-12 17:30:49.628432] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:30:49.629665] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:30:49.633569] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 17:30:49.635036] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:30:49.650821] target_dyn_opt > Initial loss [-9.582875539879286]\n",
      "\u001b[2K[2018-05-12 17:31:09.728290] target_dyn_opt > Curr loss: -1.151728E+01 [1534: -1.216379E+01], n_evals: 1999, Avg. time per updt: 0.008523\n",
      "[2018-05-12 17:31:09.744526] target_dyn_opt > Done training. New loss [-11.800635] iter: [2000]\n",
      "[2018-05-12 17:31:09.747986] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:31:09.750267] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_16.zip\n",
      "[2018-05-12 17:31:10.579872] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_16.zip\n",
      "[2018-05-12 17:31:10.673631] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_16.zip\n",
      "[2018-05-12 17:31:12.553823] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 17:31:12.558853] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:31:12.710356] SGDOptimizer > Initial loss [0.6935774087905884]\n",
      "\u001b[2K[2018-05-12 17:33:02.795465] SGDOptimizer > Curr loss: 4.157199E-01, n_evals: 999, Avg. time per updt: 0.108726\n",
      "[2018-05-12 17:33:02.829388] SGDOptimizer > Done training. New loss [0.419240] iter: [999]\n",
      "[2018-05-12 17:33:02.831163] apply_controller > Starting run\n",
      "[2018-05-12 17:33:02.832679] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:33:03.029405] apply_controller > Done. Stopping robot. Value of run [14.814023]\n",
      "[2018-05-12 17:33:03.030762] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:33:03.032544] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:33:03.036247] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 17:33:03.037643] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:33:03.053352] target_dyn_opt > Initial loss [-8.964946417630404]\n",
      "\u001b[2K[2018-05-12 17:33:22.996093] target_dyn_opt > Curr loss: -1.147010E+01 [1660: -1.253858E+01], n_evals: 1999, Avg. time per updt: 0.008471\n",
      "[2018-05-12 17:33:23.011850] target_dyn_opt > Done training. New loss [-11.687528] iter: [2000]\n",
      "[2018-05-12 17:33:23.015182] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:33:23.016779] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_17.zip\n",
      "[2018-05-12 17:33:23.865466] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_17.zip\n",
      "[2018-05-12 17:33:23.956034] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_17.zip\n",
      "[2018-05-12 17:33:26.145232] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 17:33:26.151391] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:33:26.287739] SGDOptimizer > Initial loss [0.4281851649284363]\n",
      "\u001b[2K[2018-05-12 17:35:17.313300] SGDOptimizer > Curr loss: 4.108897E-01, n_evals: 999, Avg. time per updt: 0.109621\n",
      "[2018-05-12 17:35:17.348542] SGDOptimizer > Done training. New loss [0.414717] iter: [999]\n",
      "[2018-05-12 17:35:17.350613] apply_controller > Starting run\n",
      "[2018-05-12 17:35:17.351932] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:35:17.558748] apply_controller > Done. Stopping robot. Value of run [13.594633]\n",
      "[2018-05-12 17:35:17.560045] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:35:17.561356] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:35:17.566089] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 17:35:17.567473] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:35:17.586513] target_dyn_opt > Initial loss [-9.283283035032547]\n",
      "\u001b[2K[2018-05-12 17:35:37.431049] target_dyn_opt > Curr loss: -1.214411E+01 [1675: -1.269432E+01], n_evals: 1999, Avg. time per updt: 0.008433\n",
      "[2018-05-12 17:35:37.445636] target_dyn_opt > Done training. New loss [-12.158201] iter: [2000]\n",
      "[2018-05-12 17:35:37.448402] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:35:37.449875] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_18.zip\n",
      "[2018-05-12 17:35:38.375994] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_18.zip\n",
      "[2018-05-12 17:35:38.467441] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_18.zip\n",
      "[2018-05-12 17:35:42.240287] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 17:35:42.246028] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:35:42.402000] SGDOptimizer > Initial loss [0.42172253131866455]\n",
      "\u001b[2K[2018-05-12 17:37:40.410029] SGDOptimizer > Curr loss: 3.880881E-01, n_evals: 999, Avg. time per updt: 0.116676\n",
      "[2018-05-12 17:37:40.447860] SGDOptimizer > Done training. New loss [0.384883] iter: [999]\n",
      "[2018-05-12 17:37:40.449905] apply_controller > Starting run\n",
      "[2018-05-12 17:37:40.451391] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:37:40.636323] apply_controller > Done. Stopping robot. Value of run [11.056768]\n",
      "[2018-05-12 17:37:40.637671] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:37:40.638931] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:37:40.643230] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 17:37:40.644701] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:37:40.661451] target_dyn_opt > Initial loss [-10.131616319047993]\n",
      "\u001b[2K[2018-05-12 17:38:01.001045] target_dyn_opt > Curr loss: -1.200429E+01 [1485: -1.287330E+01], n_evals: 1999, Avg. time per updt: 0.008657\n",
      "[2018-05-12 17:38:01.016656] target_dyn_opt > Done training. New loss [-11.990581] iter: [2000]\n",
      "[2018-05-12 17:38:01.019278] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:38:01.020661] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_19.zip\n",
      "[2018-05-12 17:38:01.943593] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_19.zip\n",
      "[2018-05-12 17:38:02.036684] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_19.zip\n",
      "[2018-05-12 17:38:04.244616] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 17:38:04.249311] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:38:04.426673] SGDOptimizer > Initial loss [0.5929355621337891]\n",
      "\u001b[2K[2018-05-12 17:40:23.350682] SGDOptimizer > Curr loss: 4.197245E-01, n_evals: 999, Avg. time per updt: 0.137598\n",
      "[2018-05-12 17:40:23.399207] SGDOptimizer > Done training. New loss [0.405119] iter: [999]\n",
      "[2018-05-12 17:40:23.401024] apply_controller > Starting run\n",
      "[2018-05-12 17:40:23.402378] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:40:23.572421] apply_controller > Done. Stopping robot. Value of run [10.749657]\n",
      "[2018-05-12 17:40:23.573876] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:40:23.575177] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:40:23.579255] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 17:40:23.580906] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:40:23.597022] target_dyn_opt > Initial loss [-8.216172428651788]\n",
      "\u001b[2K[2018-05-12 17:40:44.109001] target_dyn_opt > Curr loss: -1.234614E+01 [1805: -1.293580E+01], n_evals: 1999, Avg. time per updt: 0.008745\n",
      "[2018-05-12 17:40:44.125293] target_dyn_opt > Done training. New loss [-12.750066] iter: [2000]\n",
      "[2018-05-12 17:40:44.129146] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:40:44.130788] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_20.zip\n",
      "[2018-05-12 17:40:45.093707] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_20.zip\n",
      "[2018-05-12 17:40:45.187204] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_20.zip\n",
      "[2018-05-12 17:40:47.369621] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 17:40:47.374911] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:40:47.541050] SGDOptimizer > Initial loss [0.6740347146987915]\n",
      "\u001b[2K[2018-05-12 17:43:14.490919] SGDOptimizer > Curr loss: 3.759529E-01, n_evals: 999, Avg. time per updt: 0.145535\n",
      "[2018-05-12 17:43:14.539314] SGDOptimizer > Done training. New loss [0.440000] iter: [999]\n",
      "[2018-05-12 17:43:14.541231] apply_controller > Starting run\n",
      "[2018-05-12 17:43:14.542636] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:43:14.749360] apply_controller > Done. Stopping robot. Value of run [25.240799]\n",
      "[2018-05-12 17:43:14.750721] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:43:14.752211] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:43:14.756203] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 17:43:14.757709] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:43:14.775846] target_dyn_opt > Initial loss [-1.6851684045642146]\n",
      "\u001b[2K[2018-05-12 17:43:35.728551] target_dyn_opt > Curr loss: -1.254691E+01 [1399: -1.314618E+01], n_evals: 1999, Avg. time per updt: 0.008918\n",
      "[2018-05-12 17:43:35.743299] target_dyn_opt > Done training. New loss [-12.411468] iter: [2000]\n",
      "[2018-05-12 17:43:35.746073] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:43:35.747565] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_21.zip\n",
      "[2018-05-12 17:43:36.778072] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_21.zip\n",
      "[2018-05-12 17:43:36.870163] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_21.zip\n",
      "[2018-05-12 17:43:39.083736] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 17:43:39.089148] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:43:39.235993] SGDOptimizer > Initial loss [0.7474124431610107]\n",
      "\u001b[2K[2018-05-12 17:45:31.995846] SGDOptimizer > Curr loss: 4.000421E-01, n_evals: 999, Avg. time per updt: 0.111400\n",
      "[2018-05-12 17:45:32.030621] SGDOptimizer > Done training. New loss [0.396896] iter: [999]\n",
      "[2018-05-12 17:45:32.032535] apply_controller > Starting run\n",
      "[2018-05-12 17:45:32.033841] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:45:32.244553] apply_controller > Done. Stopping robot. Value of run [11.798441]\n",
      "[2018-05-12 17:45:32.246060] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:45:32.248663] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:45:32.253646] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 17:45:32.254930] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:45:32.271822] target_dyn_opt > Initial loss [-9.373591334119194]\n",
      "\u001b[2K[2018-05-12 17:45:53.064292] target_dyn_opt > Curr loss: -1.286662E+01 [1903: -1.336084E+01], n_evals: 1999, Avg. time per updt: 0.008838\n",
      "[2018-05-12 17:45:53.079959] target_dyn_opt > Done training. New loss [-12.576307] iter: [2000]\n",
      "[2018-05-12 17:45:53.082739] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:45:53.084557] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_22.zip\n",
      "[2018-05-12 17:45:54.146322] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_22.zip\n",
      "[2018-05-12 17:45:54.238579] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_22.zip\n",
      "[2018-05-12 17:45:56.415002] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 17:45:56.420951] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:45:56.580701] SGDOptimizer > Initial loss [0.6775530576705933]\n",
      "\u001b[2K[2018-05-12 17:47:58.904384] SGDOptimizer > Curr loss: 3.816882E-01, n_evals: 999, Avg. time per updt: 0.121007\n",
      "[2018-05-12 17:47:58.941913] SGDOptimizer > Done training. New loss [0.378493] iter: [999]\n",
      "[2018-05-12 17:47:58.943995] apply_controller > Starting run\n",
      "[2018-05-12 17:47:58.945302] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:47:59.131066] apply_controller > Done. Stopping robot. Value of run [11.016406]\n",
      "[2018-05-12 17:47:59.132410] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:47:59.133729] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:47:59.138448] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 17:47:59.139863] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:47:59.158486] target_dyn_opt > Initial loss [-10.182641957597486]\n",
      "\u001b[2K[2018-05-12 17:48:19.787922] target_dyn_opt > Curr loss: -1.289684E+01 [1513: -1.342050E+01], n_evals: 1999, Avg. time per updt: 0.008771\n",
      "[2018-05-12 17:48:19.804373] target_dyn_opt > Done training. New loss [-12.778950] iter: [2000]\n",
      "[2018-05-12 17:48:19.807061] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:48:19.808535] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_23.zip\n",
      "[2018-05-12 17:48:20.937759] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_23.zip\n",
      "[2018-05-12 17:48:21.032366] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_23.zip\n",
      "[2018-05-12 17:48:22.774788] ==== Iteration [24], experience: [720 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 17:48:22.780171] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:48:22.952205] SGDOptimizer > Initial loss [0.38807886838912964]\n",
      "\u001b[2K[2018-05-12 17:50:27.951149] SGDOptimizer > Curr loss: 3.800575E-01, n_evals: 999, Avg. time per updt: 0.123710\n",
      "[2018-05-12 17:50:27.992171] SGDOptimizer > Done training. New loss [0.383806] iter: [999]\n",
      "[2018-05-12 17:50:27.994084] apply_controller > Starting run\n",
      "[2018-05-12 17:50:27.995567] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:50:28.183770] apply_controller > Done. Stopping robot. Value of run [18.834042]\n",
      "[2018-05-12 17:50:28.185118] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:50:28.186364] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:50:28.190992] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 17:50:28.192269] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:50:28.207996] target_dyn_opt > Initial loss [-7.73263591207307]\n",
      "\u001b[2K[2018-05-12 17:50:47.999689] target_dyn_opt > Curr loss: -1.282054E+01 [1513: -1.351387E+01], n_evals: 1999, Avg. time per updt: 0.008364\n",
      "[2018-05-12 17:50:48.013452] target_dyn_opt > Done training. New loss [-12.785029] iter: [2000]\n",
      "[2018-05-12 17:50:48.016290] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:50:48.017805] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_24.zip\n",
      "[2018-05-12 17:50:49.151938] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_24.zip\n",
      "[2018-05-12 17:50:49.247552] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_24.zip\n",
      "[2018-05-12 17:50:51.435163] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 17:50:51.439971] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:50:51.581702] SGDOptimizer > Initial loss [0.6624100804328918]\n",
      "\u001b[2K[2018-05-12 17:52:43.324881] SGDOptimizer > Curr loss: 4.115352E-01, n_evals: 999, Avg. time per updt: 0.110413\n",
      "[2018-05-12 17:52:43.359930] SGDOptimizer > Done training. New loss [0.411312] iter: [999]\n",
      "[2018-05-12 17:52:43.361733] apply_controller > Starting run\n",
      "[2018-05-12 17:52:43.363138] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:52:43.547946] apply_controller > Done. Stopping robot. Value of run [12.076398]\n",
      "[2018-05-12 17:52:43.549328] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:52:43.550558] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:52:43.555742] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 17:52:43.557206] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:52:43.573495] target_dyn_opt > Initial loss [-10.25501592714211]\n",
      "\u001b[2K[2018-05-12 17:53:03.584564] target_dyn_opt > Curr loss: -1.324777E+01 [1798: -1.371686E+01], n_evals: 1999, Avg. time per updt: 0.008438\n",
      "[2018-05-12 17:53:03.600893] target_dyn_opt > Done training. New loss [-13.061468] iter: [2000]\n",
      "[2018-05-12 17:53:03.603519] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:53:03.604951] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_25.zip\n",
      "[2018-05-12 17:53:04.787300] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_25.zip\n",
      "[2018-05-12 17:53:04.880047] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_25.zip\n",
      "[2018-05-12 17:53:07.089054] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 17:53:07.094551] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:53:07.238457] SGDOptimizer > Initial loss [0.43048375844955444]\n",
      "\u001b[2K[2018-05-12 17:55:14.276764] SGDOptimizer > Curr loss: 4.028467E-01, n_evals: 999, Avg. time per updt: 0.125268\n",
      "[2018-05-12 17:55:14.310995] SGDOptimizer > Done training. New loss [0.400396] iter: [999]\n",
      "[2018-05-12 17:55:14.312760] apply_controller > Starting run\n",
      "[2018-05-12 17:55:14.314228] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:55:14.497360] apply_controller > Done. Stopping robot. Value of run [12.427175]\n",
      "[2018-05-12 17:55:14.498727] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:55:14.499935] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:55:14.505393] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 17:55:14.506663] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:55:14.524236] target_dyn_opt > Initial loss [-10.896428014811885]\n",
      "\u001b[2K[2018-05-12 17:55:41.678335] target_dyn_opt > Curr loss: -1.327234E+01 [1286: -1.387971E+01], n_evals: 1999, Avg. time per updt: 0.011557\n",
      "[2018-05-12 17:55:41.692309] target_dyn_opt > Done training. New loss [-13.099115] iter: [2000]\n",
      "[2018-05-12 17:55:41.694911] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:55:41.696588] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_26.zip\n",
      "[2018-05-12 17:55:42.932324] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_26.zip\n",
      "[2018-05-12 17:55:43.025895] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_26.zip\n",
      "[2018-05-12 17:55:45.246252] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 17:55:45.251329] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:55:45.401077] SGDOptimizer > Initial loss [0.4364577531814575]\n",
      "\u001b[2K[2018-05-12 17:57:48.953037] SGDOptimizer > Curr loss: 3.972510E-01, n_evals: 999, Avg. time per updt: 0.122151\n",
      "[2018-05-12 17:57:48.988301] SGDOptimizer > Done training. New loss [0.397165] iter: [999]\n",
      "[2018-05-12 17:57:48.990103] apply_controller > Starting run\n",
      "[2018-05-12 17:57:48.991594] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 17:57:49.181386] apply_controller > Done. Stopping robot. Value of run [20.010370]\n",
      "[2018-05-12 17:57:49.182992] target_2x_mass > Stopping robot\n",
      "[2018-05-12 17:57:49.184274] train_dynamics > Training dynamics model\n",
      "[2018-05-12 17:57:49.188623] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 17:57:49.190190] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 17:57:49.206187] target_dyn_opt > Initial loss [-9.177825366041343]\n",
      "\u001b[2K[2018-05-12 17:58:09.605750] target_dyn_opt > Curr loss: -1.369123E+01 [652: -1.404327E+01], n_evals: 1999, Avg. time per updt: 0.008657\n",
      "[2018-05-12 17:58:09.623100] target_dyn_opt > Done training. New loss [-13.489339] iter: [2000]\n",
      "[2018-05-12 17:58:09.625718] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 17:58:09.627060] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_27.zip\n",
      "[2018-05-12 17:58:10.905648] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_27.zip\n",
      "[2018-05-12 17:58:10.997690] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_27.zip\n",
      "[2018-05-12 17:58:13.223065] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 17:58:13.228052] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 17:58:13.409963] SGDOptimizer > Initial loss [0.6895471215248108]\n",
      "\u001b[2K[2018-05-12 18:00:39.456393] SGDOptimizer > Curr loss: 4.078264E-01, n_evals: 999, Avg. time per updt: 0.144685\n",
      "[2018-05-12 18:00:39.501047] SGDOptimizer > Done training. New loss [0.409528] iter: [999]\n",
      "[2018-05-12 18:00:39.504859] apply_controller > Starting run\n",
      "[2018-05-12 18:00:39.506215] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:00:39.749154] apply_controller > Done. Stopping robot. Value of run [12.135168]\n",
      "[2018-05-12 18:00:39.750528] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:00:39.751825] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:00:39.757213] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 18:00:39.758756] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:00:39.775200] target_dyn_opt > Initial loss [-10.520030928777883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:01:02.860788] target_dyn_opt > Curr loss: -1.340658E+01 [1896: -1.396489E+01], n_evals: 1999, Avg. time per updt: 0.010010\n",
      "[2018-05-12 18:01:02.881740] target_dyn_opt > Done training. New loss [-13.573767] iter: [2000]\n",
      "[2018-05-12 18:01:02.885062] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:01:02.886479] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_28.zip\n",
      "[2018-05-12 18:01:04.528831] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_28.zip\n",
      "[2018-05-12 18:01:04.648673] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_28.zip\n",
      "[2018-05-12 18:01:07.500020] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 18:01:07.505604] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:01:07.696139] SGDOptimizer > Initial loss [0.42210742831230164]\n",
      "\u001b[2K[2018-05-12 18:03:13.630384] SGDOptimizer > Curr loss: 3.975329E-01, n_evals: 999, Avg. time per updt: 0.124646\n",
      "[2018-05-12 18:03:13.670506] SGDOptimizer > Done training. New loss [0.398665] iter: [999]\n",
      "[2018-05-12 18:03:13.672171] apply_controller > Starting run\n",
      "[2018-05-12 18:03:13.673712] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:03:13.853054] apply_controller > Done. Stopping robot. Value of run [11.814992]\n",
      "[2018-05-12 18:03:13.854435] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:03:13.855687] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:03:13.861198] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 18:03:13.862466] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:03:13.878924] target_dyn_opt > Initial loss [-11.200814341676647]\n",
      "\u001b[2K[2018-05-12 18:03:36.257391] target_dyn_opt > Curr loss: -1.357847E+01 [1638: -1.422099E+01], n_evals: 1999, Avg. time per updt: 0.009570\n",
      "[2018-05-12 18:03:36.272895] target_dyn_opt > Done training. New loss [-13.184232] iter: [2000]\n",
      "[2018-05-12 18:03:36.275683] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:03:36.277069] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_29.zip\n",
      "[2018-05-12 18:03:37.638665] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_29.zip\n",
      "[2018-05-12 18:03:37.736224] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_29.zip\n",
      "[2018-05-12 18:03:39.961110] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 18:03:39.966741] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:03:40.131188] SGDOptimizer > Initial loss [0.4156937003135681]\n",
      "\u001b[2K[2018-05-12 18:05:43.444851] SGDOptimizer > Curr loss: 3.933279E-01, n_evals: 999, Avg. time per updt: 0.122032\n",
      "[2018-05-12 18:05:43.485568] SGDOptimizer > Done training. New loss [0.395188] iter: [999]\n",
      "[2018-05-12 18:05:43.487592] apply_controller > Starting run\n",
      "[2018-05-12 18:05:43.488970] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:05:43.671091] apply_controller > Done. Stopping robot. Value of run [12.950757]\n",
      "[2018-05-12 18:05:43.672593] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:05:43.673832] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:05:43.679085] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 18:05:43.680366] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:05:43.696409] target_dyn_opt > Initial loss [-9.914838553270588]\n",
      "\u001b[2K[2018-05-12 18:06:04.846382] target_dyn_opt > Curr loss: -1.346829E+01 [1025: -1.416877E+01], n_evals: 1999, Avg. time per updt: 0.009011\n",
      "[2018-05-12 18:06:04.862136] target_dyn_opt > Done training. New loss [-13.619464] iter: [2000]\n",
      "[2018-05-12 18:06:04.864800] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:06:04.866204] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/experience_30.zip\n",
      "[2018-05-12 18:06:06.271768] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/policy_30.zip\n",
      "[2018-05-12 18:06:06.366263] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_002_task_cost_from_source/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 2 learn starting from source policy and dynamics\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_002_task_cost_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=False,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, task_cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:07:01.672530] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 18:07:01.696574] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 18:07:01.727029] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 18:07:01.739143] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 18:07:01.746079] Experience > Initialising new experience dataset\n",
      "[2018-05-12 18:07:01.747480] Executing uniformly-random controls\n",
      "[2018-05-12 18:07:01.748745] apply_controller > Starting run\n",
      "[2018-05-12 18:07:01.750224] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:07:01.930016] apply_controller > Done. Stopping robot. Value of run [29.985722]\n",
      "[2018-05-12 18:07:01.931577] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:07:01.933049] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:07:01.935954] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 18:07:01.937289] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8ad0>})\n",
      "[2018-05-12 18:07:01.983726] target_dyn > Initialising loss function\n",
      "[2018-05-12 18:07:02.136994] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 18:07:04.338008] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 18:07:04.339289] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 18:07:04.400890] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 18:07:05.306381] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 18:07:10.186432] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:07:10.194051] target_dyn_opt > Initial loss [2739.4149668008836]\n",
      "\u001b[2K[2018-05-12 18:07:20.707157] target_dyn_opt > Curr loss: 6.242018E+01 [1926: 5.313988E+01], n_evals: 1999, Avg. time per updt: 0.003635\n",
      "[2018-05-12 18:07:20.714820] target_dyn_opt > Done training. New loss [68.703835] iter: [2000]\n",
      "[2018-05-12 18:07:20.965565] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:07:21.005136] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8c5def8990>})\n",
      "[2018-05-12 18:07:21.178345] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 18:07:21.179758] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 18:07:21.267464] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 18:07:21.268767] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 18:07:21.894826] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 18:07:21.896077] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 18:07:21.986688] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 18:07:21.988065] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 18:07:27.125070] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 18:07:28.483728] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 18:07:28.494426] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 18:07:28.529328] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 18:07:31.651538] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 18:07:51.116366] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_0.zip\n",
      "[2018-05-12 18:07:51.212898] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_0.zip\n",
      "[2018-05-12 18:07:51.324924] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_0.zip\n",
      "[2018-05-12 18:07:51.475703] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 18:07:51.478174] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 18:07:51.484280] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:07:51.984199] SGDOptimizer > Initial loss [69433.765625]\n",
      "\u001b[2K[2018-05-12 18:09:40.977325] SGDOptimizer > Curr loss: 1.463850E+04, n_evals: 999, Avg. time per updt: 0.107645\n",
      "[2018-05-12 18:09:41.000075] SGDOptimizer > Done training. New loss [47538.859375] iter: [999]\n",
      "[2018-05-12 18:09:41.002206] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 18:09:41.087388] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 18:09:41.253766] NNPolicy > Done compiling\n",
      "[2018-05-12 18:09:41.255400] apply_controller > Starting run\n",
      "[2018-05-12 18:09:41.257332] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:09:41.441277] apply_controller > Done. Stopping robot. Value of run [29.884550]\n",
      "[2018-05-12 18:09:41.442936] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:09:41.444441] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:09:41.447484] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 18:09:41.448851] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:09:41.461214] target_dyn_opt > Initial loss [86.12310002248228]\n",
      "\u001b[2K[2018-05-12 18:09:54.839105] target_dyn_opt > Curr loss: 2.913741E+01 [1648: 2.204935E+01], n_evals: 1999, Avg. time per updt: 0.005158\n",
      "[2018-05-12 18:09:54.849303] target_dyn_opt > Done training. New loss [24.445112] iter: [2000]\n",
      "[2018-05-12 18:09:54.851855] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:09:54.853476] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_1.zip\n",
      "[2018-05-12 18:09:55.000338] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_1.zip\n",
      "[2018-05-12 18:09:55.104843] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_1.zip\n",
      "[2018-05-12 18:09:57.776343] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 18:09:57.781382] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:09:57.913607] SGDOptimizer > Initial loss [63934.1171875]\n",
      "\u001b[2K[2018-05-12 18:11:49.084387] SGDOptimizer > Curr loss: 8.841696E+04, n_evals: 999, Avg. time per updt: 0.109826\n",
      "[2018-05-12 18:11:49.109829] SGDOptimizer > Done training. New loss [135481.015625] iter: [999]\n",
      "[2018-05-12 18:11:49.112154] apply_controller > Starting run\n",
      "[2018-05-12 18:11:49.113666] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:11:49.290275] apply_controller > Done. Stopping robot. Value of run [29.942989]\n",
      "[2018-05-12 18:11:49.291856] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:11:49.293467] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:11:49.295965] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 18:11:49.297414] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:11:49.310996] target_dyn_opt > Initial loss [29.044263332244544]\n",
      "\u001b[2K[2018-05-12 18:12:06.094948] target_dyn_opt > Curr loss: 1.182224E+01 [1964: 1.046451E+01], n_evals: 1999, Avg. time per updt: 0.006833\n",
      "[2018-05-12 18:12:06.107143] target_dyn_opt > Done training. New loss [12.355997] iter: [2000]\n",
      "[2018-05-12 18:12:06.109937] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:12:06.111728] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_2.zip\n",
      "[2018-05-12 18:12:06.297919] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_2.zip\n",
      "[2018-05-12 18:12:06.397727] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_2.zip\n",
      "[2018-05-12 18:12:08.910600] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 18:12:08.915874] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:12:09.043701] SGDOptimizer > Initial loss [106089.046875]\n",
      "\u001b[2K[2018-05-12 18:14:00.797915] SGDOptimizer > Curr loss: 2.352675E+04, n_evals: 999, Avg. time per updt: 0.109957\n",
      "[2018-05-12 18:14:00.826936] SGDOptimizer > Done training. New loss [23732.035156] iter: [999]\n",
      "[2018-05-12 18:14:00.831017] apply_controller > Starting run\n",
      "[2018-05-12 18:14:00.832265] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:14:01.070406] apply_controller > Done. Stopping robot. Value of run [29.926685]\n",
      "[2018-05-12 18:14:01.072186] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:14:01.073415] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:14:01.077840] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 18:14:01.079364] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:14:01.116688] target_dyn_opt > Initial loss [12.922963012367134]\n",
      "\u001b[2K[2018-05-12 18:14:19.874141] target_dyn_opt > Curr loss: 6.053292E+00 [1868: 4.915508E+00], n_evals: 1999, Avg. time per updt: 0.007793\n",
      "[2018-05-12 18:14:19.886871] target_dyn_opt > Done training. New loss [6.115399] iter: [2000]\n",
      "[2018-05-12 18:14:19.889464] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:14:19.892571] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_3.zip\n",
      "[2018-05-12 18:14:20.131215] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_3.zip\n",
      "[2018-05-12 18:14:20.248242] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_3.zip\n",
      "[2018-05-12 18:14:22.825066] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 18:14:22.830519] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:14:22.958065] SGDOptimizer > Initial loss [18939.2578125]\n",
      "\u001b[2K[2018-05-12 18:16:14.856275] SGDOptimizer > Curr loss: 2.979494E+04, n_evals: 999, Avg. time per updt: 0.110535\n",
      "[2018-05-12 18:16:14.879949] SGDOptimizer > Done training. New loss [29801.537109] iter: [999]\n",
      "[2018-05-12 18:16:14.882404] apply_controller > Starting run\n",
      "[2018-05-12 18:16:14.886007] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:16:15.095178] apply_controller > Done. Stopping robot. Value of run [28.572929]\n",
      "[2018-05-12 18:16:15.096848] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:16:15.098331] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:16:15.100785] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 18:16:15.102148] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:16:15.119318] target_dyn_opt > Initial loss [9.396487676700705]\n",
      "\u001b[2K[2018-05-12 18:16:34.039386] target_dyn_opt > Curr loss: 2.564275E+00 [1741: 1.668358E+00], n_evals: 1999, Avg. time per updt: 0.007869\n",
      "[2018-05-12 18:16:34.055002] target_dyn_opt > Done training. New loss [2.213652] iter: [2000]\n",
      "[2018-05-12 18:16:34.057801] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:16:34.059895] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_4.zip\n",
      "[2018-05-12 18:16:34.337065] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_4.zip\n",
      "[2018-05-12 18:16:34.439429] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_4.zip\n",
      "[2018-05-12 18:16:36.969381] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 18:16:36.974427] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:16:37.119549] SGDOptimizer > Initial loss [27245.18359375]\n",
      "\u001b[2K[2018-05-12 18:18:30.873856] SGDOptimizer > Curr loss: 2.221213E+04, n_evals: 999, Avg. time per updt: 0.112392\n",
      "[2018-05-12 18:18:30.900528] SGDOptimizer > Done training. New loss [22136.376953] iter: [999]\n",
      "[2018-05-12 18:18:30.902441] apply_controller > Starting run\n",
      "[2018-05-12 18:18:30.904008] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:18:31.079126] apply_controller > Done. Stopping robot. Value of run [29.986776]\n",
      "[2018-05-12 18:18:31.080568] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:18:31.082035] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:18:31.085028] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 18:18:31.086771] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:18:31.101108] target_dyn_opt > Initial loss [4.759038792706319]\n",
      "\u001b[2K[2018-05-12 18:18:52.582437] target_dyn_opt > Curr loss: -7.768030E-01 [1896: -1.114577E+00], n_evals: 1999, Avg. time per updt: 0.009028\n",
      "[2018-05-12 18:18:52.595407] target_dyn_opt > Done training. New loss [-0.396261] iter: [2000]\n",
      "[2018-05-12 18:18:52.598372] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:18:52.599801] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_5.zip\n",
      "[2018-05-12 18:18:52.923354] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_5.zip\n",
      "[2018-05-12 18:18:53.031698] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_5.zip\n",
      "[2018-05-12 18:18:55.575893] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 18:18:55.581661] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 18:18:55.728596] SGDOptimizer > Initial loss [16146.7490234375]\n",
      "\u001b[2K[2018-05-12 18:20:47.453708] SGDOptimizer > Curr loss: 1.852543E+04, n_evals: 999, Avg. time per updt: 0.110363\n",
      "[2018-05-12 18:20:47.478936] SGDOptimizer > Done training. New loss [25032.130859] iter: [999]\n",
      "[2018-05-12 18:20:47.480988] apply_controller > Starting run\n",
      "[2018-05-12 18:20:47.482785] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:20:47.656831] apply_controller > Done. Stopping robot. Value of run [29.985237]\n",
      "[2018-05-12 18:20:47.658165] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:20:47.659386] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:20:47.662451] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 18:20:47.663823] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:20:47.680779] target_dyn_opt > Initial loss [9.682417066577418]\n",
      "\u001b[2K[2018-05-12 18:21:05.893852] target_dyn_opt > Curr loss: -2.607559E+00 [1977: -2.835589E+00], n_evals: 1999, Avg. time per updt: 0.007577\n",
      "[2018-05-12 18:21:05.907007] target_dyn_opt > Done training. New loss [-2.516647] iter: [2000]\n",
      "[2018-05-12 18:21:05.909999] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:21:05.911418] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_6.zip\n",
      "[2018-05-12 18:21:06.278460] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_6.zip\n",
      "[2018-05-12 18:21:06.381093] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_6.zip\n",
      "[2018-05-12 18:21:08.943450] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 18:21:08.948786] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:21:09.086092] SGDOptimizer > Initial loss [40771.20703125]\n",
      "\u001b[2K[2018-05-12 18:23:05.601072] SGDOptimizer > Curr loss: 3.698182E+04, n_evals: 999, Avg. time per updt: 0.115177\n",
      "[2018-05-12 18:23:05.625212] SGDOptimizer > Done training. New loss [41267.160156] iter: [999]\n",
      "[2018-05-12 18:23:05.626963] apply_controller > Starting run\n",
      "[2018-05-12 18:23:05.628443] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:23:05.816939] apply_controller > Done. Stopping robot. Value of run [28.644251]\n",
      "[2018-05-12 18:23:05.818157] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:23:05.819515] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:23:05.822434] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 18:23:05.824236] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:23:05.840745] target_dyn_opt > Initial loss [1.5595983914641565]\n",
      "\u001b[2K[2018-05-12 18:23:24.444147] target_dyn_opt > Curr loss: -3.268668E+00 [1480: -4.147147E+00], n_evals: 1999, Avg. time per updt: 0.007780\n",
      "[2018-05-12 18:23:24.457965] target_dyn_opt > Done training. New loss [-3.862143] iter: [2000]\n",
      "[2018-05-12 18:23:24.460840] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:23:24.462851] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_7.zip\n",
      "[2018-05-12 18:23:24.881809] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_7.zip\n",
      "[2018-05-12 18:23:24.982100] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_7.zip\n",
      "[2018-05-12 18:23:27.622129] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 18:23:27.627775] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:23:27.777768] SGDOptimizer > Initial loss [36382.3359375]\n",
      "\u001b[2K[2018-05-12 18:25:18.947127] SGDOptimizer > Curr loss: 1.958506E+04, n_evals: 999, Avg. time per updt: 0.109807\n",
      "[2018-05-12 18:25:18.970616] SGDOptimizer > Done training. New loss [16452.753906] iter: [999]\n",
      "[2018-05-12 18:25:18.972836] apply_controller > Starting run\n",
      "[2018-05-12 18:25:18.973988] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:25:19.140482] apply_controller > Done. Stopping robot. Value of run [29.989891]\n",
      "[2018-05-12 18:25:19.142213] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:25:19.143436] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:25:19.146068] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 18:25:19.147488] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:25:19.162035] target_dyn_opt > Initial loss [-3.0789644833969962]\n",
      "\u001b[2K[2018-05-12 18:25:38.451148] target_dyn_opt > Curr loss: -5.051531E+00 [1923: -5.404793E+00], n_evals: 1999, Avg. time per updt: 0.007921\n",
      "[2018-05-12 18:25:38.465483] target_dyn_opt > Done training. New loss [-4.576589] iter: [2000]\n",
      "[2018-05-12 18:25:38.468687] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:25:38.471950] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_8.zip\n",
      "[2018-05-12 18:25:38.943198] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_8.zip\n",
      "[2018-05-12 18:25:39.047282] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_8.zip\n",
      "[2018-05-12 18:25:41.220969] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 18:25:41.226717] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:25:41.358378] SGDOptimizer > Initial loss [19553.89453125]\n",
      "\u001b[2K[2018-05-12 18:27:35.275834] SGDOptimizer > Curr loss: 3.328670E+04, n_evals: 999, Avg. time per updt: 0.112566\n",
      "[2018-05-12 18:27:35.299209] SGDOptimizer > Done training. New loss [31528.052734] iter: [999]\n",
      "[2018-05-12 18:27:35.301048] apply_controller > Starting run\n",
      "[2018-05-12 18:27:35.302333] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:27:35.498533] apply_controller > Done. Stopping robot. Value of run [29.927071]\n",
      "[2018-05-12 18:27:35.500008] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:27:35.501513] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:27:35.504646] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 18:27:35.506017] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:27:35.522199] target_dyn_opt > Initial loss [-3.357338646633936]\n",
      "\u001b[2K[2018-05-12 18:27:53.807654] target_dyn_opt > Curr loss: -5.612216E+00 [1577: -6.248832E+00], n_evals: 1999, Avg. time per updt: 0.007652\n",
      "[2018-05-12 18:27:53.821465] target_dyn_opt > Done training. New loss [-5.569221] iter: [2000]\n",
      "[2018-05-12 18:27:53.824263] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:27:53.825679] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_9.zip\n",
      "[2018-05-12 18:27:54.328472] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_9.zip\n",
      "[2018-05-12 18:27:54.432608] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_9.zip\n",
      "[2018-05-12 18:27:57.023051] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 18:27:57.029044] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:27:57.159151] SGDOptimizer > Initial loss [32656.25]\n",
      "\u001b[2K[2018-05-12 18:29:50.382129] SGDOptimizer > Curr loss: 1.959654E+04, n_evals: 999, Avg. time per updt: 0.111887\n",
      "[2018-05-12 18:29:50.412925] SGDOptimizer > Done training. New loss [18696.605469] iter: [999]\n",
      "[2018-05-12 18:29:50.414763] apply_controller > Starting run\n",
      "[2018-05-12 18:29:50.416106] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:29:50.660929] apply_controller > Done. Stopping robot. Value of run [25.625702]\n",
      "[2018-05-12 18:29:50.662393] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:29:50.663569] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:29:50.666871] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 18:29:50.668262] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:29:50.684591] target_dyn_opt > Initial loss [-4.243365755418555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:30:09.534704] target_dyn_opt > Curr loss: -6.387366E+00 [1939: -6.906607E+00], n_evals: 1999, Avg. time per updt: 0.007931\n",
      "[2018-05-12 18:30:09.550512] target_dyn_opt > Done training. New loss [-6.493181] iter: [2000]\n",
      "[2018-05-12 18:30:09.553331] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:30:09.554765] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_10.zip\n",
      "[2018-05-12 18:30:10.120019] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_10.zip\n",
      "[2018-05-12 18:30:10.225679] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_10.zip\n",
      "[2018-05-12 18:30:12.855644] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 18:30:12.861508] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:30:12.999015] SGDOptimizer > Initial loss [16508.91796875]\n",
      "\u001b[2K[2018-05-12 18:31:57.384987] SGDOptimizer > Curr loss: 1.623779E+04, n_evals: 999, Avg. time per updt: 0.103093\n",
      "[2018-05-12 18:31:57.409894] SGDOptimizer > Done training. New loss [13444.902344] iter: [999]\n",
      "[2018-05-12 18:31:57.412019] apply_controller > Starting run\n",
      "[2018-05-12 18:31:57.413391] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:31:57.575046] apply_controller > Done. Stopping robot. Value of run [29.628450]\n",
      "[2018-05-12 18:31:57.576274] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:31:57.577788] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:31:57.581476] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 18:31:57.582911] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:31:57.599867] target_dyn_opt > Initial loss [-6.13810023739827]\n",
      "\u001b[2K[2018-05-12 18:32:15.289755] target_dyn_opt > Curr loss: -7.014058E+00 [1953: -7.738067E+00], n_evals: 1999, Avg. time per updt: 0.007378\n",
      "[2018-05-12 18:32:15.305186] target_dyn_opt > Done training. New loss [-7.171149] iter: [2000]\n",
      "[2018-05-12 18:32:15.307837] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:32:15.309309] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_11.zip\n",
      "[2018-05-12 18:32:15.870366] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_11.zip\n",
      "[2018-05-12 18:32:15.971294] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_11.zip\n",
      "[2018-05-12 18:32:18.449765] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 18:32:18.455671] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:32:18.586209] SGDOptimizer > Initial loss [12354.9384765625]\n",
      "\u001b[2K[2018-05-12 18:34:00.759118] SGDOptimizer > Curr loss: 3.257018E+04, n_evals: 999, Avg. time per updt: 0.100885\n",
      "[2018-05-12 18:34:00.787218] SGDOptimizer > Done training. New loss [25988.267578] iter: [999]\n",
      "[2018-05-12 18:34:00.789023] apply_controller > Starting run\n",
      "[2018-05-12 18:34:00.790634] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:34:00.984092] apply_controller > Done. Stopping robot. Value of run [24.478720]\n",
      "[2018-05-12 18:34:00.985432] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:34:00.986383] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:34:00.990774] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 18:34:00.992623] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:34:01.008942] target_dyn_opt > Initial loss [-5.030327142060633]\n",
      "\u001b[2K[2018-05-12 18:34:18.817892] target_dyn_opt > Curr loss: -7.570787E+00 [1904: -8.189936E+00], n_evals: 1999, Avg. time per updt: 0.007436\n",
      "[2018-05-12 18:34:18.830551] target_dyn_opt > Done training. New loss [-7.896636] iter: [2000]\n",
      "[2018-05-12 18:34:18.833365] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:34:18.835012] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_12.zip\n",
      "[2018-05-12 18:34:19.443964] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_12.zip\n",
      "[2018-05-12 18:34:19.545318] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_12.zip\n",
      "[2018-05-12 18:34:22.027671] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 18:34:22.032770] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:34:22.164834] SGDOptimizer > Initial loss [48278.390625]\n",
      "\u001b[2K[2018-05-12 18:36:07.870748] SGDOptimizer > Curr loss: 1.456780E+04, n_evals: 999, Avg. time per updt: 0.104401\n",
      "[2018-05-12 18:36:07.899878] SGDOptimizer > Done training. New loss [16969.351562] iter: [999]\n",
      "[2018-05-12 18:36:07.901646] apply_controller > Starting run\n",
      "[2018-05-12 18:36:07.902827] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:36:08.145765] apply_controller > Done. Stopping robot. Value of run [29.068411]\n",
      "[2018-05-12 18:36:08.147136] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:36:08.148396] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:36:08.151867] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 18:36:08.153115] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:36:08.170094] target_dyn_opt > Initial loss [-6.720657154614923]\n",
      "\u001b[2K[2018-05-12 18:36:26.201381] target_dyn_opt > Curr loss: -8.486809E+00 [1772: -8.703479E+00], n_evals: 1999, Avg. time per updt: 0.007533\n",
      "[2018-05-12 18:36:26.215088] target_dyn_opt > Done training. New loss [-8.693795] iter: [2000]\n",
      "[2018-05-12 18:36:26.218068] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:36:26.219587] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_13.zip\n",
      "[2018-05-12 18:36:26.864261] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_13.zip\n",
      "[2018-05-12 18:36:26.965577] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_13.zip\n",
      "[2018-05-12 18:36:29.465888] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 18:36:29.471164] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:36:29.601777] SGDOptimizer > Initial loss [18085.607421875]\n",
      "\u001b[2K[2018-05-12 18:38:14.716386] SGDOptimizer > Curr loss: 3.019063E+04, n_evals: 999, Avg. time per updt: 0.103813\n",
      "[2018-05-12 18:38:14.742625] SGDOptimizer > Done training. New loss [24060.908203] iter: [999]\n",
      "[2018-05-12 18:38:14.744496] apply_controller > Starting run\n",
      "[2018-05-12 18:38:14.745879] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:38:14.926695] apply_controller > Done. Stopping robot. Value of run [28.978449]\n",
      "[2018-05-12 18:38:14.928261] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:38:14.929518] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:38:14.933181] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 18:38:14.934556] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:38:14.951326] target_dyn_opt > Initial loss [-7.030451164308978]\n",
      "\u001b[2K[2018-05-12 18:38:32.954643] target_dyn_opt > Curr loss: -8.888142E+00 [1829: -9.277110E+00], n_evals: 1999, Avg. time per updt: 0.007516\n",
      "[2018-05-12 18:38:32.967781] target_dyn_opt > Done training. New loss [-8.632411] iter: [2000]\n",
      "[2018-05-12 18:38:32.970484] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:38:32.971839] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_14.zip\n",
      "[2018-05-12 18:38:33.660444] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_14.zip\n",
      "[2018-05-12 18:38:33.767305] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_14.zip\n",
      "[2018-05-12 18:38:36.271474] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 18:38:36.277374] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:38:36.423385] SGDOptimizer > Initial loss [24716.794921875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:40:25.483579] SGDOptimizer > Curr loss: 1.258405E+04, n_evals: 999, Avg. time per updt: 0.107769\n",
      "[2018-05-12 18:40:25.508662] SGDOptimizer > Done training. New loss [11852.201172] iter: [999]\n",
      "[2018-05-12 18:40:25.510430] apply_controller > Starting run\n",
      "[2018-05-12 18:40:25.511905] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:40:25.684192] apply_controller > Done. Stopping robot. Value of run [28.420656]\n",
      "[2018-05-12 18:40:25.685524] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:40:25.686885] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:40:25.690083] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 18:40:25.691584] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:40:25.706010] target_dyn_opt > Initial loss [-7.930185625377785]\n",
      "\u001b[2K[2018-05-12 18:40:43.822502] target_dyn_opt > Curr loss: -9.295877E+00 [1970: -9.622886E+00], n_evals: 1999, Avg. time per updt: 0.007581\n",
      "[2018-05-12 18:40:43.835192] target_dyn_opt > Done training. New loss [-8.727267] iter: [2000]\n",
      "[2018-05-12 18:40:43.837695] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:40:43.839136] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_15.zip\n",
      "[2018-05-12 18:40:44.574735] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_15.zip\n",
      "[2018-05-12 18:40:44.676748] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_15.zip\n",
      "[2018-05-12 18:40:49.061839] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 18:40:49.067087] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:40:49.196752] SGDOptimizer > Initial loss [9133.998046875]\n",
      "\u001b[2K[2018-05-12 18:42:32.199078] SGDOptimizer > Curr loss: 3.745184E+04, n_evals: 999, Avg. time per updt: 0.101707\n",
      "[2018-05-12 18:42:32.223292] SGDOptimizer > Done training. New loss [30301.699219] iter: [999]\n",
      "[2018-05-12 18:42:32.225122] apply_controller > Starting run\n",
      "[2018-05-12 18:42:32.226445] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:42:32.397070] apply_controller > Done. Stopping robot. Value of run [24.272949]\n",
      "[2018-05-12 18:42:32.398294] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:42:32.399683] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:42:32.405081] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 18:42:32.406481] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:42:32.421111] target_dyn_opt > Initial loss [-8.02787181355709]\n",
      "\u001b[2K[2018-05-12 18:42:50.102291] target_dyn_opt > Curr loss: -9.713243E+00 [1417: -1.002886E+01], n_evals: 1999, Avg. time per updt: 0.007363\n",
      "[2018-05-12 18:42:50.117740] target_dyn_opt > Done training. New loss [-9.242538] iter: [2000]\n",
      "[2018-05-12 18:42:50.120558] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:42:50.122397] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_16.zip\n",
      "[2018-05-12 18:42:50.902189] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_16.zip\n",
      "[2018-05-12 18:42:51.005064] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_16.zip\n",
      "[2018-05-12 18:42:53.516711] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 18:42:53.522578] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:42:53.651255] SGDOptimizer > Initial loss [38324.515625]\n",
      "\u001b[2K[2018-05-12 18:44:39.986224] SGDOptimizer > Curr loss: 1.255081E+04, n_evals: 999, Avg. time per updt: 0.105036\n",
      "[2018-05-12 18:44:40.010960] SGDOptimizer > Done training. New loss [12891.431641] iter: [999]\n",
      "[2018-05-12 18:44:40.013051] apply_controller > Starting run\n",
      "[2018-05-12 18:44:40.014369] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:44:40.190575] apply_controller > Done. Stopping robot. Value of run [26.283020]\n",
      "[2018-05-12 18:44:40.192012] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:44:40.193329] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:44:40.197220] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 18:44:40.198475] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:44:40.213056] target_dyn_opt > Initial loss [-6.1859179971689695]\n",
      "\u001b[2K[2018-05-12 18:45:00.275332] target_dyn_opt > Curr loss: -9.727232E+00 [1604: -1.030686E+01], n_evals: 1999, Avg. time per updt: 0.008504\n",
      "[2018-05-12 18:45:00.289190] target_dyn_opt > Done training. New loss [-10.055898] iter: [2000]\n",
      "[2018-05-12 18:45:00.292080] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:45:00.293773] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_17.zip\n",
      "[2018-05-12 18:45:01.104715] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_17.zip\n",
      "[2018-05-12 18:45:01.208121] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_17.zip\n",
      "[2018-05-12 18:45:03.711705] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 18:45:03.716967] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:45:03.851586] SGDOptimizer > Initial loss [21477.474609375]\n",
      "\u001b[2K[2018-05-12 18:46:53.272408] SGDOptimizer > Curr loss: 1.595699E+04, n_evals: 999, Avg. time per updt: 0.108064\n",
      "[2018-05-12 18:46:53.297240] SGDOptimizer > Done training. New loss [17262.632812] iter: [999]\n",
      "[2018-05-12 18:46:53.299074] apply_controller > Starting run\n",
      "[2018-05-12 18:46:53.300582] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:46:53.477545] apply_controller > Done. Stopping robot. Value of run [29.721409]\n",
      "[2018-05-12 18:46:53.479159] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:46:53.480733] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:46:53.484743] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 18:46:53.486074] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:46:53.502805] target_dyn_opt > Initial loss [-8.500170460602982]\n",
      "\u001b[2K[2018-05-12 18:47:11.468478] target_dyn_opt > Curr loss: -1.010357E+01 [1619: -1.067989E+01], n_evals: 1999, Avg. time per updt: 0.007506\n",
      "[2018-05-12 18:47:11.481638] target_dyn_opt > Done training. New loss [-10.229236] iter: [2000]\n",
      "[2018-05-12 18:47:11.484417] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:47:11.486114] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_18.zip\n",
      "[2018-05-12 18:47:12.341445] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_18.zip\n",
      "[2018-05-12 18:47:12.444212] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_18.zip\n",
      "[2018-05-12 18:47:14.943784] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 18:47:14.949181] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:47:15.077936] SGDOptimizer > Initial loss [20440.314453125]\n",
      "\u001b[2K[2018-05-12 18:49:03.978402] SGDOptimizer > Curr loss: 1.235183E+04, n_evals: 999, Avg. time per updt: 0.107577\n",
      "[2018-05-12 18:49:04.006392] SGDOptimizer > Done training. New loss [10672.977539] iter: [999]\n",
      "[2018-05-12 18:49:04.008047] apply_controller > Starting run\n",
      "[2018-05-12 18:49:04.009349] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:49:04.174406] apply_controller > Done. Stopping robot. Value of run [29.464809]\n",
      "[2018-05-12 18:49:04.175905] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:49:04.177190] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:49:04.181283] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 18:49:04.182553] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:49:04.199022] target_dyn_opt > Initial loss [-8.209677924858084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 18:49:22.005316] target_dyn_opt > Curr loss: -1.073867E+01 [1839: -1.108668E+01], n_evals: 1999, Avg. time per updt: 0.007419\n",
      "[2018-05-12 18:49:22.018121] target_dyn_opt > Done training. New loss [-10.245923] iter: [2000]\n",
      "[2018-05-12 18:49:22.021046] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:49:22.022408] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_19.zip\n",
      "[2018-05-12 18:49:22.927869] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_19.zip\n",
      "[2018-05-12 18:49:23.029309] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_19.zip\n",
      "[2018-05-12 18:49:25.549078] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 18:49:25.554235] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:49:25.684238] SGDOptimizer > Initial loss [18763.236328125]\n",
      "\u001b[2K[2018-05-12 18:51:09.051585] SGDOptimizer > Curr loss: 2.384082E+04, n_evals: 999, Avg. time per updt: 0.102074\n",
      "[2018-05-12 18:51:09.078842] SGDOptimizer > Done training. New loss [14840.610352] iter: [999]\n",
      "[2018-05-12 18:51:09.080650] apply_controller > Starting run\n",
      "[2018-05-12 18:51:09.081924] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:51:09.300268] apply_controller > Done. Stopping robot. Value of run [29.905176]\n",
      "[2018-05-12 18:51:09.301698] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:51:09.302871] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:51:09.307178] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 18:51:09.308440] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:51:09.324748] target_dyn_opt > Initial loss [-9.271064153959598]\n",
      "\u001b[2K[2018-05-12 18:51:31.174961] target_dyn_opt > Curr loss: -1.106888E+01 [1770: -1.129142E+01], n_evals: 1999, Avg. time per updt: 0.009363\n",
      "[2018-05-12 18:51:31.198010] target_dyn_opt > Done training. New loss [-10.738486] iter: [2000]\n",
      "[2018-05-12 18:51:31.201615] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:51:31.203219] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_20.zip\n",
      "[2018-05-12 18:51:32.366470] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_20.zip\n",
      "[2018-05-12 18:51:32.470012] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_20.zip\n",
      "[2018-05-12 18:51:35.118910] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 18:51:35.124382] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:51:35.253816] SGDOptimizer > Initial loss [15092.8056640625]\n",
      "\u001b[2K[2018-05-12 18:53:26.100599] SGDOptimizer > Curr loss: 2.395182E+04, n_evals: 999, Avg. time per updt: 0.109540\n",
      "[2018-05-12 18:53:26.125314] SGDOptimizer > Done training. New loss [23158.564453] iter: [999]\n",
      "[2018-05-12 18:53:26.127161] apply_controller > Starting run\n",
      "[2018-05-12 18:53:26.128441] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:53:26.303979] apply_controller > Done. Stopping robot. Value of run [29.815540]\n",
      "[2018-05-12 18:53:26.305298] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:53:26.306513] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:53:26.310926] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 18:53:26.312569] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:53:26.326680] target_dyn_opt > Initial loss [-8.919259407910808]\n",
      "\u001b[2K[2018-05-12 18:53:44.192124] target_dyn_opt > Curr loss: -1.119882E+01 [1619: -1.164348E+01], n_evals: 1999, Avg. time per updt: 0.007475\n",
      "[2018-05-12 18:53:44.205071] target_dyn_opt > Done training. New loss [-11.321265] iter: [2000]\n",
      "[2018-05-12 18:53:44.207826] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:53:44.209724] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_21.zip\n",
      "[2018-05-12 18:53:45.187119] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_21.zip\n",
      "[2018-05-12 18:53:45.289712] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_21.zip\n",
      "[2018-05-12 18:53:47.804838] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 18:53:47.810572] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:53:47.956379] SGDOptimizer > Initial loss [25904.072265625]\n",
      "\u001b[2K[2018-05-12 18:55:36.527194] SGDOptimizer > Curr loss: 1.152047E+04, n_evals: 999, Avg. time per updt: 0.107213\n",
      "[2018-05-12 18:55:36.552280] SGDOptimizer > Done training. New loss [10554.502930] iter: [999]\n",
      "[2018-05-12 18:55:36.554416] apply_controller > Starting run\n",
      "[2018-05-12 18:55:36.555884] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:55:36.734759] apply_controller > Done. Stopping robot. Value of run [22.585712]\n",
      "[2018-05-12 18:55:36.736270] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:55:36.737496] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:55:36.741920] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 18:55:36.743286] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:55:36.757552] target_dyn_opt > Initial loss [-7.074496658845641]\n",
      "\u001b[2K[2018-05-12 18:55:54.571885] target_dyn_opt > Curr loss: -1.162786E+01 [1720: -1.175572E+01], n_evals: 1999, Avg. time per updt: 0.007424\n",
      "[2018-05-12 18:55:54.584639] target_dyn_opt > Done training. New loss [-11.192965] iter: [2000]\n",
      "[2018-05-12 18:55:54.587518] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:55:54.589251] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_22.zip\n",
      "[2018-05-12 18:55:55.608997] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_22.zip\n",
      "[2018-05-12 18:55:55.711433] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_22.zip\n",
      "[2018-05-12 18:55:58.239933] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 18:55:58.245372] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:55:58.376001] SGDOptimizer > Initial loss [14708.9794921875]\n",
      "\u001b[2K[2018-05-12 18:57:47.117418] SGDOptimizer > Curr loss: 3.378782E+04, n_evals: 999, Avg. time per updt: 0.107393\n",
      "[2018-05-12 18:57:47.144136] SGDOptimizer > Done training. New loss [31941.712891] iter: [999]\n",
      "[2018-05-12 18:57:47.146232] apply_controller > Starting run\n",
      "[2018-05-12 18:57:47.147791] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 18:57:47.322763] apply_controller > Done. Stopping robot. Value of run [29.871780]\n",
      "[2018-05-12 18:57:47.324098] target_2x_mass > Stopping robot\n",
      "[2018-05-12 18:57:47.325421] train_dynamics > Training dynamics model\n",
      "[2018-05-12 18:57:47.329847] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 18:57:47.331247] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 18:57:47.347916] target_dyn_opt > Initial loss [-9.929558729881357]\n",
      "\u001b[2K[2018-05-12 18:58:05.644748] target_dyn_opt > Curr loss: -1.159093E+01 [1943: -1.201631E+01], n_evals: 1999, Avg. time per updt: 0.007673\n",
      "[2018-05-12 18:58:05.658713] target_dyn_opt > Done training. New loss [-11.364474] iter: [2000]\n",
      "[2018-05-12 18:58:05.661428] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 18:58:05.663231] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_23.zip\n",
      "[2018-05-12 18:58:06.730562] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_23.zip\n",
      "[2018-05-12 18:58:06.835815] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_23.zip\n",
      "[2018-05-12 18:58:09.345729] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 18:58:09.351477] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 18:58:09.501060] SGDOptimizer > Initial loss [31288.822265625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 19:00:00.537035] SGDOptimizer > Curr loss: 2.311229E+04, n_evals: 999, Avg. time per updt: 0.109729\n",
      "[2018-05-12 19:00:00.563348] SGDOptimizer > Done training. New loss [14469.771484] iter: [999]\n",
      "[2018-05-12 19:00:00.565282] apply_controller > Starting run\n",
      "[2018-05-12 19:00:00.566809] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:00:00.735036] apply_controller > Done. Stopping robot. Value of run [28.099049]\n",
      "[2018-05-12 19:00:00.736433] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:00:00.737978] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:00:00.742253] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 19:00:00.743542] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:00:00.757698] target_dyn_opt > Initial loss [-9.43703396492991]\n",
      "\u001b[2K[2018-05-12 19:00:18.373511] target_dyn_opt > Curr loss: -1.205195E+01 [1556: -1.218129E+01], n_evals: 1999, Avg. time per updt: 0.007344\n",
      "[2018-05-12 19:00:18.386648] target_dyn_opt > Done training. New loss [-11.371996] iter: [2000]\n",
      "[2018-05-12 19:00:18.391324] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:00:18.392946] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_24.zip\n",
      "[2018-05-12 19:00:19.512717] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_24.zip\n",
      "[2018-05-12 19:00:19.619589] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_24.zip\n",
      "[2018-05-12 19:00:22.161176] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 19:00:22.166236] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:00:22.303272] SGDOptimizer > Initial loss [19297.72265625]\n",
      "\u001b[2K[2018-05-12 19:02:13.821858] SGDOptimizer > Curr loss: 1.870514E+04, n_evals: 999, Avg. time per updt: 0.110164\n",
      "[2018-05-12 19:02:13.848035] SGDOptimizer > Done training. New loss [18553.951172] iter: [999]\n",
      "[2018-05-12 19:02:13.849795] apply_controller > Starting run\n",
      "[2018-05-12 19:02:13.851034] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:02:14.025675] apply_controller > Done. Stopping robot. Value of run [29.793797]\n",
      "[2018-05-12 19:02:14.026885] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:02:14.028408] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:02:14.033140] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 19:02:14.034424] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:02:14.051520] target_dyn_opt > Initial loss [-9.988703667267721]\n",
      "\u001b[2K[2018-05-12 19:02:35.482169] target_dyn_opt > Curr loss: -1.188268E+01 [1859: -1.246441E+01], n_evals: 1999, Avg. time per updt: 0.009151\n",
      "[2018-05-12 19:02:35.495988] target_dyn_opt > Done training. New loss [-12.227940] iter: [2000]\n",
      "[2018-05-12 19:02:35.498464] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:02:35.499785] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_25.zip\n",
      "[2018-05-12 19:02:36.659892] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_25.zip\n",
      "[2018-05-12 19:02:36.763508] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_25.zip\n",
      "[2018-05-12 19:02:39.284289] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 19:02:39.289494] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:02:39.433958] SGDOptimizer > Initial loss [20726.474609375]\n",
      "\u001b[2K[2018-05-12 19:04:28.738422] SGDOptimizer > Curr loss: 1.323460E+04, n_evals: 999, Avg. time per updt: 0.108001\n",
      "[2018-05-12 19:04:28.768743] SGDOptimizer > Done training. New loss [13043.127930] iter: [999]\n",
      "[2018-05-12 19:04:28.770577] apply_controller > Starting run\n",
      "[2018-05-12 19:04:28.771876] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:04:29.020685] apply_controller > Done. Stopping robot. Value of run [29.094303]\n",
      "[2018-05-12 19:04:29.021971] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:04:29.023251] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:04:29.028252] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 19:04:29.029565] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:04:29.047176] target_dyn_opt > Initial loss [-9.307435519241587]\n",
      "\u001b[2K[2018-05-12 19:04:47.008788] target_dyn_opt > Curr loss: -1.195579E+01 [1987: -1.261471E+01], n_evals: 1999, Avg. time per updt: 0.007513\n",
      "[2018-05-12 19:04:47.024768] target_dyn_opt > Done training. New loss [-12.201139] iter: [2000]\n",
      "[2018-05-12 19:04:47.028084] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:04:47.029781] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_26.zip\n",
      "[2018-05-12 19:04:48.384875] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_26.zip\n",
      "[2018-05-12 19:04:48.491253] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_26.zip\n",
      "[2018-05-12 19:04:51.145184] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 19:04:51.150954] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:04:51.304598] SGDOptimizer > Initial loss [13051.51171875]\n",
      "\u001b[2K[2018-05-12 19:06:40.418506] SGDOptimizer > Curr loss: 1.282300E+04, n_evals: 999, Avg. time per updt: 0.107831\n",
      "[2018-05-12 19:06:40.444913] SGDOptimizer > Done training. New loss [12875.144531] iter: [999]\n",
      "[2018-05-12 19:06:40.447114] apply_controller > Starting run\n",
      "[2018-05-12 19:06:40.448465] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:06:40.626485] apply_controller > Done. Stopping robot. Value of run [28.837791]\n",
      "[2018-05-12 19:06:40.627931] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:06:40.629263] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:06:40.634893] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 19:06:40.636312] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:06:40.651531] target_dyn_opt > Initial loss [-10.940624673451696]\n",
      "\u001b[2K[2018-05-12 19:06:58.679896] target_dyn_opt > Curr loss: -1.259073E+01 [1472: -1.286045E+01], n_evals: 1999, Avg. time per updt: 0.007548\n",
      "[2018-05-12 19:06:58.693053] target_dyn_opt > Done training. New loss [-12.349292] iter: [2000]\n",
      "[2018-05-12 19:06:58.695669] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:06:58.697163] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_27.zip\n",
      "[2018-05-12 19:06:59.933847] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_27.zip\n",
      "[2018-05-12 19:07:00.037917] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_27.zip\n",
      "[2018-05-12 19:07:02.568959] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 19:07:02.574142] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:07:02.708408] SGDOptimizer > Initial loss [11901.240234375]\n",
      "\u001b[2K[2018-05-12 19:08:50.901633] SGDOptimizer > Curr loss: 1.981585E+04, n_evals: 999, Avg. time per updt: 0.106889\n",
      "[2018-05-12 19:08:50.926194] SGDOptimizer > Done training. New loss [23344.783203] iter: [999]\n",
      "[2018-05-12 19:08:50.927974] apply_controller > Starting run\n",
      "[2018-05-12 19:08:50.929582] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:08:51.111096] apply_controller > Done. Stopping robot. Value of run [29.880968]\n",
      "[2018-05-12 19:08:51.112449] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:08:51.113919] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:08:51.118482] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 19:08:51.119736] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:08:51.134470] target_dyn_opt > Initial loss [-9.652976512838062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 19:09:08.939753] target_dyn_opt > Curr loss: -1.243961E+01 [1791: -1.305509E+01], n_evals: 1999, Avg. time per updt: 0.007441\n",
      "[2018-05-12 19:09:08.952958] target_dyn_opt > Done training. New loss [-12.592446] iter: [2000]\n",
      "[2018-05-12 19:09:08.955653] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:09:08.957064] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_28.zip\n",
      "[2018-05-12 19:09:10.251176] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_28.zip\n",
      "[2018-05-12 19:09:10.354843] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_28.zip\n",
      "[2018-05-12 19:09:12.904812] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 19:09:12.911156] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:09:13.066821] SGDOptimizer > Initial loss [17912.044921875]\n",
      "\u001b[2K[2018-05-12 19:11:02.820308] SGDOptimizer > Curr loss: 2.382416E+04, n_evals: 999, Avg. time per updt: 0.108422\n",
      "[2018-05-12 19:11:02.845654] SGDOptimizer > Done training. New loss [22898.125000] iter: [999]\n",
      "[2018-05-12 19:11:02.847598] apply_controller > Starting run\n",
      "[2018-05-12 19:11:02.848960] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:11:03.053739] apply_controller > Done. Stopping robot. Value of run [29.859039]\n",
      "[2018-05-12 19:11:03.054956] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:11:03.056298] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:11:03.061534] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 19:11:03.062856] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:11:03.079419] target_dyn_opt > Initial loss [-9.89231672643245]\n",
      "\u001b[2K[2018-05-12 19:11:26.251295] target_dyn_opt > Curr loss: -1.256907E+01 [1445: -1.319573E+01], n_evals: 1999, Avg. time per updt: 0.009886\n",
      "[2018-05-12 19:11:26.264403] target_dyn_opt > Done training. New loss [-12.636573] iter: [2000]\n",
      "[2018-05-12 19:11:26.267085] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:11:26.268786] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_29.zip\n",
      "[2018-05-12 19:11:27.591943] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_29.zip\n",
      "[2018-05-12 19:11:27.694832] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_29.zip\n",
      "[2018-05-12 19:11:30.226362] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 19:11:30.231463] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 19:11:30.361664] SGDOptimizer > Initial loss [20568.310546875]\n",
      "\u001b[2K[2018-05-12 19:13:19.163142] SGDOptimizer > Curr loss: 2.426105E+04, n_evals: 999, Avg. time per updt: 0.107434\n",
      "[2018-05-12 19:13:19.193581] SGDOptimizer > Done training. New loss [24274.386719] iter: [999]\n",
      "[2018-05-12 19:13:19.195253] apply_controller > Starting run\n",
      "[2018-05-12 19:13:19.196702] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 19:13:19.439194] apply_controller > Done. Stopping robot. Value of run [29.973801]\n",
      "[2018-05-12 19:13:19.440785] target_2x_mass > Stopping robot\n",
      "[2018-05-12 19:13:19.442139] train_dynamics > Training dynamics model\n",
      "[2018-05-12 19:13:19.446815] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 19:13:19.448139] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 19:13:19.465445] target_dyn_opt > Initial loss [-5.348768560321498]\n",
      "\u001b[2K[2018-05-12 19:13:37.332065] target_dyn_opt > Curr loss: -1.272342E+01 [1952: -1.323914E+01], n_evals: 1999, Avg. time per updt: 0.007465\n",
      "[2018-05-12 19:13:37.345132] target_dyn_opt > Done training. New loss [-12.863421] iter: [2000]\n",
      "[2018-05-12 19:13:37.347662] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 19:13:37.349255] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/experience_30.zip\n",
      "[2018-05-12 19:13:38.707634] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/policy_30.zip\n",
      "[2018-05-12 19:13:38.810372] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_003_il_klqp_from_scratch/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 3 learn starting from scratch, using klqp imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_003_il_klqp_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:13:07.022654] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 20:13:07.045435] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 20:13:07.076419] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 20:13:07.089706] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 20:13:07.095354] Experience > Initialising new experience dataset\n",
      "[2018-05-12 20:13:07.096943] Executing uniformly-random controls\n",
      "[2018-05-12 20:13:07.098647] apply_controller > Starting run\n",
      "[2018-05-12 20:13:07.100083] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:13:07.265401] apply_controller > Done. Stopping robot. Value of run [29.808973]\n",
      "[2018-05-12 20:13:07.266742] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:13:07.267972] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:13:07.270836] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 20:13:07.272224] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305090>})\n",
      "[2018-05-12 20:13:07.304038] target_dyn > Initialising loss function\n",
      "[2018-05-12 20:13:07.449808] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 20:13:07.735924] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 20:13:07.737459] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 20:13:07.794441] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 20:13:08.718419] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 20:13:13.567093] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:13:13.574570] target_dyn_opt > Initial loss [1449.0460819028094]\n",
      "\u001b[2K[2018-05-12 20:13:23.726167] target_dyn_opt > Curr loss: 5.120722E+01 [1969: 4.795866E+01], n_evals: 1999, Avg. time per updt: 0.003513\n",
      "[2018-05-12 20:13:23.732170] target_dyn_opt > Done training. New loss [54.190578] iter: [2000]\n",
      "[2018-05-12 20:13:23.958062] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:13:23.996217] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>, 'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7f8d1ea82590>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7f8c7d305c50>})\n",
      "[2018-05-12 20:13:24.155916] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 20:13:24.157103] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 20:13:24.241057] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 20:13:24.242331] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 20:13:24.797464] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 20:13:24.798709] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 20:13:24.885539] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 20:13:24.886886] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 20:13:30.795284] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 20:13:33.979528] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 20:13:33.989546] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 20:13:34.021916] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 20:13:36.985656] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 20:13:55.246334] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_0.zip\n",
      "[2018-05-12 20:13:55.344798] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_0.zip\n",
      "[2018-05-12 20:13:55.453342] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_0.zip\n",
      "[2018-05-12 20:13:55.592438] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 20:13:55.594297] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 20:13:55.600376] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:13:55.814462] SGDOptimizer > Initial loss [1809.6915283203125]\n",
      "\u001b[2K[2018-05-12 20:15:35.430577] SGDOptimizer > Curr loss: 4.369022E+01, n_evals: 999, Avg. time per updt: 0.098318\n",
      "[2018-05-12 20:15:35.458804] SGDOptimizer > Done training. New loss [110.390114] iter: [999]\n",
      "[2018-05-12 20:15:35.461164] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 20:15:35.540221] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 20:15:35.692238] NNPolicy > Done compiling\n",
      "[2018-05-12 20:15:35.693672] apply_controller > Starting run\n",
      "[2018-05-12 20:15:35.694917] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:15:36.074634] apply_controller > Done. Stopping robot. Value of run [26.841860]\n",
      "[2018-05-12 20:15:36.075872] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:15:36.077211] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:15:36.079655] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 20:15:36.087313] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:15:36.098548] target_dyn_opt > Initial loss [156.75030500114923]\n",
      "\u001b[2K[2018-05-12 20:15:48.759590] target_dyn_opt > Curr loss: 2.502083E+01 [1983: 2.290967E+01], n_evals: 1999, Avg. time per updt: 0.004833\n",
      "[2018-05-12 20:15:48.768349] target_dyn_opt > Done training. New loss [24.500931] iter: [2000]\n",
      "[2018-05-12 20:15:48.771099] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:15:48.772927] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_1.zip\n",
      "[2018-05-12 20:15:48.916921] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_1.zip\n",
      "[2018-05-12 20:15:49.023452] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_1.zip\n",
      "[2018-05-12 20:15:51.819620] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 20:15:51.824978] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:15:51.956453] SGDOptimizer > Initial loss [489.1590576171875]\n",
      "\u001b[2K[2018-05-12 20:17:26.029032] SGDOptimizer > Curr loss: 1.518364E+02, n_evals: 999, Avg. time per updt: 0.092771\n",
      "[2018-05-12 20:17:26.053182] SGDOptimizer > Done training. New loss [109.822807] iter: [999]\n",
      "[2018-05-12 20:17:26.055070] apply_controller > Starting run\n",
      "[2018-05-12 20:17:26.056433] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:17:26.306159] apply_controller > Done. Stopping robot. Value of run [27.152744]\n",
      "[2018-05-12 20:17:26.307540] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:17:26.308845] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:17:26.311088] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 20:17:26.312558] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:17:26.325776] target_dyn_opt > Initial loss [135.39488375698346]\n",
      "\u001b[2K[2018-05-12 20:17:42.755637] target_dyn_opt > Curr loss: 1.579651E+01 [1931: 1.322955E+01], n_evals: 1999, Avg. time per updt: 0.006716\n",
      "[2018-05-12 20:17:42.767384] target_dyn_opt > Done training. New loss [14.415502] iter: [2000]\n",
      "[2018-05-12 20:17:42.770241] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:17:42.771759] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_2.zip\n",
      "[2018-05-12 20:17:42.958098] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_2.zip\n",
      "[2018-05-12 20:17:43.059182] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_2.zip\n",
      "[2018-05-12 20:17:45.822069] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 20:17:45.827005] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:17:45.942741] SGDOptimizer > Initial loss [300.6897888183594]\n",
      "\u001b[2K[2018-05-12 20:19:20.402095] SGDOptimizer > Curr loss: 7.409200E+01, n_evals: 999, Avg. time per updt: 0.093154\n",
      "[2018-05-12 20:19:20.430645] SGDOptimizer > Done training. New loss [98.809341] iter: [999]\n",
      "[2018-05-12 20:19:20.432639] apply_controller > Starting run\n",
      "[2018-05-12 20:19:20.433957] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:19:20.651922] apply_controller > Done. Stopping robot. Value of run [29.182371]\n",
      "[2018-05-12 20:19:20.653254] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:19:20.654598] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:19:20.657001] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 20:19:20.658577] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:19:20.672665] target_dyn_opt > Initial loss [51.6355578030293]\n",
      "\u001b[2K[2018-05-12 20:19:38.390340] target_dyn_opt > Curr loss: 9.046230E+00 [1731: 7.585209E+00], n_evals: 1999, Avg. time per updt: 0.007346\n",
      "[2018-05-12 20:19:38.402554] target_dyn_opt > Done training. New loss [8.581415] iter: [2000]\n",
      "[2018-05-12 20:19:38.405340] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:19:38.406808] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_3.zip\n",
      "[2018-05-12 20:19:38.631067] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_3.zip\n",
      "[2018-05-12 20:19:38.735720] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_3.zip\n",
      "[2018-05-12 20:19:41.515402] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 20:19:41.520758] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:19:41.638247] SGDOptimizer > Initial loss [206.2925262451172]\n",
      "\u001b[2K[2018-05-12 20:21:17.990694] SGDOptimizer > Curr loss: 6.084954E+01, n_evals: 999, Avg. time per updt: 0.095054\n",
      "[2018-05-12 20:21:18.014843] SGDOptimizer > Done training. New loss [53.010418] iter: [999]\n",
      "[2018-05-12 20:21:18.016628] apply_controller > Starting run\n",
      "[2018-05-12 20:21:18.017907] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:21:18.264860] apply_controller > Done. Stopping robot. Value of run [28.167542]\n",
      "[2018-05-12 20:21:18.266461] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:21:18.267746] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:21:18.270398] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 20:21:18.272081] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:21:18.288474] target_dyn_opt > Initial loss [33.07630306505598]\n",
      "\u001b[2K[2018-05-12 20:21:36.640217] target_dyn_opt > Curr loss: 7.188378E+00 [1855: 4.112478E+00], n_evals: 1999, Avg. time per updt: 0.007603\n",
      "[2018-05-12 20:21:36.652971] target_dyn_opt > Done training. New loss [4.618518] iter: [2000]\n",
      "[2018-05-12 20:21:36.655521] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:21:36.656885] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_4.zip\n",
      "[2018-05-12 20:21:36.944474] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_4.zip\n",
      "[2018-05-12 20:21:37.046030] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_4.zip\n",
      "[2018-05-12 20:21:40.147284] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 20:21:40.153056] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:21:40.297570] SGDOptimizer > Initial loss [187.55487060546875]\n",
      "\u001b[2K[2018-05-12 20:23:23.936250] SGDOptimizer > Curr loss: 1.369909E+02, n_evals: 999, Avg. time per updt: 0.102307\n",
      "[2018-05-12 20:23:23.969967] SGDOptimizer > Done training. New loss [131.286987] iter: [999]\n",
      "[2018-05-12 20:23:23.974067] apply_controller > Starting run\n",
      "[2018-05-12 20:23:23.975467] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:23:24.265974] apply_controller > Done. Stopping robot. Value of run [28.956675]\n",
      "[2018-05-12 20:23:24.266959] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:23:24.267741] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:23:24.274696] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 20:23:24.276638] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:23:24.321608] target_dyn_opt > Initial loss [10.952441990602997]\n",
      "\u001b[2K[2018-05-12 20:23:43.744304] target_dyn_opt > Curr loss: 2.908167E+00 [1994: 1.429534E+00], n_evals: 1999, Avg. time per updt: 0.008055\n",
      "[2018-05-12 20:23:43.760418] target_dyn_opt > Done training. New loss [2.724225] iter: [2000]\n",
      "[2018-05-12 20:23:43.763163] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:23:43.766360] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_5.zip\n",
      "[2018-05-12 20:23:44.148828] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_5.zip\n",
      "[2018-05-12 20:23:44.272551] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_5.zip\n",
      "[2018-05-12 20:23:47.592825] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 20:23:47.598005] SGDOptimizer > Optimizing parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 20:23:47.752621] SGDOptimizer > Initial loss [183.74156188964844]\n",
      "\u001b[2K[2018-05-12 20:25:35.594984] SGDOptimizer > Curr loss: 9.030720E+01, n_evals: 999, Avg. time per updt: 0.106446\n",
      "[2018-05-12 20:25:35.620236] SGDOptimizer > Done training. New loss [88.412155] iter: [999]\n",
      "[2018-05-12 20:25:35.622412] apply_controller > Starting run\n",
      "[2018-05-12 20:25:35.623761] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:25:35.806487] apply_controller > Done. Stopping robot. Value of run [29.997684]\n",
      "[2018-05-12 20:25:35.807713] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:25:35.808982] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:25:35.812052] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 20:25:35.813794] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:25:35.830479] target_dyn_opt > Initial loss [5.547990425266188]\n",
      "\u001b[2K[2018-05-12 20:25:53.594466] target_dyn_opt > Curr loss: 7.135745E-01 [1566: -3.422650E-01], n_evals: 1999, Avg. time per updt: 0.0073343\n",
      "[2018-05-12 20:25:53.609665] target_dyn_opt > Done training. New loss [1.333639] iter: [2000]\n",
      "[2018-05-12 20:25:53.612649] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:25:53.614100] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_6.zip\n",
      "[2018-05-12 20:25:54.021297] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_6.zip\n",
      "[2018-05-12 20:25:54.129343] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_6.zip\n",
      "[2018-05-12 20:25:57.200105] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 20:25:57.205470] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:25:57.325275] SGDOptimizer > Initial loss [116.95795440673828]\n",
      "\u001b[2K[2018-05-12 20:27:37.160601] SGDOptimizer > Curr loss: 7.166201E+01, n_evals: 999, Avg. time per updt: 0.098490\n",
      "[2018-05-12 20:27:37.184538] SGDOptimizer > Done training. New loss [65.098305] iter: [999]\n",
      "[2018-05-12 20:27:37.186698] apply_controller > Starting run\n",
      "[2018-05-12 20:27:37.188053] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:27:37.409493] apply_controller > Done. Stopping robot. Value of run [28.743435]\n",
      "[2018-05-12 20:27:37.410701] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:27:37.413630] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:27:37.416299] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 20:27:37.418154] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:27:37.432501] target_dyn_opt > Initial loss [13.578265984734351]\n",
      "\u001b[2K[2018-05-12 20:27:54.513754] target_dyn_opt > Curr loss: -1.136976E+00 [1274: -1.611615E+00], n_evals: 1999, Avg. time per updt: 0.007065\n",
      "[2018-05-12 20:27:54.526700] target_dyn_opt > Done training. New loss [-0.532303] iter: [2000]\n",
      "[2018-05-12 20:27:54.529278] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:27:54.530606] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_7.zip\n",
      "[2018-05-12 20:27:54.918391] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_7.zip\n",
      "[2018-05-12 20:27:55.013753] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_7.zip\n",
      "[2018-05-12 20:27:57.782139] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 20:27:57.787456] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:27:57.910145] SGDOptimizer > Initial loss [161.6786651611328]\n",
      "\u001b[2K[2018-05-12 20:29:30.681287] SGDOptimizer > Curr loss: 1.887861E+02, n_evals: 999, Avg. time per updt: 0.091491\n",
      "[2018-05-12 20:29:30.704178] SGDOptimizer > Done training. New loss [236.822723] iter: [999]\n",
      "[2018-05-12 20:29:30.706285] apply_controller > Starting run\n",
      "[2018-05-12 20:29:30.707669] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:29:30.897058] apply_controller > Done. Stopping robot. Value of run [29.897728]\n",
      "[2018-05-12 20:29:30.898393] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:29:30.899689] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:29:30.902242] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 20:29:30.903624] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:29:30.917594] target_dyn_opt > Initial loss [3.8736015477314076]\n",
      "\u001b[2K[2018-05-12 20:29:48.426993] target_dyn_opt > Curr loss: -1.598387E+00 [1582: -2.750037E+00], n_evals: 1999, Avg. time per updt: 0.007300\n",
      "[2018-05-12 20:29:48.441330] target_dyn_opt > Done training. New loss [-1.803476] iter: [2000]\n",
      "[2018-05-12 20:29:48.443937] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:29:48.445347] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_8.zip\n",
      "[2018-05-12 20:29:48.920257] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_8.zip\n",
      "[2018-05-12 20:29:49.017543] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_8.zip\n",
      "[2018-05-12 20:29:51.808706] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 20:29:51.814217] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:29:51.937895] SGDOptimizer > Initial loss [108.95458984375]\n",
      "\u001b[2K[2018-05-12 20:31:27.088706] SGDOptimizer > Curr loss: 7.760637E+01, n_evals: 999, Avg. time per updt: 0.093841\n",
      "[2018-05-12 20:31:27.112885] SGDOptimizer > Done training. New loss [58.210728] iter: [999]\n",
      "[2018-05-12 20:31:27.114745] apply_controller > Starting run\n",
      "[2018-05-12 20:31:27.115585] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:31:27.306177] apply_controller > Done. Stopping robot. Value of run [28.128326]\n",
      "[2018-05-12 20:31:27.307796] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:31:27.308756] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:31:27.312060] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 20:31:27.315894] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:31:27.331579] target_dyn_opt > Initial loss [-1.8946908533187772]\n",
      "\u001b[2K[2018-05-12 20:31:44.798805] target_dyn_opt > Curr loss: -3.101903E+00 [1713: -3.818303E+00], n_evals: 1999, Avg. time per updt: 0.007258\n",
      "[2018-05-12 20:31:44.816615] target_dyn_opt > Done training. New loss [-3.105309] iter: [2000]\n",
      "[2018-05-12 20:31:44.819221] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:31:44.820881] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_9.zip\n",
      "[2018-05-12 20:31:45.320258] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_9.zip\n",
      "[2018-05-12 20:31:45.421682] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_9.zip\n",
      "[2018-05-12 20:31:48.437659] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 20:31:48.442910] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:31:48.573479] SGDOptimizer > Initial loss [51.32132339477539]\n",
      "\u001b[2K[2018-05-12 20:33:26.698792] SGDOptimizer > Curr loss: 7.202946E+01, n_evals: 999, Avg. time per updt: 0.096835\n",
      "[2018-05-12 20:33:26.721935] SGDOptimizer > Done training. New loss [54.434517] iter: [999]\n",
      "[2018-05-12 20:33:26.723589] apply_controller > Starting run\n",
      "[2018-05-12 20:33:26.724878] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:33:26.926562] apply_controller > Done. Stopping robot. Value of run [29.890650]\n",
      "[2018-05-12 20:33:26.927896] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:33:26.928850] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:33:26.932251] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-12 20:33:26.933222] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:33:26.946573] target_dyn_opt > Initial loss [-0.3213394027331784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:33:46.041886] target_dyn_opt > Curr loss: -3.845105E+00 [1941: -4.612096E+00], n_evals: 1999, Avg. time per updt: 0.008042\n",
      "[2018-05-12 20:33:46.054923] target_dyn_opt > Done training. New loss [-3.908500] iter: [2000]\n",
      "[2018-05-12 20:33:46.057763] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:33:46.059285] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_10.zip\n",
      "[2018-05-12 20:33:46.578953] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_10.zip\n",
      "[2018-05-12 20:33:46.677389] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_10.zip\n",
      "[2018-05-12 20:33:49.482247] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 20:33:49.487934] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:33:49.614617] SGDOptimizer > Initial loss [85.52481079101562]\n",
      "\u001b[2K[2018-05-12 20:35:25.287344] SGDOptimizer > Curr loss: 7.315050E+01, n_evals: 999, Avg. time per updt: 0.094382\n",
      "[2018-05-12 20:35:25.311706] SGDOptimizer > Done training. New loss [79.855682] iter: [999]\n",
      "[2018-05-12 20:35:25.313370] apply_controller > Starting run\n",
      "[2018-05-12 20:35:25.314656] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:35:25.497937] apply_controller > Done. Stopping robot. Value of run [29.374386]\n",
      "[2018-05-12 20:35:25.499279] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:35:25.500778] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:35:25.504044] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 20:35:25.505431] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:35:25.521143] target_dyn_opt > Initial loss [-4.064233961568653]\n",
      "\u001b[2K[2018-05-12 20:35:43.074435] target_dyn_opt > Curr loss: -4.710786E+00 [1936: -5.622435E+00], n_evals: 1999, Avg. time per updt: 0.007301\n",
      "[2018-05-12 20:35:43.087177] target_dyn_opt > Done training. New loss [-4.884670] iter: [2000]\n",
      "[2018-05-12 20:35:43.090265] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:35:43.091877] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_11.zip\n",
      "[2018-05-12 20:35:43.656348] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_11.zip\n",
      "[2018-05-12 20:35:43.753910] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_11.zip\n",
      "[2018-05-12 20:35:46.562500] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 20:35:46.567623] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:35:46.710143] SGDOptimizer > Initial loss [99.30023956298828]\n",
      "\u001b[2K[2018-05-12 20:37:22.434797] SGDOptimizer > Curr loss: 7.271214E+01, n_evals: 999, Avg. time per updt: 0.094416\n",
      "[2018-05-12 20:37:22.460444] SGDOptimizer > Done training. New loss [66.544167] iter: [999]\n",
      "[2018-05-12 20:37:22.462410] apply_controller > Starting run\n",
      "[2018-05-12 20:37:22.463953] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:37:22.659869] apply_controller > Done. Stopping robot. Value of run [27.098261]\n",
      "[2018-05-12 20:37:22.661368] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:37:22.662682] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:37:22.666444] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 20:37:22.667872] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:37:22.683865] target_dyn_opt > Initial loss [-4.39454162794731]\n",
      "\u001b[2K[2018-05-12 20:37:41.544293] target_dyn_opt > Curr loss: -5.564897E+00 [1898: -6.305591E+00], n_evals: 1999, Avg. time per updt: 0.007901\n",
      "[2018-05-12 20:37:41.557509] target_dyn_opt > Done training. New loss [-5.960584] iter: [2000]\n",
      "[2018-05-12 20:37:41.560682] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:37:41.562164] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_12.zip\n",
      "[2018-05-12 20:37:42.150433] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_12.zip\n",
      "[2018-05-12 20:37:42.245406] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_12.zip\n",
      "[2018-05-12 20:37:45.027046] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 20:37:45.032001] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:37:45.152270] SGDOptimizer > Initial loss [64.31504821777344]\n",
      "\u001b[2K[2018-05-12 20:39:23.754914] SGDOptimizer > Curr loss: 8.437412E+01, n_evals: 999, Avg. time per updt: 0.097318\n",
      "[2018-05-12 20:39:23.786345] SGDOptimizer > Done training. New loss [91.379051] iter: [999]\n",
      "[2018-05-12 20:39:23.788077] apply_controller > Starting run\n",
      "[2018-05-12 20:39:23.789274] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:39:24.012045] apply_controller > Done. Stopping robot. Value of run [29.190010]\n",
      "[2018-05-12 20:39:24.013684] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:39:24.014959] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:39:24.018126] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 20:39:24.019667] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:39:24.034287] target_dyn_opt > Initial loss [-4.075117544605961]\n",
      "\u001b[2K[2018-05-12 20:39:41.972257] target_dyn_opt > Curr loss: -6.111131E+00 [992: -6.830262E+00], n_evals: 1999, Avg. time per updt: 0.007497\n",
      "[2018-05-12 20:39:41.985400] target_dyn_opt > Done training. New loss [-6.536750] iter: [2000]\n",
      "[2018-05-12 20:39:41.988204] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:39:41.989532] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_13.zip\n",
      "[2018-05-12 20:39:42.626781] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_13.zip\n",
      "[2018-05-12 20:39:42.721607] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_13.zip\n",
      "[2018-05-12 20:39:45.521374] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 20:39:45.526416] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:39:45.650388] SGDOptimizer > Initial loss [99.39570617675781]\n",
      "\u001b[2K[2018-05-12 20:41:24.435499] SGDOptimizer > Curr loss: 1.389257E+02, n_evals: 999, Avg. time per updt: 0.097490\n",
      "[2018-05-12 20:41:24.462094] SGDOptimizer > Done training. New loss [253.574905] iter: [999]\n",
      "[2018-05-12 20:41:24.463748] apply_controller > Starting run\n",
      "[2018-05-12 20:41:24.464950] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:41:24.650845] apply_controller > Done. Stopping robot. Value of run [28.766054]\n",
      "[2018-05-12 20:41:24.652530] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:41:24.655861] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:41:24.665664] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 20:41:24.666935] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:41:24.683860] target_dyn_opt > Initial loss [-5.984883029878825]\n",
      "\u001b[2K[2018-05-12 20:41:42.672928] target_dyn_opt > Curr loss: -6.785939E+00 [1742: -7.443015E+00], n_evals: 1999, Avg. time per updt: 0.007510\n",
      "[2018-05-12 20:41:42.686322] target_dyn_opt > Done training. New loss [-6.654930] iter: [2000]\n",
      "[2018-05-12 20:41:42.689105] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:41:42.690466] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_14.zip\n",
      "[2018-05-12 20:41:43.372293] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_14.zip\n",
      "[2018-05-12 20:41:43.468864] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_14.zip\n",
      "[2018-05-12 20:41:46.270002] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-12 20:41:46.275105] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:41:46.419965] SGDOptimizer > Initial loss [97.5036392211914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:43:26.496291] SGDOptimizer > Curr loss: 9.777536E+01, n_evals: 999, Avg. time per updt: 0.098778\n",
      "[2018-05-12 20:43:26.522299] SGDOptimizer > Done training. New loss [89.084068] iter: [999]\n",
      "[2018-05-12 20:43:26.524153] apply_controller > Starting run\n",
      "[2018-05-12 20:43:26.525455] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:43:26.709600] apply_controller > Done. Stopping robot. Value of run [29.969034]\n",
      "[2018-05-12 20:43:26.710988] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:43:26.712875] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:43:26.716548] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 20:43:26.717837] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:43:26.734353] target_dyn_opt > Initial loss [-5.8900237881161015]\n",
      "\u001b[2K[2018-05-12 20:43:44.551802] target_dyn_opt > Curr loss: -7.737148E+00 [1270: -7.983390E+00], n_evals: 1999, Avg. time per updt: 0.007422\n",
      "[2018-05-12 20:43:44.564506] target_dyn_opt > Done training. New loss [-7.297037] iter: [2000]\n",
      "[2018-05-12 20:43:44.567045] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:43:44.568436] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_15.zip\n",
      "[2018-05-12 20:43:45.291219] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_15.zip\n",
      "[2018-05-12 20:43:45.388251] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_15.zip\n",
      "[2018-05-12 20:43:48.199170] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 20:43:48.205084] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:43:48.338214] SGDOptimizer > Initial loss [88.7794189453125]\n",
      "\u001b[2K[2018-05-12 20:45:28.102958] SGDOptimizer > Curr loss: 9.147955E+01, n_evals: 999, Avg. time per updt: 0.098469\n",
      "[2018-05-12 20:45:28.128943] SGDOptimizer > Done training. New loss [144.481461] iter: [999]\n",
      "[2018-05-12 20:45:28.130606] apply_controller > Starting run\n",
      "[2018-05-12 20:45:28.132087] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:45:28.309625] apply_controller > Done. Stopping robot. Value of run [28.207523]\n",
      "[2018-05-12 20:45:28.310953] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:45:28.312179] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:45:28.315679] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 20:45:28.317385] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:45:28.332143] target_dyn_opt > Initial loss [-6.848559504680894]\n",
      "\u001b[2K[2018-05-12 20:45:52.557109] target_dyn_opt > Curr loss: -8.417477E+00 [1927: -8.452904E+00], n_evals: 1999, Avg. time per updt: 0.010521\n",
      "[2018-05-12 20:45:52.575100] target_dyn_opt > Done training. New loss [-7.892199] iter: [2000]\n",
      "[2018-05-12 20:45:52.578570] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:45:52.580388] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_16.zip\n",
      "[2018-05-12 20:45:53.459384] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_16.zip\n",
      "[2018-05-12 20:45:53.557733] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_16.zip\n",
      "[2018-05-12 20:45:56.401847] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 20:45:56.406375] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:45:56.551486] SGDOptimizer > Initial loss [94.7374267578125]\n",
      "\u001b[2K[2018-05-12 20:47:39.012450] SGDOptimizer > Curr loss: 7.941199E+01, n_evals: 999, Avg. time per updt: 0.101169\n",
      "[2018-05-12 20:47:39.039451] SGDOptimizer > Done training. New loss [78.915039] iter: [999]\n",
      "[2018-05-12 20:47:39.041089] apply_controller > Starting run\n",
      "[2018-05-12 20:47:39.042573] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:47:39.221450] apply_controller > Done. Stopping robot. Value of run [26.909536]\n",
      "[2018-05-12 20:47:39.222914] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:47:39.223967] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:47:39.228229] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 20:47:39.229737] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:47:39.246335] target_dyn_opt > Initial loss [-6.005824927711624]\n",
      "\u001b[2K[2018-05-12 20:47:56.969108] target_dyn_opt > Curr loss: -8.413984E+00 [1875: -8.859416E+00], n_evals: 1999, Avg. time per updt: 0.007403\n",
      "[2018-05-12 20:47:56.983254] target_dyn_opt > Done training. New loss [-8.389574] iter: [2000]\n",
      "[2018-05-12 20:47:56.985926] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:47:56.987511] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_17.zip\n",
      "[2018-05-12 20:47:57.806924] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_17.zip\n",
      "[2018-05-12 20:47:57.905240] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_17.zip\n",
      "[2018-05-12 20:48:00.718993] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 20:48:00.724284] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:48:00.844587] SGDOptimizer > Initial loss [75.63398742675781]\n",
      "\u001b[2K[2018-05-12 20:49:46.358760] SGDOptimizer > Curr loss: 6.201745E+01, n_evals: 999, Avg. time per updt: 0.104200\n",
      "[2018-05-12 20:49:46.385484] SGDOptimizer > Done training. New loss [62.506218] iter: [999]\n",
      "[2018-05-12 20:49:46.387918] apply_controller > Starting run\n",
      "[2018-05-12 20:49:46.389960] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:49:46.615307] apply_controller > Done. Stopping robot. Value of run [28.899960]\n",
      "[2018-05-12 20:49:46.616542] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:49:46.617874] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:49:46.622428] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 20:49:46.623711] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:49:46.638093] target_dyn_opt > Initial loss [-6.095444916164377]\n",
      "\u001b[2K[2018-05-12 20:50:04.764360] target_dyn_opt > Curr loss: -8.746287E+00 [1204: -9.208214E+00], n_evals: 1999, Avg. time per updt: 0.007580\n",
      "[2018-05-12 20:50:04.779649] target_dyn_opt > Done training. New loss [-8.647629] iter: [2000]\n",
      "[2018-05-12 20:50:04.782206] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:50:04.783829] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_18.zip\n",
      "[2018-05-12 20:50:05.639115] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_18.zip\n",
      "[2018-05-12 20:50:05.738025] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_18.zip\n",
      "[2018-05-12 20:50:10.491725] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 20:50:10.497413] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:50:10.639479] SGDOptimizer > Initial loss [84.66505432128906]\n",
      "\u001b[2K[2018-05-12 20:51:57.295989] SGDOptimizer > Curr loss: 8.429072E+01, n_evals: 999, Avg. time per updt: 0.105250\n",
      "[2018-05-12 20:51:57.321634] SGDOptimizer > Done training. New loss [115.934105] iter: [999]\n",
      "[2018-05-12 20:51:57.323561] apply_controller > Starting run\n",
      "[2018-05-12 20:51:57.324824] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:51:57.589210] apply_controller > Done. Stopping robot. Value of run [29.242113]\n",
      "[2018-05-12 20:51:57.590496] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:51:57.591870] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:51:57.595878] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 20:51:57.597302] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:51:57.611106] target_dyn_opt > Initial loss [-8.706030629421102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 20:52:20.171100] target_dyn_opt > Curr loss: -8.872998E+00 [1169: -9.725033E+00], n_evals: 1999, Avg. time per updt: 0.009548\n",
      "[2018-05-12 20:52:20.184300] target_dyn_opt > Done training. New loss [-9.178159] iter: [2000]\n",
      "[2018-05-12 20:52:20.186897] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:52:20.188462] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_19.zip\n",
      "[2018-05-12 20:52:21.092353] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_19.zip\n",
      "[2018-05-12 20:52:21.191756] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_19.zip\n",
      "[2018-05-12 20:52:24.028651] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 20:52:24.034044] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:52:24.156794] SGDOptimizer > Initial loss [123.30403900146484]\n",
      "\u001b[2K[2018-05-12 20:54:11.551068] SGDOptimizer > Curr loss: 9.723950E+01, n_evals: 999, Avg. time per updt: 0.105971\n",
      "[2018-05-12 20:54:11.576977] SGDOptimizer > Done training. New loss [150.924759] iter: [999]\n",
      "[2018-05-12 20:54:11.578977] apply_controller > Starting run\n",
      "[2018-05-12 20:54:11.580538] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:54:11.758628] apply_controller > Done. Stopping robot. Value of run [29.998886]\n",
      "[2018-05-12 20:54:11.759844] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:54:11.761175] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:54:11.765683] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 20:54:11.767111] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:54:11.782074] target_dyn_opt > Initial loss [-7.56185535868792]\n",
      "\u001b[2K[2018-05-12 20:54:29.703637] target_dyn_opt > Curr loss: -9.135219E+00 [1720: -1.003726E+01], n_evals: 1999, Avg. time per updt: 0.007493\n",
      "[2018-05-12 20:54:29.719068] target_dyn_opt > Done training. New loss [-9.224328] iter: [2000]\n",
      "[2018-05-12 20:54:29.721739] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:54:29.723079] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_20.zip\n",
      "[2018-05-12 20:54:30.668848] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_20.zip\n",
      "[2018-05-12 20:54:30.767067] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_20.zip\n",
      "[2018-05-12 20:54:33.590006] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 20:54:33.595418] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:54:33.727349] SGDOptimizer > Initial loss [554.4725341796875]\n",
      "\u001b[2K[2018-05-12 20:56:26.322714] SGDOptimizer > Curr loss: 1.440446E+02, n_evals: 999, Avg. time per updt: 0.111186\n",
      "[2018-05-12 20:56:26.353056] SGDOptimizer > Done training. New loss [79.807121] iter: [999]\n",
      "[2018-05-12 20:56:26.355022] apply_controller > Starting run\n",
      "[2018-05-12 20:56:26.356548] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:56:26.569337] apply_controller > Done. Stopping robot. Value of run [27.030294]\n",
      "[2018-05-12 20:56:26.570560] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:56:26.571776] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:56:26.576066] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 20:56:26.577512] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:56:26.591632] target_dyn_opt > Initial loss [-8.233392474139372]\n",
      "\u001b[2K[2018-05-12 20:56:44.535987] target_dyn_opt > Curr loss: -9.839159E+00 [1713: -1.031727E+01], n_evals: 1999, Avg. time per updt: 0.007507\n",
      "[2018-05-12 20:56:44.548866] target_dyn_opt > Done training. New loss [-9.786186] iter: [2000]\n",
      "[2018-05-12 20:56:44.551340] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:56:44.552727] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_21.zip\n",
      "[2018-05-12 20:56:45.533467] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_21.zip\n",
      "[2018-05-12 20:56:45.631726] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_21.zip\n",
      "[2018-05-12 20:56:48.473196] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 20:56:48.478254] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:56:48.614592] SGDOptimizer > Initial loss [86.18090057373047]\n",
      "\u001b[2K[2018-05-12 20:58:37.155642] SGDOptimizer > Curr loss: 1.059604E+02, n_evals: 999, Avg. time per updt: 0.107206\n",
      "[2018-05-12 20:58:37.183831] SGDOptimizer > Done training. New loss [91.429619] iter: [999]\n",
      "[2018-05-12 20:58:37.185936] apply_controller > Starting run\n",
      "[2018-05-12 20:58:37.187256] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 20:58:37.364069] apply_controller > Done. Stopping robot. Value of run [28.339367]\n",
      "[2018-05-12 20:58:37.365403] target_2x_mass > Stopping robot\n",
      "[2018-05-12 20:58:37.366911] train_dynamics > Training dynamics model\n",
      "[2018-05-12 20:58:37.373687] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 20:58:37.374967] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 20:58:37.391302] target_dyn_opt > Initial loss [-9.15780636502885]\n",
      "\u001b[2K[2018-05-12 20:58:55.412850] target_dyn_opt > Curr loss: -1.024699E+01 [586: -1.063787E+01], n_evals: 1999, Avg. time per updt: 0.007531\n",
      "[2018-05-12 20:58:55.428268] target_dyn_opt > Done training. New loss [-10.315668] iter: [2000]\n",
      "[2018-05-12 20:58:55.431060] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 20:58:55.432369] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_22.zip\n",
      "[2018-05-12 20:58:56.453956] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_22.zip\n",
      "[2018-05-12 20:58:56.552658] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_22.zip\n",
      "[2018-05-12 20:58:59.389343] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 20:58:59.394206] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 20:58:59.540270] SGDOptimizer > Initial loss [73.01078033447266]\n",
      "\u001b[2K[2018-05-12 21:00:49.212468] SGDOptimizer > Curr loss: 8.012540E+01, n_evals: 999, Avg. time per updt: 0.108297\n",
      "[2018-05-12 21:00:49.239831] SGDOptimizer > Done training. New loss [76.835129] iter: [999]\n",
      "[2018-05-12 21:00:49.241662] apply_controller > Starting run\n",
      "[2018-05-12 21:00:49.242940] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:00:49.411342] apply_controller > Done. Stopping robot. Value of run [29.982616]\n",
      "[2018-05-12 21:00:49.412929] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:00:49.414317] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:00:49.418250] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 21:00:49.419723] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:00:49.433835] target_dyn_opt > Initial loss [-8.576063050706496]\n",
      "\u001b[2K[2018-05-12 21:01:07.398612] target_dyn_opt > Curr loss: -1.022615E+01 [1503: -1.101882E+01], n_evals: 1999, Avg. time per updt: 0.007503\n",
      "[2018-05-12 21:01:07.411679] target_dyn_opt > Done training. New loss [-10.637498] iter: [2000]\n",
      "[2018-05-12 21:01:07.414513] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:01:07.416359] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_23.zip\n",
      "[2018-05-12 21:01:08.481268] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_23.zip\n",
      "[2018-05-12 21:01:08.580484] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_23.zip\n",
      "[2018-05-12 21:01:11.435191] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 21:01:11.440023] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:01:11.588141] SGDOptimizer > Initial loss [86.83418273925781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 21:02:57.038370] SGDOptimizer > Curr loss: 1.110953E+02, n_evals: 999, Avg. time per updt: 0.104143\n",
      "[2018-05-12 21:02:57.066327] SGDOptimizer > Done training. New loss [109.132835] iter: [999]\n",
      "[2018-05-12 21:02:57.068489] apply_controller > Starting run\n",
      "[2018-05-12 21:02:57.069875] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:02:57.260728] apply_controller > Done. Stopping robot. Value of run [28.661507]\n",
      "[2018-05-12 21:02:57.261949] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:02:57.263204] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:02:57.267930] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 21:02:57.269470] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:02:57.284307] target_dyn_opt > Initial loss [-9.025384691131526]\n",
      "\u001b[2K[2018-05-12 21:03:15.225636] target_dyn_opt > Curr loss: -1.077499E+01 [1967: -1.117132E+01], n_evals: 1999, Avg. time per updt: 0.007520\n",
      "[2018-05-12 21:03:15.239337] target_dyn_opt > Done training. New loss [-10.699543] iter: [2000]\n",
      "[2018-05-12 21:03:15.242047] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:03:15.243663] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_24.zip\n",
      "[2018-05-12 21:03:16.350765] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_24.zip\n",
      "[2018-05-12 21:03:16.451196] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_24.zip\n",
      "[2018-05-12 21:03:19.282995] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 21:03:19.288055] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:03:19.425023] SGDOptimizer > Initial loss [95.45222473144531]\n",
      "\u001b[2K[2018-05-12 21:05:04.225784] SGDOptimizer > Curr loss: 5.852072E+01, n_evals: 999, Avg. time per updt: 0.103509\n",
      "[2018-05-12 21:05:04.256141] SGDOptimizer > Done training. New loss [76.083855] iter: [999]\n",
      "[2018-05-12 21:05:04.257902] apply_controller > Starting run\n",
      "[2018-05-12 21:05:04.259191] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:05:04.439316] apply_controller > Done. Stopping robot. Value of run [29.998867]\n",
      "[2018-05-12 21:05:04.440535] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:05:04.442012] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:05:04.446293] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 21:05:04.447669] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:05:04.461661] target_dyn_opt > Initial loss [-5.858701338818598]\n",
      "\u001b[2K[2018-05-12 21:05:22.530707] target_dyn_opt > Curr loss: -1.102693E+01 [1412: -1.137432E+01], n_evals: 1999, Avg. time per updt: 0.007555\n",
      "[2018-05-12 21:05:22.543376] target_dyn_opt > Done training. New loss [-10.956538] iter: [2000]\n",
      "[2018-05-12 21:05:22.545929] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:05:22.547613] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_25.zip\n",
      "[2018-05-12 21:05:23.732695] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_25.zip\n",
      "[2018-05-12 21:05:23.834967] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_25.zip\n",
      "[2018-05-12 21:05:26.704566] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 21:05:26.710175] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:05:26.856851] SGDOptimizer > Initial loss [61.19783401489258]\n",
      "\u001b[2K[2018-05-12 21:07:06.104754] SGDOptimizer > Curr loss: 7.713223E+01, n_evals: 999, Avg. time per updt: 0.097950\n",
      "[2018-05-12 21:07:06.132396] SGDOptimizer > Done training. New loss [72.173195] iter: [999]\n",
      "[2018-05-12 21:07:06.134350] apply_controller > Starting run\n",
      "[2018-05-12 21:07:06.135646] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:07:06.325979] apply_controller > Done. Stopping robot. Value of run [28.123980]\n",
      "[2018-05-12 21:07:06.327191] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:07:06.328509] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:07:06.333487] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 21:07:06.334853] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:07:06.350931] target_dyn_opt > Initial loss [-8.681667634582155]\n",
      "\u001b[2K[2018-05-12 21:07:24.960924] target_dyn_opt > Curr loss: -1.102324E+01 [1934: -1.161416E+01], n_evals: 1999, Avg. time per updt: 0.007820\n",
      "[2018-05-12 21:07:24.977440] target_dyn_opt > Done training. New loss [-11.049695] iter: [2000]\n",
      "[2018-05-12 21:07:24.980151] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:07:24.981647] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_26.zip\n",
      "[2018-05-12 21:07:26.267472] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_26.zip\n",
      "[2018-05-12 21:07:26.378766] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_26.zip\n",
      "[2018-05-12 21:07:29.389330] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 21:07:29.394902] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:07:29.518961] SGDOptimizer > Initial loss [83.03179168701172]\n",
      "\u001b[2K[2018-05-12 21:09:11.662092] SGDOptimizer > Curr loss: 1.232961E+02, n_evals: 999, Avg. time per updt: 0.100847\n",
      "[2018-05-12 21:09:11.694670] SGDOptimizer > Done training. New loss [118.395630] iter: [999]\n",
      "[2018-05-12 21:09:11.698007] apply_controller > Starting run\n",
      "[2018-05-12 21:09:11.699463] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:09:11.951841] apply_controller > Done. Stopping robot. Value of run [29.894032]\n",
      "[2018-05-12 21:09:11.953358] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:09:11.954901] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:09:11.960801] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 21:09:11.962251] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:09:11.979416] target_dyn_opt > Initial loss [-9.234579272494821]\n",
      "\u001b[2K[2018-05-12 21:09:30.236708] target_dyn_opt > Curr loss: -1.139477E+01 [1173: -1.192428E+01], n_evals: 1999, Avg. time per updt: 0.007649\n",
      "[2018-05-12 21:09:30.252216] target_dyn_opt > Done training. New loss [-11.390323] iter: [2000]\n",
      "[2018-05-12 21:09:30.255177] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:09:30.258353] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_27.zip\n",
      "[2018-05-12 21:09:31.509536] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_27.zip\n",
      "[2018-05-12 21:09:31.612601] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_27.zip\n",
      "[2018-05-12 21:09:36.477087] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 21:09:36.482074] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:09:36.618322] SGDOptimizer > Initial loss [123.34132385253906]\n",
      "\u001b[2K[2018-05-12 21:11:17.833909] SGDOptimizer > Curr loss: 1.011669E+02, n_evals: 999, Avg. time per updt: 0.099903\n",
      "[2018-05-12 21:11:17.860840] SGDOptimizer > Done training. New loss [99.637749] iter: [999]\n",
      "[2018-05-12 21:11:17.862572] apply_controller > Starting run\n",
      "[2018-05-12 21:11:17.863847] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:11:18.039159] apply_controller > Done. Stopping robot. Value of run [26.948561]\n",
      "[2018-05-12 21:11:18.040686] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:11:18.042025] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:11:18.046521] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 21:11:18.047977] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:11:18.062312] target_dyn_opt > Initial loss [-9.653396758362739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 21:11:35.978731] target_dyn_opt > Curr loss: -1.182010E+01 [1972: -1.222982E+01], n_evals: 1999, Avg. time per updt: 0.007493\n",
      "[2018-05-12 21:11:35.992255] target_dyn_opt > Done training. New loss [-11.796480] iter: [2000]\n",
      "[2018-05-12 21:11:35.994960] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:11:35.996588] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_28.zip\n",
      "[2018-05-12 21:11:37.287260] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_28.zip\n",
      "[2018-05-12 21:11:37.387881] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_28.zip\n",
      "[2018-05-12 21:11:40.273831] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 21:11:40.279270] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:11:40.408820] SGDOptimizer > Initial loss [112.98040008544922]\n",
      "\u001b[2K[2018-05-12 21:13:20.472431] SGDOptimizer > Curr loss: 1.028631E+02, n_evals: 999, Avg. time per updt: 0.098765\n",
      "[2018-05-12 21:13:20.500228] SGDOptimizer > Done training. New loss [76.483315] iter: [999]\n",
      "[2018-05-12 21:13:20.502155] apply_controller > Starting run\n",
      "[2018-05-12 21:13:20.503637] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:13:20.683765] apply_controller > Done. Stopping robot. Value of run [29.607996]\n",
      "[2018-05-12 21:13:20.685328] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:13:20.686657] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:13:20.691976] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 21:13:20.693398] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:13:20.708062] target_dyn_opt > Initial loss [-10.015932289759318]\n",
      "\u001b[2K[2018-05-12 21:13:38.945391] target_dyn_opt > Curr loss: -1.187512E+01 [1810: -1.229103E+01], n_evals: 1999, Avg. time per updt: 0.007641\n",
      "[2018-05-12 21:13:38.958807] target_dyn_opt > Done training. New loss [-11.847032] iter: [2000]\n",
      "[2018-05-12 21:13:38.961418] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:13:38.962994] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_29.zip\n",
      "[2018-05-12 21:13:40.305725] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_29.zip\n",
      "[2018-05-12 21:13:40.408179] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_29.zip\n",
      "[2018-05-12 21:13:43.310954] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 21:13:43.316092] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:13:43.448663] SGDOptimizer > Initial loss [82.73419952392578]\n",
      "\u001b[2K[2018-05-12 21:15:24.225786] SGDOptimizer > Curr loss: 1.133917E+02, n_evals: 999, Avg. time per updt: 0.099480\n",
      "[2018-05-12 21:15:24.255577] SGDOptimizer > Done training. New loss [98.278725] iter: [999]\n",
      "[2018-05-12 21:15:24.257199] apply_controller > Starting run\n",
      "[2018-05-12 21:15:24.258488] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:15:24.423225] apply_controller > Done. Stopping robot. Value of run [28.862894]\n",
      "[2018-05-12 21:15:24.424567] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:15:24.426176] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:15:24.432763] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 21:15:24.434144] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:15:24.450981] target_dyn_opt > Initial loss [-10.896553520962712]\n",
      "\u001b[2K[2018-05-12 21:15:42.473007] target_dyn_opt > Curr loss: -1.201958E+01 [1482: -1.253386E+01], n_evals: 1999, Avg. time per updt: 0.007522\n",
      "[2018-05-12 21:15:42.485844] target_dyn_opt > Done training. New loss [-12.200907] iter: [2000]\n",
      "[2018-05-12 21:15:42.488435] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:15:42.490237] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/experience_30.zip\n",
      "[2018-05-12 21:15:43.913288] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/policy_30.zip\n",
      "[2018-05-12 21:15:44.014679] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_004_il_klpq_from_scratch/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 4 learn starting from scratch, using klpq imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_004_il_klpq_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 21:24:03.382105] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 21:24:03.409119] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 21:24:03.444697] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 21:24:03.466919] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 21:24:03.496583] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 21:24:03.512470] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 21:24:03.518143] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 21:24:03.530992] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 21:24:03.551040] Experience > Initialising new experience dataset\n",
      "[2018-05-12 21:24:03.552443] Executing initial policy\n",
      "[2018-05-12 21:24:03.554008] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 21:24:03.634604] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 21:24:03.799269] NNPolicy > Done compiling\n",
      "[2018-05-12 21:24:03.800760] apply_controller > Starting run\n",
      "[2018-05-12 21:24:03.802073] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:24:04.012571] apply_controller > Done. Stopping robot. Value of run [29.101955]\n",
      "[2018-05-12 21:24:04.013789] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:24:04.015045] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:24:04.017481] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 21:24:04.019012] target_dyn > Initialising loss function\n",
      "[2018-05-12 21:24:04.171011] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 21:24:04.483751] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 21:24:04.484982] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 21:24:04.545570] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 21:24:05.434954] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 21:24:09.973913] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:24:09.982873] target_dyn_opt > Initial loss [1041.0982945633345]\n",
      "\u001b[2K[2018-05-12 21:24:19.858312] target_dyn_opt > Curr loss: 4.099602E+01 [1993: 4.016877E+01], n_evals: 1999, Avg. time per updt: 0.003400\n",
      "[2018-05-12 21:24:19.864675] target_dyn_opt > Done training. New loss [41.119727] iter: [2000]\n",
      "[2018-05-12 21:24:20.086204] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:24:20.277211] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 21:24:20.278709] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 21:24:20.365953] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 21:24:20.367835] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 21:24:20.950432] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 21:24:20.951718] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 21:24:21.038133] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 21:24:21.039930] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 21:24:27.050938] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 21:24:28.458855] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 21:24:28.468849] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 21:24:28.502028] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 21:24:33.435586] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 21:24:53.413801] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_0.zip\n",
      "[2018-05-12 21:24:53.555328] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_0.zip\n",
      "[2018-05-12 21:24:53.874669] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_0.zip\n",
      "[2018-05-12 21:24:55.005603] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 21:24:55.007478] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 21:24:55.016765] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:24:55.323465] SGDOptimizer > Initial loss [115268.0859375]\n",
      "\u001b[2K[2018-05-12 21:26:46.565199] SGDOptimizer > Curr loss: 9.049371E+03, n_evals: 999, Avg. time per updt: 0.109098\n",
      "[2018-05-12 21:26:46.599296] SGDOptimizer > Done training. New loss [40001.636719] iter: [999]\n",
      "[2018-05-12 21:26:46.606567] apply_controller > Starting run\n",
      "[2018-05-12 21:26:46.607975] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:26:46.794830] apply_controller > Done. Stopping robot. Value of run [29.856440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 21:26:46.796804] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:26:46.798151] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:26:46.804463] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 21:26:46.806269] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:26:46.866516] target_dyn_opt > Initial loss [81.07482053442249]\n",
      "\u001b[2K[2018-05-12 21:26:59.851637] target_dyn_opt > Curr loss: 1.292845E+01 [1894: 1.268465E+01], n_evals: 1999, Avg. time per updt: 0.004991\n",
      "[2018-05-12 21:26:59.862250] target_dyn_opt > Done training. New loss [13.446337] iter: [2000]\n",
      "[2018-05-12 21:26:59.865439] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:26:59.868321] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_1.zip\n",
      "[2018-05-12 21:27:00.043281] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_1.zip\n",
      "[2018-05-12 21:27:00.162363] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_1.zip\n",
      "[2018-05-12 21:27:03.860290] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 21:27:03.865241] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:27:04.004319] SGDOptimizer > Initial loss [38568.69140625]\n",
      "\u001b[2K[2018-05-12 21:28:47.738971] SGDOptimizer > Curr loss: 3.557516E+04, n_evals: 999, Avg. time per updt: 0.102424\n",
      "[2018-05-12 21:28:47.770779] SGDOptimizer > Done training. New loss [34601.421875] iter: [999]\n",
      "[2018-05-12 21:28:47.772825] apply_controller > Starting run\n",
      "[2018-05-12 21:28:47.774335] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:28:47.953275] apply_controller > Done. Stopping robot. Value of run [29.978720]\n",
      "[2018-05-12 21:28:47.954604] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:28:47.955915] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:28:47.958701] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 21:28:47.960081] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:28:47.973426] target_dyn_opt > Initial loss [16.66900375279887]\n",
      "\u001b[2K[2018-05-12 21:29:04.522856] target_dyn_opt > Curr loss: 3.608531E+00 [1975: 3.308174E+00], n_evals: 1999, Avg. time per updt: 0.006773\n",
      "[2018-05-12 21:29:04.535502] target_dyn_opt > Done training. New loss [3.740929] iter: [2000]\n",
      "[2018-05-12 21:29:04.538501] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:29:04.540161] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_2.zip\n",
      "[2018-05-12 21:29:04.751948] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_2.zip\n",
      "[2018-05-12 21:29:04.869947] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_2.zip\n",
      "[2018-05-12 21:29:08.239855] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 21:29:08.244807] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:29:08.409688] SGDOptimizer > Initial loss [36435.34765625]\n",
      "\u001b[2K[2018-05-12 21:30:57.875550] SGDOptimizer > Curr loss: 4.947795E+04, n_evals: 999, Avg. time per updt: 0.108190\n",
      "[2018-05-12 21:30:57.909611] SGDOptimizer > Done training. New loss [46908.695312] iter: [999]\n",
      "[2018-05-12 21:30:57.911366] apply_controller > Starting run\n",
      "[2018-05-12 21:30:57.912665] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:30:58.109760] apply_controller > Done. Stopping robot. Value of run [28.142229]\n",
      "[2018-05-12 21:30:58.111232] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:30:58.112545] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:30:58.114635] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 21:30:58.115886] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:30:58.130513] target_dyn_opt > Initial loss [49.20071296239721]\n",
      "\u001b[2K[2018-05-12 21:31:17.392097] target_dyn_opt > Curr loss: -2.461023E-01 [1939: -9.197480E-01], n_evals: 1999, Avg. time per updt: 0.008056\n",
      "[2018-05-12 21:31:17.408211] target_dyn_opt > Done training. New loss [-0.535334] iter: [2000]\n",
      "[2018-05-12 21:31:17.411008] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:31:17.412515] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_3.zip\n",
      "[2018-05-12 21:31:17.661524] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_3.zip\n",
      "[2018-05-12 21:31:17.780100] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_3.zip\n",
      "[2018-05-12 21:31:21.208832] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 21:31:21.213759] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:31:21.391132] SGDOptimizer > Initial loss [31958.685546875]\n",
      "\u001b[2K[2018-05-12 21:33:22.952169] SGDOptimizer > Curr loss: 4.618905E+04, n_evals: 999, Avg. time per updt: 0.120282\n",
      "[2018-05-12 21:33:22.987740] SGDOptimizer > Done training. New loss [51956.488281] iter: [999]\n",
      "[2018-05-12 21:33:22.989493] apply_controller > Starting run\n",
      "[2018-05-12 21:33:22.990833] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:33:23.188148] apply_controller > Done. Stopping robot. Value of run [27.634729]\n",
      "[2018-05-12 21:33:23.189380] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:33:23.191351] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:33:23.193847] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 21:33:23.195387] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:33:23.210724] target_dyn_opt > Initial loss [41.43571382637681]\n",
      "\u001b[2K[2018-05-12 21:33:42.766125] target_dyn_opt > Curr loss: -2.938359E+00 [1743: -3.647395E+00], n_evals: 1999, Avg. time per updt: 0.008188\n",
      "[2018-05-12 21:33:42.781380] target_dyn_opt > Done training. New loss [-3.156229] iter: [2000]\n",
      "[2018-05-12 21:33:42.784160] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:33:42.786364] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_4.zip\n",
      "[2018-05-12 21:33:43.087236] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_4.zip\n",
      "[2018-05-12 21:33:43.213192] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_4.zip\n",
      "[2018-05-12 21:33:46.515226] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 21:33:46.520206] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:33:46.685701] SGDOptimizer > Initial loss [79732.3515625]\n",
      "\u001b[2K[2018-05-12 21:35:47.229040] SGDOptimizer > Curr loss: 4.014843E+04, n_evals: 999, Avg. time per updt: 0.119246\n",
      "[2018-05-12 21:35:47.265360] SGDOptimizer > Done training. New loss [39431.078125] iter: [999]\n",
      "[2018-05-12 21:35:47.267149] apply_controller > Starting run\n",
      "[2018-05-12 21:35:47.268517] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:35:47.436300] apply_controller > Done. Stopping robot. Value of run [29.104164]\n",
      "[2018-05-12 21:35:47.438043] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:35:47.439477] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:35:47.442731] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 21:35:47.444549] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:35:47.459508] target_dyn_opt > Initial loss [1.9509154513649563]\n",
      "\u001b[2K[2018-05-12 21:36:06.494211] target_dyn_opt > Curr loss: -5.408464E+00 [1839: -5.685325E+00], n_evals: 1999, Avg. time per updt: 0.007947\n",
      "[2018-05-12 21:36:06.507267] target_dyn_opt > Done training. New loss [-5.476704] iter: [2000]\n",
      "[2018-05-12 21:36:06.510116] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:36:06.511953] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_5.zip\n",
      "[2018-05-12 21:36:06.848473] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 21:36:06.970343] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_5.zip\n",
      "[2018-05-12 21:36:10.222628] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 21:36:10.227787] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:36:10.369849] SGDOptimizer > Initial loss [23754.146484375]\n",
      "\u001b[2K[2018-05-12 21:37:47.037477] SGDOptimizer > Curr loss: 1.906376E+04, n_evals: 999, Avg. time per updt: 0.095388\n",
      "[2018-05-12 21:37:47.064257] SGDOptimizer > Done training. New loss [18178.949219] iter: [999]\n",
      "[2018-05-12 21:37:47.066485] apply_controller > Starting run\n",
      "[2018-05-12 21:37:47.067986] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:37:47.248966] apply_controller > Done. Stopping robot. Value of run [21.561527]\n",
      "[2018-05-12 21:37:47.250315] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:37:47.251356] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:37:47.254348] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 21:37:47.257639] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:37:47.275084] target_dyn_opt > Initial loss [5.618017249359873]\n",
      "\u001b[2K[2018-05-12 21:38:05.626477] target_dyn_opt > Curr loss: -6.491470E+00 [1821: -7.091565E+00], n_evals: 1999, Avg. time per updt: 0.007676\n",
      "[2018-05-12 21:38:05.640729] target_dyn_opt > Done training. New loss [-6.421438] iter: [2000]\n",
      "[2018-05-12 21:38:05.643542] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:38:05.644893] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_6.zip\n",
      "[2018-05-12 21:38:06.023656] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_6.zip\n",
      "[2018-05-12 21:38:06.146335] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_6.zip\n",
      "[2018-05-12 21:38:09.449500] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 21:38:09.454638] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:38:09.611661] SGDOptimizer > Initial loss [12323.267578125]\n",
      "\u001b[2K[2018-05-12 21:40:08.481912] SGDOptimizer > Curr loss: 9.608490E+03, n_evals: 999, Avg. time per updt: 0.117579\n",
      "[2018-05-12 21:40:08.520293] SGDOptimizer > Done training. New loss [9283.796875] iter: [999]\n",
      "[2018-05-12 21:40:08.522295] apply_controller > Starting run\n",
      "[2018-05-12 21:40:08.523539] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:40:08.707148] apply_controller > Done. Stopping robot. Value of run [27.406160]\n",
      "[2018-05-12 21:40:08.708480] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:40:08.709778] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:40:08.712439] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 21:40:08.713841] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:40:08.729337] target_dyn_opt > Initial loss [2.105595781885344]\n",
      "\u001b[2K[2018-05-12 21:40:27.668195] target_dyn_opt > Curr loss: -7.560795E+00 [1730: -8.199985E+00], n_evals: 1999, Avg. time per updt: 0.007981\n",
      "[2018-05-12 21:40:27.684263] target_dyn_opt > Done training. New loss [-7.988347] iter: [2000]\n",
      "[2018-05-12 21:40:27.687067] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:40:27.688384] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_7.zip\n",
      "[2018-05-12 21:40:28.809532] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_7.zip\n",
      "[2018-05-12 21:40:28.955110] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_7.zip\n",
      "[2018-05-12 21:40:32.558977] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 21:40:32.564521] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:40:32.726989] SGDOptimizer > Initial loss [9889.806640625]\n",
      "\u001b[2K[2018-05-12 21:42:30.815978] SGDOptimizer > Curr loss: 9.758255E+03, n_evals: 999, Avg. time per updt: 0.116797\n",
      "[2018-05-12 21:42:30.852588] SGDOptimizer > Done training. New loss [10878.675781] iter: [999]\n",
      "[2018-05-12 21:42:30.854524] apply_controller > Starting run\n",
      "[2018-05-12 21:42:30.855862] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:42:31.029176] apply_controller > Done. Stopping robot. Value of run [28.673225]\n",
      "[2018-05-12 21:42:31.030755] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:42:31.032285] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:42:31.035580] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 21:42:31.037042] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:42:31.052620] target_dyn_opt > Initial loss [-3.645347236559309]\n",
      "\u001b[2K[2018-05-12 21:42:49.708303] target_dyn_opt > Curr loss: -8.521700E+00 [1812: -8.953641E+00], n_evals: 1999, Avg. time per updt: 0.007840\n",
      "[2018-05-12 21:42:49.722461] target_dyn_opt > Done training. New loss [-8.383622] iter: [2000]\n",
      "[2018-05-12 21:42:49.725357] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:42:49.726771] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_8.zip\n",
      "[2018-05-12 21:42:50.196409] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_8.zip\n",
      "[2018-05-12 21:42:50.319017] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_8.zip\n",
      "[2018-05-12 21:42:53.615103] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 21:42:53.619980] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:42:53.795134] SGDOptimizer > Initial loss [16587.0703125]\n",
      "\u001b[2K[2018-05-12 21:44:54.737136] SGDOptimizer > Curr loss: 1.317099E+04, n_evals: 999, Avg. time per updt: 0.119688\n",
      "[2018-05-12 21:44:54.774408] SGDOptimizer > Done training. New loss [13007.701172] iter: [999]\n",
      "[2018-05-12 21:44:54.776640] apply_controller > Starting run\n",
      "[2018-05-12 21:44:54.777856] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:44:54.953359] apply_controller > Done. Stopping robot. Value of run [28.576551]\n",
      "[2018-05-12 21:44:54.954757] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:44:54.956074] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:44:54.959845] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 21:44:54.961229] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:44:54.976214] target_dyn_opt > Initial loss [-6.231365741840724]\n",
      "\u001b[2K[2018-05-12 21:45:13.229605] target_dyn_opt > Curr loss: -8.977503E+00 [1924: -9.728103E+00], n_evals: 1999, Avg. time per updt: 0.007639\n",
      "[2018-05-12 21:45:13.242684] target_dyn_opt > Done training. New loss [-9.160027] iter: [2000]\n",
      "[2018-05-12 21:45:13.245425] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:45:13.246948] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_9.zip\n",
      "[2018-05-12 21:45:13.752579] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_9.zip\n",
      "[2018-05-12 21:45:13.877688] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_9.zip\n",
      "[2018-05-12 21:45:17.194194] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 21:45:17.198988] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:45:17.322814] SGDOptimizer > Initial loss [12728.05078125]\n",
      "\u001b[2K[2018-05-12 21:46:55.238644] SGDOptimizer > Curr loss: 8.938359E+03, n_evals: 999, Avg. time per updt: 0.096633\n",
      "[2018-05-12 21:46:55.267605] SGDOptimizer > Done training. New loss [9331.073242] iter: [999]\n",
      "[2018-05-12 21:46:55.270003] apply_controller > Starting run\n",
      "[2018-05-12 21:46:55.271505] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:46:55.447729] apply_controller > Done. Stopping robot. Value of run [28.405424]\n",
      "[2018-05-12 21:46:55.449286] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:46:55.450745] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:46:55.454047] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 21:46:55.455635] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:46:55.476536] target_dyn_opt > Initial loss [-5.33886449585514]\n",
      "\u001b[2K[2018-05-12 21:47:13.648922] target_dyn_opt > Curr loss: -1.017741E+01 [1998: -1.017741E+01], n_evals: 1999, Avg. time per updt: 0.007595\n",
      "[2018-05-12 21:47:13.662690] target_dyn_opt > Done training. New loss [-9.802204] iter: [2000]\n",
      "[2018-05-12 21:47:13.665414] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:47:13.666812] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_10.zip\n",
      "[2018-05-12 21:47:14.222221] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_10.zip\n",
      "[2018-05-12 21:47:14.346260] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_10.zip\n",
      "[2018-05-12 21:47:17.652118] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 21:47:17.657177] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:47:17.810252] SGDOptimizer > Initial loss [9013.9833984375]\n",
      "\u001b[2K[2018-05-12 21:48:59.672694] SGDOptimizer > Curr loss: 1.940786E+04, n_evals: 999, Avg. time per updt: 0.100567\n",
      "[2018-05-12 21:48:59.703873] SGDOptimizer > Done training. New loss [18031.333984] iter: [999]\n",
      "[2018-05-12 21:48:59.706005] apply_controller > Starting run\n",
      "[2018-05-12 21:48:59.707328] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:48:59.882232] apply_controller > Done. Stopping robot. Value of run [29.635891]\n",
      "[2018-05-12 21:48:59.883466] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:48:59.885097] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:48:59.888195] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 21:48:59.889625] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:48:59.903783] target_dyn_opt > Initial loss [-3.12436155598054]\n",
      "\u001b[2K[2018-05-12 21:49:18.450746] target_dyn_opt > Curr loss: -1.028168E+01 [1925: -1.079916E+01], n_evals: 1999, Avg. time per updt: 0.007773\n",
      "[2018-05-12 21:49:18.464444] target_dyn_opt > Done training. New loss [-10.312699] iter: [2000]\n",
      "[2018-05-12 21:49:18.467009] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:49:18.468347] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_11.zip\n",
      "[2018-05-12 21:49:19.062717] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_11.zip\n",
      "[2018-05-12 21:49:19.188607] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_11.zip\n",
      "[2018-05-12 21:49:22.496230] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 21:49:22.501259] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:49:22.660889] SGDOptimizer > Initial loss [17273.970703125]\n",
      "\u001b[2K[2018-05-12 21:51:19.529536] SGDOptimizer > Curr loss: 2.497232E+04, n_evals: 999, Avg. time per updt: 0.115567\n",
      "[2018-05-12 21:51:19.565432] SGDOptimizer > Done training. New loss [23556.642578] iter: [999]\n",
      "[2018-05-12 21:51:19.569153] apply_controller > Starting run\n",
      "[2018-05-12 21:51:19.571140] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:51:19.750788] apply_controller > Done. Stopping robot. Value of run [24.754675]\n",
      "[2018-05-12 21:51:19.751998] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:51:19.753533] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:51:19.758724] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 21:51:19.759971] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:51:19.786239] target_dyn_opt > Initial loss [-6.108857945674927]\n",
      "\u001b[2K[2018-05-12 21:51:38.904655] target_dyn_opt > Curr loss: -1.090496E+01 [1902: -1.116614E+01], n_evals: 1999, Avg. time per updt: 0.008047\n",
      "[2018-05-12 21:51:38.919002] target_dyn_opt > Done training. New loss [-10.691981] iter: [2000]\n",
      "[2018-05-12 21:51:38.921597] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:51:38.923882] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_12.zip\n",
      "[2018-05-12 21:51:39.571117] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_12.zip\n",
      "[2018-05-12 21:51:39.696043] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_12.zip\n",
      "[2018-05-12 21:51:43.051545] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 21:51:43.057591] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:51:43.222404] SGDOptimizer > Initial loss [24851.525390625]\n",
      "\u001b[2K[2018-05-12 21:53:45.049401] SGDOptimizer > Curr loss: 9.075594E+03, n_evals: 999, Avg. time per updt: 0.120531\n",
      "[2018-05-12 21:53:45.089905] SGDOptimizer > Done training. New loss [8744.941406] iter: [999]\n",
      "[2018-05-12 21:53:45.092199] apply_controller > Starting run\n",
      "[2018-05-12 21:53:45.093604] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:53:45.261203] apply_controller > Done. Stopping robot. Value of run [25.543142]\n",
      "[2018-05-12 21:53:45.262632] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:53:45.263821] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:53:45.267793] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 21:53:45.269102] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:53:45.285516] target_dyn_opt > Initial loss [-6.81622461233233]\n",
      "\u001b[2K[2018-05-12 21:54:04.237934] target_dyn_opt > Curr loss: -1.085208E+01 [1193: -1.151231E+01], n_evals: 1999, Avg. time per updt: 0.007934\n",
      "[2018-05-12 21:54:04.250882] target_dyn_opt > Done training. New loss [-10.894642] iter: [2000]\n",
      "[2018-05-12 21:54:04.253673] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:54:04.255402] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_13.zip\n",
      "[2018-05-12 21:54:04.931973] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_13.zip\n",
      "[2018-05-12 21:54:05.058493] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_13.zip\n",
      "[2018-05-12 21:54:08.392721] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 21:54:08.398275] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:54:08.545748] SGDOptimizer > Initial loss [9851.099609375]\n",
      "\u001b[2K[2018-05-12 21:55:50.236791] SGDOptimizer > Curr loss: 1.021894E+04, n_evals: 999, Avg. time per updt: 0.100392\n",
      "[2018-05-12 21:55:50.264309] SGDOptimizer > Done training. New loss [11547.815430] iter: [999]\n",
      "[2018-05-12 21:55:50.266334] apply_controller > Starting run\n",
      "[2018-05-12 21:55:50.267555] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:55:50.445494] apply_controller > Done. Stopping robot. Value of run [28.924637]\n",
      "[2018-05-12 21:55:50.446868] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:55:50.448151] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:55:50.452587] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 21:55:50.454010] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:55:50.471312] target_dyn_opt > Initial loss [-7.676761217912038]\n",
      "\u001b[2K[2018-05-12 21:56:09.149133] target_dyn_opt > Curr loss: -1.151055E+01 [1973: -1.190293E+01], n_evals: 1999, Avg. time per updt: 0.007811\n",
      "[2018-05-12 21:56:09.165147] target_dyn_opt > Done training. New loss [-11.404656] iter: [2000]\n",
      "[2018-05-12 21:56:09.168229] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:56:09.169680] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_14.zip\n",
      "[2018-05-12 21:56:09.887295] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_14.zip\n",
      "[2018-05-12 21:56:10.013041] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_14.zip\n",
      "[2018-05-12 21:56:13.321087] ==== Iteration [15], experience: [450 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 21:56:13.326715] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:56:13.456017] SGDOptimizer > Initial loss [9152.763671875]\n",
      "\u001b[2K[2018-05-12 21:57:56.272324] SGDOptimizer > Curr loss: 1.183951E+04, n_evals: 999, Avg. time per updt: 0.101494\n",
      "[2018-05-12 21:57:56.301087] SGDOptimizer > Done training. New loss [11353.252930] iter: [999]\n",
      "[2018-05-12 21:57:56.303169] apply_controller > Starting run\n",
      "[2018-05-12 21:57:56.304496] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 21:57:56.488817] apply_controller > Done. Stopping robot. Value of run [29.678513]\n",
      "[2018-05-12 21:57:56.490318] target_2x_mass > Stopping robot\n",
      "[2018-05-12 21:57:56.491753] train_dynamics > Training dynamics model\n",
      "[2018-05-12 21:57:56.495404] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 21:57:56.497092] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 21:57:56.513367] target_dyn_opt > Initial loss [-5.984004893436515]\n",
      "\u001b[2K[2018-05-12 21:58:14.393237] target_dyn_opt > Curr loss: -1.154792E+01 [1415: -1.225768E+01], n_evals: 1999, Avg. time per updt: 0.007450\n",
      "[2018-05-12 21:58:14.406727] target_dyn_opt > Done training. New loss [-11.913041] iter: [2000]\n",
      "[2018-05-12 21:58:14.409562] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 21:58:14.411141] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_15.zip\n",
      "[2018-05-12 21:58:15.180768] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_15.zip\n",
      "[2018-05-12 21:58:15.305736] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_15.zip\n",
      "[2018-05-12 21:58:18.617292] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 21:58:18.622820] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 21:58:18.753496] SGDOptimizer > Initial loss [10686.07421875]\n",
      "\u001b[2K[2018-05-12 22:00:02.736759] SGDOptimizer > Curr loss: 2.461721E+04, n_evals: 999, Avg. time per updt: 0.102661\n",
      "[2018-05-12 22:00:02.764488] SGDOptimizer > Done training. New loss [34872.796875] iter: [999]\n",
      "[2018-05-12 22:00:02.766303] apply_controller > Starting run\n",
      "[2018-05-12 22:00:02.767560] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:00:02.935666] apply_controller > Done. Stopping robot. Value of run [29.789722]\n",
      "[2018-05-12 22:00:02.937123] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:00:02.938408] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:00:02.942079] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 22:00:02.943768] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:00:02.958170] target_dyn_opt > Initial loss [-4.065130015294885]\n",
      "\u001b[2K[2018-05-12 22:00:21.307702] target_dyn_opt > Curr loss: -1.195655E+01 [1664: -1.253504E+01], n_evals: 1999, Avg. time per updt: 0.007705\n",
      "[2018-05-12 22:00:21.321633] target_dyn_opt > Done training. New loss [-12.342198] iter: [2000]\n",
      "[2018-05-12 22:00:21.324111] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:00:21.325444] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_16.zip\n",
      "[2018-05-12 22:00:23.240269] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_16.zip\n",
      "[2018-05-12 22:00:23.365808] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_16.zip\n",
      "[2018-05-12 22:00:26.732624] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 22:00:26.737957] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:00:26.875147] SGDOptimizer > Initial loss [33817.70703125]\n",
      "\u001b[2K[2018-05-12 22:02:17.495715] SGDOptimizer > Curr loss: 1.037130E+04, n_evals: 999, Avg. time per updt: 0.109320\n",
      "[2018-05-12 22:02:17.526936] SGDOptimizer > Done training. New loss [9113.578125] iter: [999]\n",
      "[2018-05-12 22:02:17.528709] apply_controller > Starting run\n",
      "[2018-05-12 22:02:17.529910] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:02:17.721855] apply_controller > Done. Stopping robot. Value of run [27.268726]\n",
      "[2018-05-12 22:02:17.723565] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:02:17.724792] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:02:17.728308] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 22:02:17.730036] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:02:17.744836] target_dyn_opt > Initial loss [-0.04401247814240605]\n",
      "\u001b[2K[2018-05-12 22:02:36.520137] target_dyn_opt > Curr loss: -1.208492E+01 [1977: -1.271795E+01], n_evals: 1999, Avg. time per updt: 0.007916\n",
      "[2018-05-12 22:02:36.533823] target_dyn_opt > Done training. New loss [-12.328613] iter: [2000]\n",
      "[2018-05-12 22:02:36.536330] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:02:36.537781] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_17.zip\n",
      "[2018-05-12 22:02:37.386088] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_17.zip\n",
      "[2018-05-12 22:02:37.512117] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_17.zip\n",
      "[2018-05-12 22:02:40.840953] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 22:02:40.845979] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:02:41.002184] SGDOptimizer > Initial loss [13286.419921875]\n",
      "\u001b[2K[2018-05-12 22:04:40.960849] SGDOptimizer > Curr loss: 6.594765E+04, n_evals: 999, Avg. time per updt: 0.118667\n",
      "[2018-05-12 22:04:40.999636] SGDOptimizer > Done training. New loss [73841.296875] iter: [999]\n",
      "[2018-05-12 22:04:41.001489] apply_controller > Starting run\n",
      "[2018-05-12 22:04:41.002979] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:04:41.194577] apply_controller > Done. Stopping robot. Value of run [26.183884]\n",
      "[2018-05-12 22:04:41.195922] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:04:41.197208] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:04:41.200892] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 22:04:41.202503] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:04:41.217309] target_dyn_opt > Initial loss [-1.4852569105404476]\n",
      "\u001b[2K[2018-05-12 22:05:00.094465] target_dyn_opt > Curr loss: -1.235080E+01 [1767: -1.296179E+01], n_evals: 1999, Avg. time per updt: 0.007962\n",
      "[2018-05-12 22:05:00.109496] target_dyn_opt > Done training. New loss [-12.353802] iter: [2000]\n",
      "[2018-05-12 22:05:00.112528] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:05:00.114162] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_18.zip\n",
      "[2018-05-12 22:05:01.004533] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_18.zip\n",
      "[2018-05-12 22:05:01.129984] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_18.zip\n",
      "[2018-05-12 22:05:04.449725] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 22:05:04.454431] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:05:04.617781] SGDOptimizer > Initial loss [70668.3828125]\n",
      "\u001b[2K[2018-05-12 22:07:13.714856] SGDOptimizer > Curr loss: 1.524805E+04, n_evals: 999, Avg. time per updt: 0.127844\n",
      "[2018-05-12 22:07:13.754138] SGDOptimizer > Done training. New loss [19853.105469] iter: [999]\n",
      "[2018-05-12 22:07:13.756011] apply_controller > Starting run\n",
      "[2018-05-12 22:07:13.757377] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:07:13.940928] apply_controller > Done. Stopping robot. Value of run [28.195131]\n",
      "[2018-05-12 22:07:13.942275] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:07:13.943517] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:07:13.947406] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 22:07:13.948701] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:07:13.964399] target_dyn_opt > Initial loss [-7.578592712406454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 22:07:33.662843] target_dyn_opt > Curr loss: -1.305463E+01 [1752: -1.318502E+01], n_evals: 1999, Avg. time per updt: 0.008287\n",
      "[2018-05-12 22:07:33.677745] target_dyn_opt > Done training. New loss [-12.711449] iter: [2000]\n",
      "[2018-05-12 22:07:33.680693] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:07:33.682602] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_19.zip\n",
      "[2018-05-12 22:07:34.647471] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_19.zip\n",
      "[2018-05-12 22:07:34.784304] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_19.zip\n",
      "[2018-05-12 22:07:38.371488] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 22:07:38.376785] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:07:38.520877] SGDOptimizer > Initial loss [16394.966796875]\n",
      "\u001b[2K[2018-05-12 22:09:24.816820] SGDOptimizer > Curr loss: 1.359602E+04, n_evals: 999, Avg. time per updt: 0.104967\n",
      "[2018-05-12 22:09:24.844931] SGDOptimizer > Done training. New loss [16074.857422] iter: [999]\n",
      "[2018-05-12 22:09:24.846839] apply_controller > Starting run\n",
      "[2018-05-12 22:09:24.848117] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:09:25.048324] apply_controller > Done. Stopping robot. Value of run [26.217028]\n",
      "[2018-05-12 22:09:25.049964] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:09:25.051482] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:09:25.055366] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 22:09:25.056904] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:09:25.071158] target_dyn_opt > Initial loss [-3.7869180385115113]\n",
      "\u001b[2K[2018-05-12 22:09:43.327795] target_dyn_opt > Curr loss: -1.296314E+01 [1769: -1.329277E+01], n_evals: 1999, Avg. time per updt: 0.007645\n",
      "[2018-05-12 22:09:43.343374] target_dyn_opt > Done training. New loss [-12.947858] iter: [2000]\n",
      "[2018-05-12 22:09:43.345989] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:09:43.347402] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_20.zip\n",
      "[2018-05-12 22:09:44.345523] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_20.zip\n",
      "[2018-05-12 22:09:44.473490] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_20.zip\n",
      "[2018-05-12 22:09:47.837391] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 22:09:47.842607] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:09:47.968921] SGDOptimizer > Initial loss [13165.5517578125]\n",
      "\u001b[2K[2018-05-12 22:11:37.927502] SGDOptimizer > Curr loss: 2.295849E+04, n_evals: 999, Avg. time per updt: 0.108622\n",
      "[2018-05-12 22:11:37.955993] SGDOptimizer > Done training. New loss [14635.317383] iter: [999]\n",
      "[2018-05-12 22:11:37.957789] apply_controller > Starting run\n",
      "[2018-05-12 22:11:37.959004] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:11:38.127775] apply_controller > Done. Stopping robot. Value of run [28.780373]\n",
      "[2018-05-12 22:11:38.130084] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:11:38.131422] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:11:38.135867] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 22:11:38.137386] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:11:38.154661] target_dyn_opt > Initial loss [-5.128581545943376]\n",
      "\u001b[2K[2018-05-12 22:11:57.672878] target_dyn_opt > Curr loss: -1.322507E+01 [1896: -1.347751E+01], n_evals: 1999, Avg. time per updt: 0.008242\n",
      "[2018-05-12 22:11:57.686403] target_dyn_opt > Done training. New loss [-12.979456] iter: [2000]\n",
      "[2018-05-12 22:11:57.689452] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:11:57.690926] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_21.zip\n",
      "[2018-05-12 22:11:58.726730] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_21.zip\n",
      "[2018-05-12 22:11:58.858373] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_21.zip\n",
      "[2018-05-12 22:12:02.233587] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 22:12:02.238568] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:12:02.381032] SGDOptimizer > Initial loss [15379.1787109375]\n",
      "\u001b[2K[2018-05-12 22:13:49.756762] SGDOptimizer > Curr loss: 1.277448E+04, n_evals: 999, Avg. time per updt: 0.106049\n",
      "[2018-05-12 22:13:49.787156] SGDOptimizer > Done training. New loss [11409.790039] iter: [999]\n",
      "[2018-05-12 22:13:49.789462] apply_controller > Starting run\n",
      "[2018-05-12 22:13:49.791143] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:13:49.983312] apply_controller > Done. Stopping robot. Value of run [23.058249]\n",
      "[2018-05-12 22:13:49.984911] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:13:49.986226] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:13:49.992519] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 22:13:49.993901] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:13:50.008852] target_dyn_opt > Initial loss [1.227931308513996]\n",
      "\u001b[2K[2018-05-12 22:14:09.877732] target_dyn_opt > Curr loss: -1.313012E+01 [1137: -1.365273E+01], n_evals: 1999, Avg. time per updt: 0.008324\n",
      "[2018-05-12 22:14:09.891781] target_dyn_opt > Done training. New loss [-13.347734] iter: [2000]\n",
      "[2018-05-12 22:14:09.896130] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:14:09.897639] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_22.zip\n",
      "[2018-05-12 22:14:11.976311] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_22.zip\n",
      "[2018-05-12 22:14:12.111484] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_22.zip\n",
      "[2018-05-12 22:14:15.483177] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 22:14:15.488187] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:14:15.652437] SGDOptimizer > Initial loss [13309.0849609375]\n",
      "\u001b[2K[2018-05-12 22:16:05.413045] SGDOptimizer > Curr loss: 1.192490E+04, n_evals: 999, Avg. time per updt: 0.108455\n",
      "[2018-05-12 22:16:05.442870] SGDOptimizer > Done training. New loss [11927.899414] iter: [999]\n",
      "[2018-05-12 22:16:05.444816] apply_controller > Starting run\n",
      "[2018-05-12 22:16:05.446389] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:16:05.701570] apply_controller > Done. Stopping robot. Value of run [23.736605]\n",
      "[2018-05-12 22:16:05.703228] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:16:05.704767] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:16:05.709708] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 22:16:05.711022] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:16:05.726318] target_dyn_opt > Initial loss [-6.465689959197209]\n",
      "\u001b[2K[2018-05-12 22:16:25.141522] target_dyn_opt > Curr loss: -1.306431E+01 [1824: -1.384029E+01], n_evals: 1999, Avg. time per updt: 0.008121\n",
      "[2018-05-12 22:16:25.157851] target_dyn_opt > Done training. New loss [-13.338490] iter: [2000]\n",
      "[2018-05-12 22:16:25.160585] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:16:25.161966] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_23.zip\n",
      "[2018-05-12 22:16:26.319433] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_23.zip\n",
      "[2018-05-12 22:16:26.459289] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_23.zip\n",
      "[2018-05-12 22:16:29.840841] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 22:16:29.845809] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:16:30.005098] SGDOptimizer > Initial loss [14091.5341796875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 22:18:32.546978] SGDOptimizer > Curr loss: 2.181756E+04, n_evals: 999, Avg. time per updt: 0.121214\n",
      "[2018-05-12 22:18:32.581876] SGDOptimizer > Done training. New loss [25214.322266] iter: [999]\n",
      "[2018-05-12 22:18:32.583874] apply_controller > Starting run\n",
      "[2018-05-12 22:18:32.585258] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:18:32.761881] apply_controller > Done. Stopping robot. Value of run [29.497971]\n",
      "[2018-05-12 22:18:32.763335] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:18:32.764867] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:18:32.769642] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 22:18:32.771052] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:18:32.788590] target_dyn_opt > Initial loss [-8.119942300812951]\n",
      "\u001b[2K[2018-05-12 22:18:51.980628] target_dyn_opt > Curr loss: -1.346883E+01 [1696: -1.394797E+01], n_evals: 1999, Avg. time per updt: 0.008105\n",
      "[2018-05-12 22:18:51.994706] target_dyn_opt > Done training. New loss [-13.403162] iter: [2000]\n",
      "[2018-05-12 22:18:51.997536] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:18:51.999002] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_24.zip\n",
      "[2018-05-12 22:18:53.161556] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_24.zip\n",
      "[2018-05-12 22:18:53.290600] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_24.zip\n",
      "[2018-05-12 22:18:56.853313] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 22:18:56.859066] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:18:57.019655] SGDOptimizer > Initial loss [24969.966796875]\n",
      "\u001b[2K[2018-05-12 22:21:03.693794] SGDOptimizer > Curr loss: 1.937059E+04, n_evals: 999, Avg. time per updt: 0.125396\n",
      "[2018-05-12 22:21:03.735321] SGDOptimizer > Done training. New loss [14857.560547] iter: [999]\n",
      "[2018-05-12 22:21:03.737616] apply_controller > Starting run\n",
      "[2018-05-12 22:21:03.738835] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:21:03.921706] apply_controller > Done. Stopping robot. Value of run [29.795166]\n",
      "[2018-05-12 22:21:03.922928] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:21:03.924270] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:21:03.929313] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 22:21:03.931174] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:21:03.950750] target_dyn_opt > Initial loss [-5.187703112313223]\n",
      "\u001b[2K[2018-05-12 22:21:24.610994] target_dyn_opt > Curr loss: -1.338504E+01 [1223: -1.412369E+01], n_evals: 1999, Avg. time per updt: 0.008740\n",
      "[2018-05-12 22:21:24.627854] target_dyn_opt > Done training. New loss [-13.750848] iter: [2000]\n",
      "[2018-05-12 22:21:24.630629] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:21:24.632015] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_25.zip\n",
      "[2018-05-12 22:21:25.908754] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_25.zip\n",
      "[2018-05-12 22:21:26.058528] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_25.zip\n",
      "[2018-05-12 22:21:29.579724] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 22:21:29.585583] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:21:29.736345] SGDOptimizer > Initial loss [17671.6015625]\n",
      "\u001b[2K[2018-05-12 22:23:27.567247] SGDOptimizer > Curr loss: 2.736491E+04, n_evals: 999, Avg. time per updt: 0.116511\n",
      "[2018-05-12 22:23:27.599219] SGDOptimizer > Done training. New loss [22971.683594] iter: [999]\n",
      "[2018-05-12 22:23:27.601528] apply_controller > Starting run\n",
      "[2018-05-12 22:23:27.602806] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:23:27.832800] apply_controller > Done. Stopping robot. Value of run [27.894386]\n",
      "[2018-05-12 22:23:27.834145] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:23:27.835423] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:23:27.839903] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 22:23:27.841259] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:23:27.856145] target_dyn_opt > Initial loss [-8.58097209852774]\n",
      "\u001b[2K[2018-05-12 22:23:46.973826] target_dyn_opt > Curr loss: -1.347461E+01 [1316: -1.431109E+01], n_evals: 1999, Avg. time per updt: 0.008039\n",
      "[2018-05-12 22:23:46.989870] target_dyn_opt > Done training. New loss [-13.670623] iter: [2000]\n",
      "[2018-05-12 22:23:46.992834] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:23:46.994429] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_26.zip\n",
      "[2018-05-12 22:23:48.240858] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_26.zip\n",
      "[2018-05-12 22:23:48.370510] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_26.zip\n",
      "[2018-05-12 22:23:51.689004] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 22:23:51.694484] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:23:51.872276] SGDOptimizer > Initial loss [28248.1953125]\n",
      "\u001b[2K[2018-05-12 22:25:56.334622] SGDOptimizer > Curr loss: 1.607081E+04, n_evals: 999, Avg. time per updt: 0.123144\n",
      "[2018-05-12 22:25:56.373351] SGDOptimizer > Done training. New loss [16357.694336] iter: [999]\n",
      "[2018-05-12 22:25:56.375357] apply_controller > Starting run\n",
      "[2018-05-12 22:25:56.376927] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:25:56.557061] apply_controller > Done. Stopping robot. Value of run [29.676315]\n",
      "[2018-05-12 22:25:56.558423] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:25:56.559870] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:25:56.565167] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 22:25:56.566557] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:25:56.581638] target_dyn_opt > Initial loss [-4.339849501628007]\n",
      "\u001b[2K[2018-05-12 22:26:16.862017] target_dyn_opt > Curr loss: -1.411610E+01 [1799: -1.440787E+01], n_evals: 1999, Avg. time per updt: 0.008606\n",
      "[2018-05-12 22:26:16.880009] target_dyn_opt > Done training. New loss [-14.072375] iter: [2000]\n",
      "[2018-05-12 22:26:16.882700] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:26:16.884308] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_27.zip\n",
      "[2018-05-12 22:26:18.368235] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_27.zip\n",
      "[2018-05-12 22:26:18.506605] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_27.zip\n",
      "[2018-05-12 22:26:21.986022] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 22:26:21.990735] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:26:22.191496] SGDOptimizer > Initial loss [18073.3671875]\n",
      "\u001b[2K[2018-05-12 22:28:37.765232] SGDOptimizer > Curr loss: 1.226607E+04, n_evals: 999, Avg. time per updt: 0.134261\n",
      "[2018-05-12 22:28:37.806384] SGDOptimizer > Done training. New loss [12617.904297] iter: [999]\n",
      "[2018-05-12 22:28:37.808191] apply_controller > Starting run\n",
      "[2018-05-12 22:28:37.809403] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:28:37.998431] apply_controller > Done. Stopping robot. Value of run [26.206591]\n",
      "[2018-05-12 22:28:38.000044] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:28:38.001350] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:28:38.005853] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 22:28:38.007370] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:28:38.022975] target_dyn_opt > Initial loss [-5.884184162058246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 22:28:58.190506] target_dyn_opt > Curr loss: -1.398672E+01 [1321: -1.450596E+01], n_evals: 1999, Avg. time per updt: 0.008540\n",
      "[2018-05-12 22:28:58.204607] target_dyn_opt > Done training. New loss [-13.992560] iter: [2000]\n",
      "[2018-05-12 22:28:58.207376] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:28:58.209185] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_28.zip\n",
      "[2018-05-12 22:28:59.552877] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_28.zip\n",
      "[2018-05-12 22:28:59.683260] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_28.zip\n",
      "[2018-05-12 22:29:03.052390] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 22:29:03.057899] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:29:03.235752] SGDOptimizer > Initial loss [11164.6904296875]\n",
      "\u001b[2K[2018-05-12 22:30:55.532772] SGDOptimizer > Curr loss: 1.735965E+04, n_evals: 999, Avg. time per updt: 0.110977\n",
      "[2018-05-12 22:30:55.563293] SGDOptimizer > Done training. New loss [15436.149414] iter: [999]\n",
      "[2018-05-12 22:30:55.565087] apply_controller > Starting run\n",
      "[2018-05-12 22:30:55.566275] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:30:55.730487] apply_controller > Done. Stopping robot. Value of run [29.661016]\n",
      "[2018-05-12 22:30:55.731838] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:30:55.733571] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:30:55.738346] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 22:30:55.739989] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:30:55.755333] target_dyn_opt > Initial loss [-5.844864110631504]\n",
      "\u001b[2K[2018-05-12 22:31:14.463931] target_dyn_opt > Curr loss: -1.361149E+01 [1912: -1.455427E+01], n_evals: 1999, Avg. time per updt: 0.007874\n",
      "[2018-05-12 22:31:14.478382] target_dyn_opt > Done training. New loss [-13.965265] iter: [2000]\n",
      "[2018-05-12 22:31:14.480968] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:31:14.482431] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_29.zip\n",
      "[2018-05-12 22:31:15.856433] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_29.zip\n",
      "[2018-05-12 22:31:15.987593] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_29.zip\n",
      "[2018-05-12 22:31:19.328992] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 22:31:19.334158] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:31:19.513462] SGDOptimizer > Initial loss [13570.1591796875]\n",
      "\u001b[2K[2018-05-12 22:33:21.635870] SGDOptimizer > Curr loss: 2.206962E+04, n_evals: 999, Avg. time per updt: 0.120672\n",
      "[2018-05-12 22:33:21.671444] SGDOptimizer > Done training. New loss [28530.490234] iter: [999]\n",
      "[2018-05-12 22:33:21.673348] apply_controller > Starting run\n",
      "[2018-05-12 22:33:21.674771] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:33:21.852665] apply_controller > Done. Stopping robot. Value of run [28.610954]\n",
      "[2018-05-12 22:33:21.854002] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:33:21.855302] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:33:21.860088] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 22:33:21.861608] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:33:21.876870] target_dyn_opt > Initial loss [-9.893073824608287]\n",
      "\u001b[2K[2018-05-12 22:33:41.163253] target_dyn_opt > Curr loss: -1.381093E+01 [1965: -1.482831E+01], n_evals: 1999, Avg. time per updt: 0.008168\n",
      "[2018-05-12 22:33:41.177233] target_dyn_opt > Done training. New loss [-14.257425] iter: [2000]\n",
      "[2018-05-12 22:33:41.180029] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:33:41.181722] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/experience_30.zip\n",
      "[2018-05-12 22:33:42.604947] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/policy_30.zip\n",
      "[2018-05-12 22:33:42.735570] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_005_il_klqp_from_source/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 5 learn starting from source params, using klqp imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_005_il_klqp_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 22:33:46.557839] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 22:33:46.586640] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 22:33:46.624490] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-12 22:33:46.647262] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-12 22:33:46.677913] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 22:33:46.692941] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 22:33:46.698791] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-12 22:33:46.711768] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f8d1f485b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f8d1f48b050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-12 22:33:46.732033] Experience > Initialising new experience dataset\n",
      "[2018-05-12 22:33:46.733829] Executing initial policy\n",
      "[2018-05-12 22:33:46.735923] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-12 22:33:46.815872] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-12 22:33:46.981867] NNPolicy > Done compiling\n",
      "[2018-05-12 22:33:46.983446] apply_controller > Starting run\n",
      "[2018-05-12 22:33:46.984918] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:33:47.171906] apply_controller > Done. Stopping robot. Value of run [28.959900]\n",
      "[2018-05-12 22:33:47.173548] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:33:47.174277] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:33:47.176253] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-12 22:33:47.177465] target_dyn > Initialising loss function\n",
      "[2018-05-12 22:33:47.325847] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-12 22:33:47.636833] target_dyn_opt > No gradient clipping\n",
      "[2018-05-12 22:33:47.638095] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-12 22:33:47.697840] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-12 22:33:48.587471] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-12 22:33:56.091860] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:33:56.101026] target_dyn_opt > Initial loss [1378.8822830781855]\n",
      "\u001b[2K[2018-05-12 22:34:06.613708] target_dyn_opt > Curr loss: 4.145327E+01 [1916: 4.085520E+01], n_evals: 1999, Avg. time per updt: 0.003673\n",
      "[2018-05-12 22:34:06.620057] target_dyn_opt > Done training. New loss [41.064402] iter: [2000]\n",
      "[2018-05-12 22:34:06.847744] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:34:07.037544] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 22:34:07.039294] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 22:34:07.173906] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 22:34:07.175154] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 22:34:07.728480] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-12 22:34:07.729774] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-12 22:34:07.824079] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-12 22:34:07.825354] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-12 22:34:11.816756] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-12 22:34:13.101502] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-12 22:34:13.111041] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-12 22:34:13.142485] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-12 22:34:19.336419] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-12 22:34:41.508352] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_0.zip\n",
      "[2018-05-12 22:34:41.578908] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_0.zip\n",
      "[2018-05-12 22:34:41.617703] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_0.zip\n",
      "[2018-05-12 22:34:41.751140] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-12 22:34:41.752699] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-12 22:34:41.766384] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:34:44.294142] SGDOptimizer > Initial loss [5187.408203125]\n",
      "\u001b[2K[2018-05-12 22:36:35.049043] SGDOptimizer > Curr loss: 8.683647E+01, n_evals: 999, Avg. time per updt: 0.109386\n",
      "[2018-05-12 22:36:35.079858] SGDOptimizer > Done training. New loss [176.350433] iter: [999]\n",
      "[2018-05-12 22:36:35.084960] apply_controller > Starting run\n",
      "[2018-05-12 22:36:35.086857] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:36:35.270510] apply_controller > Done. Stopping robot. Value of run [29.944075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 22:36:35.271989] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:36:35.273311] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:36:35.277899] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-12 22:36:35.279402] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:36:35.323002] target_dyn_opt > Initial loss [145.800531711044]\n",
      "\u001b[2K[2018-05-12 22:36:48.520767] target_dyn_opt > Curr loss: 1.427014E+01 [1997: 1.401361E+01], n_evals: 1999, Avg. time per updt: 0.005071\n",
      "[2018-05-12 22:36:48.530135] target_dyn_opt > Done training. New loss [14.547424] iter: [2000]\n",
      "[2018-05-12 22:36:48.532962] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:36:48.535975] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_1.zip\n",
      "[2018-05-12 22:36:48.616391] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_1.zip\n",
      "[2018-05-12 22:36:48.653599] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_1.zip\n",
      "[2018-05-12 22:36:52.425154] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-12 22:36:52.430428] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:36:52.567702] SGDOptimizer > Initial loss [654.1660766601562]\n",
      "\u001b[2K[2018-05-12 22:38:38.807419] SGDOptimizer > Curr loss: 1.075757E+02, n_evals: 999, Avg. time per updt: 0.104908\n",
      "[2018-05-12 22:38:38.836930] SGDOptimizer > Done training. New loss [117.333290] iter: [999]\n",
      "[2018-05-12 22:38:38.838812] apply_controller > Starting run\n",
      "[2018-05-12 22:38:38.840144] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:38:39.111627] apply_controller > Done. Stopping robot. Value of run [28.866335]\n",
      "[2018-05-12 22:38:39.112999] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:38:39.114422] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:38:39.116549] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-12 22:38:39.117866] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:38:39.131140] target_dyn_opt > Initial loss [189.22355106335948]\n",
      "\u001b[2K[2018-05-12 22:38:57.444286] target_dyn_opt > Curr loss: 6.896725E+00 [1984: 6.566219E+00], n_evals: 1999, Avg. time per updt: 0.007388\n",
      "[2018-05-12 22:38:57.458987] target_dyn_opt > Done training. New loss [6.937548] iter: [2000]\n",
      "[2018-05-12 22:38:57.461810] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:38:57.464727] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_2.zip\n",
      "[2018-05-12 22:38:57.594281] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_2.zip\n",
      "[2018-05-12 22:38:57.632748] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_2.zip\n",
      "[2018-05-12 22:39:01.435432] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-12 22:39:01.439500] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:39:01.643588] SGDOptimizer > Initial loss [185.95242309570312]\n",
      "\u001b[2K[2018-05-12 22:40:51.721742] SGDOptimizer > Curr loss: 5.829965E+01, n_evals: 999, Avg. time per updt: 0.108775\n",
      "[2018-05-12 22:40:51.752014] SGDOptimizer > Done training. New loss [60.943123] iter: [999]\n",
      "[2018-05-12 22:40:51.753557] apply_controller > Starting run\n",
      "[2018-05-12 22:40:51.755074] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:40:51.931352] apply_controller > Done. Stopping robot. Value of run [29.708044]\n",
      "[2018-05-12 22:40:51.932682] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:40:51.933898] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:40:51.935989] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-12 22:40:51.937220] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:40:51.950192] target_dyn_opt > Initial loss [11.49968803648291]\n",
      "\u001b[2K[2018-05-12 22:41:10.683384] target_dyn_opt > Curr loss: 1.050531E+00 [1846: 6.708363E-01], n_evals: 1999, Avg. time per updt: 0.007862\n",
      "[2018-05-12 22:41:10.696993] target_dyn_opt > Done training. New loss [0.781921] iter: [2000]\n",
      "[2018-05-12 22:41:10.700018] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:41:10.701667] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_3.zip\n",
      "[2018-05-12 22:41:10.869007] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_3.zip\n",
      "[2018-05-12 22:41:10.908579] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_3.zip\n",
      "[2018-05-12 22:41:14.404245] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-12 22:41:14.408619] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:41:14.550449] SGDOptimizer > Initial loss [101.59522247314453]\n",
      "\u001b[2K[2018-05-12 22:43:13.067864] SGDOptimizer > Curr loss: 8.977139E+01, n_evals: 999, Avg. time per updt: 0.117184\n",
      "[2018-05-12 22:43:13.100704] SGDOptimizer > Done training. New loss [89.147346] iter: [999]\n",
      "[2018-05-12 22:43:13.102697] apply_controller > Starting run\n",
      "[2018-05-12 22:43:13.104002] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:43:13.294487] apply_controller > Done. Stopping robot. Value of run [26.970053]\n",
      "[2018-05-12 22:43:13.295839] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:43:13.297063] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:43:13.299168] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-12 22:43:13.300537] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:43:13.314386] target_dyn_opt > Initial loss [18.347899045204294]\n",
      "\u001b[2K[2018-05-12 22:43:32.437280] target_dyn_opt > Curr loss: -2.000592E+00 [1946: -2.340518E+00], n_evals: 1999, Avg. time per updt: 0.008012\n",
      "[2018-05-12 22:43:32.451834] target_dyn_opt > Done training. New loss [-2.138354] iter: [2000]\n",
      "[2018-05-12 22:43:32.454630] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:43:32.456212] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_4.zip\n",
      "[2018-05-12 22:43:32.686797] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_4.zip\n",
      "[2018-05-12 22:43:32.727202] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_4.zip\n",
      "[2018-05-12 22:43:36.355928] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-12 22:43:36.359875] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:43:36.514245] SGDOptimizer > Initial loss [149.32949829101562]\n",
      "\u001b[2K[2018-05-12 22:45:51.534452] SGDOptimizer > Curr loss: 1.196521E+02, n_evals: 999, Avg. time per updt: 0.133703\n",
      "[2018-05-12 22:45:51.571375] SGDOptimizer > Done training. New loss [81.601318] iter: [999]\n",
      "[2018-05-12 22:45:51.575672] apply_controller > Starting run\n",
      "[2018-05-12 22:45:51.577278] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:45:51.766811] apply_controller > Done. Stopping robot. Value of run [27.351225]\n",
      "[2018-05-12 22:45:51.768151] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:45:51.769395] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:45:51.774545] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-12 22:45:51.775796] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:45:51.811893] target_dyn_opt > Initial loss [0.03564188329652751]\n",
      "\u001b[2K[2018-05-12 22:46:10.626811] target_dyn_opt > Curr loss: -3.826898E+00 [1872: -4.528417E+00], n_evals: 1999, Avg. time per updt: 0.007875\n",
      "[2018-05-12 22:46:10.642066] target_dyn_opt > Done training. New loss [-4.097619] iter: [2000]\n",
      "[2018-05-12 22:46:10.644681] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:46:10.647924] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_5.zip\n",
      "[2018-05-12 22:46:10.907139] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 22:46:10.946261] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_5.zip\n",
      "[2018-05-12 22:46:14.430147] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-12 22:46:14.435592] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:46:14.584460] SGDOptimizer > Initial loss [81.24007415771484]\n",
      "\u001b[2K[2018-05-12 22:48:01.631533] SGDOptimizer > Curr loss: 1.514444E+02, n_evals: 999, Avg. time per updt: 0.105706\n",
      "[2018-05-12 22:48:01.659496] SGDOptimizer > Done training. New loss [143.600677] iter: [999]\n",
      "[2018-05-12 22:48:01.661632] apply_controller > Starting run\n",
      "[2018-05-12 22:48:01.663096] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:48:01.839135] apply_controller > Done. Stopping robot. Value of run [28.081289]\n",
      "[2018-05-12 22:48:01.840584] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:48:01.841823] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:48:01.844413] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-12 22:48:01.845867] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:48:01.859255] target_dyn_opt > Initial loss [2.0260285001082963]\n",
      "\u001b[2K[2018-05-12 22:48:20.383392] target_dyn_opt > Curr loss: -5.717382E+00 [1931: -6.218137E+00], n_evals: 1999, Avg. time per updt: 0.007783\n",
      "[2018-05-12 22:48:20.397069] target_dyn_opt > Done training. New loss [-5.683393] iter: [2000]\n",
      "[2018-05-12 22:48:20.399624] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:48:20.401089] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_6.zip\n",
      "[2018-05-12 22:48:20.694187] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_6.zip\n",
      "[2018-05-12 22:48:20.732503] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_6.zip\n",
      "[2018-05-12 22:48:24.238029] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-12 22:48:24.242554] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:48:24.412086] SGDOptimizer > Initial loss [145.55084228515625]\n",
      "\u001b[2K[2018-05-12 22:50:23.091571] SGDOptimizer > Curr loss: 1.451062E+02, n_evals: 999, Avg. time per updt: 0.117321\n",
      "[2018-05-12 22:50:23.125401] SGDOptimizer > Done training. New loss [136.026642] iter: [999]\n",
      "[2018-05-12 22:50:23.127012] apply_controller > Starting run\n",
      "[2018-05-12 22:50:23.128206] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:50:23.322314] apply_controller > Done. Stopping robot. Value of run [29.996330]\n",
      "[2018-05-12 22:50:23.323703] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:50:23.325241] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:50:23.328654] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-12 22:50:23.329942] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:50:23.344752] target_dyn_opt > Initial loss [1.2848230990870242]\n",
      "\u001b[2K[2018-05-12 22:50:42.364591] target_dyn_opt > Curr loss: -6.785577E+00 [1879: -7.215801E+00], n_evals: 1999, Avg. time per updt: 0.008015\n",
      "[2018-05-12 22:50:42.379040] target_dyn_opt > Done training. New loss [-7.017191] iter: [2000]\n",
      "[2018-05-12 22:50:42.382024] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:50:42.383343] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_7.zip\n",
      "[2018-05-12 22:50:42.716779] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_7.zip\n",
      "[2018-05-12 22:50:42.754091] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_7.zip\n",
      "[2018-05-12 22:50:46.273139] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-12 22:50:46.277008] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:50:46.432158] SGDOptimizer > Initial loss [141.7122344970703]\n",
      "\u001b[2K[2018-05-12 22:52:48.812592] SGDOptimizer > Curr loss: 1.185104E+02, n_evals: 999, Avg. time per updt: 0.120912\n",
      "[2018-05-12 22:52:48.853199] SGDOptimizer > Done training. New loss [135.695328] iter: [999]\n",
      "[2018-05-12 22:52:48.856740] apply_controller > Starting run\n",
      "[2018-05-12 22:52:48.858050] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:52:49.069462] apply_controller > Done. Stopping robot. Value of run [26.744787]\n",
      "[2018-05-12 22:52:49.070796] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:52:49.071683] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:52:49.075259] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-12 22:52:49.076653] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:52:49.094326] target_dyn_opt > Initial loss [12.06047696057864]\n",
      "\u001b[2K[2018-05-12 22:53:08.115570] target_dyn_opt > Curr loss: -7.617488E+00 [1540: -8.068829E+00], n_evals: 1999, Avg. time per updt: 0.008023\n",
      "[2018-05-12 22:53:08.131960] target_dyn_opt > Done training. New loss [-7.673449] iter: [2000]\n",
      "[2018-05-12 22:53:08.134903] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:53:08.137662] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_8.zip\n",
      "[2018-05-12 22:53:08.538948] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_8.zip\n",
      "[2018-05-12 22:53:08.578949] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_8.zip\n",
      "[2018-05-12 22:53:12.481922] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-12 22:53:12.486928] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:53:12.655166] SGDOptimizer > Initial loss [118.7622299194336]\n",
      "\u001b[2K[2018-05-12 22:55:15.584955] SGDOptimizer > Curr loss: 1.046585E+02, n_evals: 999, Avg. time per updt: 0.121602\n",
      "[2018-05-12 22:55:15.620399] SGDOptimizer > Done training. New loss [107.858307] iter: [999]\n",
      "[2018-05-12 22:55:15.622346] apply_controller > Starting run\n",
      "[2018-05-12 22:55:15.623626] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:55:15.812686] apply_controller > Done. Stopping robot. Value of run [29.987360]\n",
      "[2018-05-12 22:55:15.813921] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:55:15.815407] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:55:15.818021] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-12 22:55:15.819505] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:55:15.833538] target_dyn_opt > Initial loss [6.327591833163952]\n",
      "\u001b[2K[2018-05-12 22:55:34.984664] target_dyn_opt > Curr loss: -8.345151E+00 [1923: -8.767111E+00], n_evals: 1999, Avg. time per updt: 0.007912\n",
      "[2018-05-12 22:55:35.346713] target_dyn_opt > Done training. New loss [-8.213332] iter: [2000]\n",
      "[2018-05-12 22:55:35.349801] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:55:35.353451] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_9.zip\n",
      "[2018-05-12 22:55:35.784335] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_9.zip\n",
      "[2018-05-12 22:55:35.821541] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_9.zip\n",
      "[2018-05-12 22:55:39.425384] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-12 22:55:39.429720] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:55:39.584940] SGDOptimizer > Initial loss [114.66996765136719]\n",
      "\u001b[2K[2018-05-12 22:57:17.856192] SGDOptimizer > Curr loss: 1.609418E+02, n_evals: 999, Avg. time per updt: 0.096981\n",
      "[2018-05-12 22:57:17.885240] SGDOptimizer > Done training. New loss [145.234375] iter: [999]\n",
      "[2018-05-12 22:57:17.888647] apply_controller > Starting run\n",
      "[2018-05-12 22:57:17.890040] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:57:18.069743] apply_controller > Done. Stopping robot. Value of run [27.975269]\n",
      "[2018-05-12 22:57:18.071210] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:57:18.072676] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:57:18.077524] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 22:57:18.078900] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:57:18.092273] target_dyn_opt > Initial loss [-4.237832629755373]\n",
      "\u001b[2K[2018-05-12 22:57:36.121767] target_dyn_opt > Curr loss: -8.656337E+00 [1672: -9.448584E+00], n_evals: 1999, Avg. time per updt: 0.007538\n",
      "[2018-05-12 22:57:36.137298] target_dyn_opt > Done training. New loss [-8.661101] iter: [2000]\n",
      "[2018-05-12 22:57:36.140306] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:57:36.141897] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_10.zip\n",
      "[2018-05-12 22:57:36.612245] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_10.zip\n",
      "[2018-05-12 22:57:36.649563] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_10.zip\n",
      "[2018-05-12 22:57:40.146833] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-12 22:57:40.151360] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:57:40.288308] SGDOptimizer > Initial loss [166.1369171142578]\n",
      "\u001b[2K[2018-05-12 22:59:27.310084] SGDOptimizer > Curr loss: 1.493581E+02, n_evals: 999, Avg. time per updt: 0.104763\n",
      "[2018-05-12 22:59:27.348909] SGDOptimizer > Done training. New loss [155.773453] iter: [999]\n",
      "[2018-05-12 22:59:27.350871] apply_controller > Starting run\n",
      "[2018-05-12 22:59:27.352109] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 22:59:27.593813] apply_controller > Done. Stopping robot. Value of run [26.618288]\n",
      "[2018-05-12 22:59:27.595217] target_2x_mass > Stopping robot\n",
      "[2018-05-12 22:59:27.596434] train_dynamics > Training dynamics model\n",
      "[2018-05-12 22:59:27.601161] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-12 22:59:27.603136] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 22:59:27.622455] target_dyn_opt > Initial loss [-2.633727089940817]\n",
      "\u001b[2K[2018-05-12 22:59:46.622406] target_dyn_opt > Curr loss: -9.457104E+00 [1809: -9.966405E+00], n_evals: 1999, Avg. time per updt: 0.007995\n",
      "[2018-05-12 22:59:46.636120] target_dyn_opt > Done training. New loss [-9.523770] iter: [2000]\n",
      "[2018-05-12 22:59:46.638692] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 22:59:46.641424] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_11.zip\n",
      "[2018-05-12 22:59:47.146848] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_11.zip\n",
      "[2018-05-12 22:59:47.184939] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_11.zip\n",
      "[2018-05-12 22:59:51.281779] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-12 22:59:51.287426] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 22:59:51.436112] SGDOptimizer > Initial loss [120.96696472167969]\n",
      "\u001b[2K[2018-05-12 23:01:48.089328] SGDOptimizer > Curr loss: 7.791038E+01, n_evals: 999, Avg. time per updt: 0.115373\n",
      "[2018-05-12 23:01:48.132248] SGDOptimizer > Done training. New loss [97.334503] iter: [999]\n",
      "[2018-05-12 23:01:48.137236] apply_controller > Starting run\n",
      "[2018-05-12 23:01:48.139544] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:01:48.396668] apply_controller > Done. Stopping robot. Value of run [24.935698]\n",
      "[2018-05-12 23:01:48.398137] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:01:48.399557] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:01:48.402952] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-12 23:01:48.404358] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:01:48.437176] target_dyn_opt > Initial loss [-5.117164140038528]\n",
      "\u001b[2K[2018-05-12 23:02:08.117923] target_dyn_opt > Curr loss: -9.973931E+00 [1929: -1.039388E+01], n_evals: 1999, Avg. time per updt: 0.008323\n",
      "[2018-05-12 23:02:08.134867] target_dyn_opt > Done training. New loss [-9.740612] iter: [2000]\n",
      "[2018-05-12 23:02:08.143612] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:02:08.145673] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_12.zip\n",
      "[2018-05-12 23:02:08.704773] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_12.zip\n",
      "[2018-05-12 23:02:08.742174] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_12.zip\n",
      "[2018-05-12 23:02:12.350883] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-12 23:02:12.356132] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:02:12.538086] SGDOptimizer > Initial loss [101.95169067382812]\n",
      "\u001b[2K[2018-05-12 23:04:15.965238] SGDOptimizer > Curr loss: 1.076730E+02, n_evals: 999, Avg. time per updt: 0.122150\n",
      "[2018-05-12 23:04:16.002597] SGDOptimizer > Done training. New loss [99.611221] iter: [999]\n",
      "[2018-05-12 23:04:16.004563] apply_controller > Starting run\n",
      "[2018-05-12 23:04:16.005898] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:04:16.193911] apply_controller > Done. Stopping robot. Value of run [24.907858]\n",
      "[2018-05-12 23:04:16.195246] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:04:16.196606] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:04:16.199892] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-12 23:04:16.201390] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:04:16.216076] target_dyn_opt > Initial loss [-8.161971819371425]\n",
      "\u001b[2K[2018-05-12 23:04:36.130433] target_dyn_opt > Curr loss: -1.043669E+01 [1354: -1.081405E+01], n_evals: 1999, Avg. time per updt: 0.008406\n",
      "[2018-05-12 23:04:36.145048] target_dyn_opt > Done training. New loss [-10.476868] iter: [2000]\n",
      "[2018-05-12 23:04:36.147621] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:04:36.150205] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_13.zip\n",
      "[2018-05-12 23:04:36.746857] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_13.zip\n",
      "[2018-05-12 23:04:36.784470] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_13.zip\n",
      "[2018-05-12 23:04:40.328576] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-12 23:04:40.333607] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:04:40.498934] SGDOptimizer > Initial loss [102.13933563232422]\n",
      "\u001b[2K[2018-05-12 23:06:45.020945] SGDOptimizer > Curr loss: 1.146577E+02, n_evals: 999, Avg. time per updt: 0.123262\n",
      "[2018-05-12 23:06:45.059352] SGDOptimizer > Done training. New loss [158.355774] iter: [999]\n",
      "[2018-05-12 23:06:45.063091] apply_controller > Starting run\n",
      "[2018-05-12 23:06:45.064302] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:06:45.244735] apply_controller > Done. Stopping robot. Value of run [28.932150]\n",
      "[2018-05-12 23:06:45.246323] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:06:45.247643] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:06:45.251699] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-12 23:06:45.255006] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:06:45.269911] target_dyn_opt > Initial loss [-8.295849622255083]\n",
      "\u001b[2K[2018-05-12 23:07:04.304639] target_dyn_opt > Curr loss: -1.064524E+01 [1434: -1.124363E+01], n_evals: 1999, Avg. time per updt: 0.008041\n",
      "[2018-05-12 23:07:04.319492] target_dyn_opt > Done training. New loss [-10.759738] iter: [2000]\n",
      "[2018-05-12 23:07:04.322322] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:07:04.323846] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_14.zip\n",
      "[2018-05-12 23:07:04.938746] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_14.zip\n",
      "[2018-05-12 23:07:04.975636] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_14.zip\n",
      "[2018-05-12 23:07:08.419451] ==== Iteration [15], experience: [450 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-12 23:07:08.423880] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:07:08.591373] SGDOptimizer > Initial loss [124.55823516845703]\n",
      "\u001b[2K[2018-05-12 23:09:09.416131] SGDOptimizer > Curr loss: 1.206766E+02, n_evals: 999, Avg. time per updt: 0.119558\n",
      "[2018-05-12 23:09:09.452660] SGDOptimizer > Done training. New loss [89.575188] iter: [999]\n",
      "[2018-05-12 23:09:09.454545] apply_controller > Starting run\n",
      "[2018-05-12 23:09:09.456003] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:09:09.664946] apply_controller > Done. Stopping robot. Value of run [27.065147]\n",
      "[2018-05-12 23:09:09.666290] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:09:09.667580] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:09:09.671439] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-12 23:09:09.672837] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:09:09.688297] target_dyn_opt > Initial loss [2.6805963020386367]\n",
      "\u001b[2K[2018-05-12 23:09:28.378107] target_dyn_opt > Curr loss: -1.067746E+01 [1938: -1.148972E+01], n_evals: 1999, Avg. time per updt: 0.007864\n",
      "[2018-05-12 23:09:28.393445] target_dyn_opt > Done training. New loss [-10.835739] iter: [2000]\n",
      "[2018-05-12 23:09:28.396071] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:09:28.397511] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_15.zip\n",
      "[2018-05-12 23:09:29.050480] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_15.zip\n",
      "[2018-05-12 23:09:29.088103] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_15.zip\n",
      "[2018-05-12 23:09:32.557937] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-12 23:09:32.562610] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:09:32.724545] SGDOptimizer > Initial loss [100.7945785522461]\n",
      "\u001b[2K[2018-05-12 23:11:25.646903] SGDOptimizer > Curr loss: 5.279827E+01, n_evals: 999, Avg. time per updt: 0.111636\n",
      "[2018-05-12 23:11:25.684958] SGDOptimizer > Done training. New loss [69.371895] iter: [999]\n",
      "[2018-05-12 23:11:25.686836] apply_controller > Starting run\n",
      "[2018-05-12 23:11:25.688243] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:11:25.880683] apply_controller > Done. Stopping robot. Value of run [28.960651]\n",
      "[2018-05-12 23:11:25.881898] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:11:25.883445] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:11:25.888313] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-12 23:11:25.889770] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:11:25.903805] target_dyn_opt > Initial loss [-8.148589302511777]\n",
      "\u001b[2K[2018-05-12 23:11:45.343140] target_dyn_opt > Curr loss: -1.094428E+01 [1743: -1.170029E+01], n_evals: 1999, Avg. time per updt: 0.008220\n",
      "[2018-05-12 23:11:45.357609] target_dyn_opt > Done training. New loss [-11.257894] iter: [2000]\n",
      "[2018-05-12 23:11:45.360501] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:11:45.362056] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_16.zip\n",
      "[2018-05-12 23:11:46.061211] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_16.zip\n",
      "[2018-05-12 23:11:46.098951] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_16.zip\n",
      "[2018-05-12 23:11:49.549932] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-12 23:11:49.554889] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:11:49.707590] SGDOptimizer > Initial loss [65.5654067993164]\n",
      "\u001b[2K[2018-05-12 23:13:51.532193] SGDOptimizer > Curr loss: 6.021614E+01, n_evals: 999, Avg. time per updt: 0.120545\n",
      "[2018-05-12 23:13:51.571419] SGDOptimizer > Done training. New loss [67.172180] iter: [999]\n",
      "[2018-05-12 23:13:51.573138] apply_controller > Starting run\n",
      "[2018-05-12 23:13:51.574348] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:13:51.796758] apply_controller > Done. Stopping robot. Value of run [26.739265]\n",
      "[2018-05-12 23:13:51.798359] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:13:51.799848] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:13:51.803078] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-12 23:13:51.804443] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:13:51.819152] target_dyn_opt > Initial loss [19.874519011298357]\n",
      "\u001b[2K[2018-05-12 23:14:11.377921] target_dyn_opt > Curr loss: -1.077101E+01 [1772: -1.196073E+01], n_evals: 1999, Avg. time per updt: 0.008287\n",
      "[2018-05-12 23:14:11.392757] target_dyn_opt > Done training. New loss [-11.432910] iter: [2000]\n",
      "[2018-05-12 23:14:11.395902] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:14:11.397276] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_17.zip\n",
      "[2018-05-12 23:14:12.179885] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_17.zip\n",
      "[2018-05-12 23:14:12.220021] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_17.zip\n",
      "[2018-05-12 23:14:15.766262] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-12 23:14:15.771315] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:14:15.962293] SGDOptimizer > Initial loss [132.12811279296875]\n",
      "\u001b[2K[2018-05-12 23:16:21.731990] SGDOptimizer > Curr loss: 5.330190E+01, n_evals: 999, Avg. time per updt: 0.124508\n",
      "[2018-05-12 23:16:21.770617] SGDOptimizer > Done training. New loss [73.910522] iter: [999]\n",
      "[2018-05-12 23:16:21.772243] apply_controller > Starting run\n",
      "[2018-05-12 23:16:21.773531] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:16:21.952920] apply_controller > Done. Stopping robot. Value of run [28.202671]\n",
      "[2018-05-12 23:16:21.954539] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:16:21.955976] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:16:21.959116] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-12 23:16:21.960526] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:16:21.974960] target_dyn_opt > Initial loss [-8.062680901719524]\n",
      "\u001b[2K[2018-05-12 23:16:41.307202] target_dyn_opt > Curr loss: -1.167120E+01 [1385: -1.220049E+01], n_evals: 1999, Avg. time per updt: 0.008185\n",
      "[2018-05-12 23:16:41.321835] target_dyn_opt > Done training. New loss [-11.524661] iter: [2000]\n",
      "[2018-05-12 23:16:41.324891] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:16:41.326258] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_18.zip\n",
      "[2018-05-12 23:16:42.115392] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_18.zip\n",
      "[2018-05-12 23:16:42.154333] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_18.zip\n",
      "[2018-05-12 23:16:45.609455] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-12 23:16:45.614334] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:16:45.781572] SGDOptimizer > Initial loss [84.99488067626953]\n",
      "\u001b[2K[2018-05-12 23:18:52.979325] SGDOptimizer > Curr loss: 8.489489E+01, n_evals: 999, Avg. time per updt: 0.125922\n",
      "[2018-05-12 23:18:53.019789] SGDOptimizer > Done training. New loss [78.007645] iter: [999]\n",
      "[2018-05-12 23:18:53.021529] apply_controller > Starting run\n",
      "[2018-05-12 23:18:53.022754] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:18:53.215549] apply_controller > Done. Stopping robot. Value of run [26.586445]\n",
      "[2018-05-12 23:18:53.217243] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:18:53.218466] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:18:53.223273] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-12 23:18:53.224625] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:18:53.238886] target_dyn_opt > Initial loss [7.694470074361768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 23:19:12.242814] target_dyn_opt > Curr loss: -1.160376E+01 [1464: -1.225831E+01], n_evals: 1999, Avg. time per updt: 0.008016\n",
      "[2018-05-12 23:19:12.257803] target_dyn_opt > Done training. New loss [-11.901140] iter: [2000]\n",
      "[2018-05-12 23:19:12.260908] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:19:12.262252] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_19.zip\n",
      "[2018-05-12 23:19:13.093271] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_19.zip\n",
      "[2018-05-12 23:19:13.130492] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_19.zip\n",
      "[2018-05-12 23:19:16.584182] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-12 23:19:16.589262] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:19:16.745941] SGDOptimizer > Initial loss [70.28131866455078]\n",
      "\u001b[2K[2018-05-12 23:21:16.441296] SGDOptimizer > Curr loss: 1.200001E+02, n_evals: 999, Avg. time per updt: 0.118421\n",
      "[2018-05-12 23:21:16.476874] SGDOptimizer > Done training. New loss [107.650444] iter: [999]\n",
      "[2018-05-12 23:21:16.479138] apply_controller > Starting run\n",
      "[2018-05-12 23:21:16.480538] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:21:16.667671] apply_controller > Done. Stopping robot. Value of run [25.421917]\n",
      "[2018-05-12 23:21:16.669018] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:21:16.670387] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:21:16.673997] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-12 23:21:16.675628] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:21:16.689663] target_dyn_opt > Initial loss [-5.133883698624734]\n",
      "\u001b[2K[2018-05-12 23:21:35.649264] target_dyn_opt > Curr loss: -1.190762E+01 [1566: -1.258061E+01], n_evals: 1999, Avg. time per updt: 0.008005\n",
      "[2018-05-12 23:21:35.664604] target_dyn_opt > Done training. New loss [-11.995735] iter: [2000]\n",
      "[2018-05-12 23:21:35.667286] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:21:35.668709] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_20.zip\n",
      "[2018-05-12 23:21:36.538302] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_20.zip\n",
      "[2018-05-12 23:21:36.575603] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_20.zip\n",
      "[2018-05-12 23:21:40.052087] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-12 23:21:40.057072] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:21:40.193056] SGDOptimizer > Initial loss [148.5163116455078]\n",
      "\u001b[2K[2018-05-12 23:23:28.566196] SGDOptimizer > Curr loss: 8.894701E+01, n_evals: 999, Avg. time per updt: 0.107077\n",
      "[2018-05-12 23:23:28.596439] SGDOptimizer > Done training. New loss [89.111427] iter: [999]\n",
      "[2018-05-12 23:23:28.598277] apply_controller > Starting run\n",
      "[2018-05-12 23:23:28.599596] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:23:28.790875] apply_controller > Done. Stopping robot. Value of run [29.239727]\n",
      "[2018-05-12 23:23:28.792535] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:23:28.793970] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:23:28.797625] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-12 23:23:28.799016] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:23:28.814557] target_dyn_opt > Initial loss [-7.419097950466]\n",
      "\u001b[2K[2018-05-12 23:23:47.944316] target_dyn_opt > Curr loss: -1.223278E+01 [1220: -1.273407E+01], n_evals: 1999, Avg. time per updt: 0.008079\n",
      "[2018-05-12 23:23:47.958762] target_dyn_opt > Done training. New loss [-11.965124] iter: [2000]\n",
      "[2018-05-12 23:23:47.961279] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:23:47.962994] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_21.zip\n",
      "[2018-05-12 23:23:48.870383] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_21.zip\n",
      "[2018-05-12 23:23:48.907673] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_21.zip\n",
      "[2018-05-12 23:23:52.358176] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-12 23:23:52.362662] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:23:52.515785] SGDOptimizer > Initial loss [73.79492950439453]\n",
      "\u001b[2K[2018-05-12 23:25:53.431981] SGDOptimizer > Curr loss: 2.662905E+02, n_evals: 999, Avg. time per updt: 0.119619\n",
      "[2018-05-12 23:25:53.467966] SGDOptimizer > Done training. New loss [154.799515] iter: [999]\n",
      "[2018-05-12 23:25:53.469714] apply_controller > Starting run\n",
      "[2018-05-12 23:25:53.471182] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:25:53.665107] apply_controller > Done. Stopping robot. Value of run [29.876888]\n",
      "[2018-05-12 23:25:53.666470] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:25:53.667834] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:25:53.672485] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-12 23:25:53.673751] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:25:53.688199] target_dyn_opt > Initial loss [-7.573213023313697]\n",
      "\u001b[2K[2018-05-12 23:26:13.747224] target_dyn_opt > Curr loss: -1.192798E+01 [1217: -1.301916E+01], n_evals: 1999, Avg. time per updt: 0.008386\n",
      "[2018-05-12 23:26:13.762711] target_dyn_opt > Done training. New loss [-12.530541] iter: [2000]\n",
      "[2018-05-12 23:26:13.765523] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:26:13.768496] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_22.zip\n",
      "[2018-05-12 23:26:14.732529] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_22.zip\n",
      "[2018-05-12 23:26:14.770153] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_22.zip\n",
      "[2018-05-12 23:26:17.816761] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-12 23:26:17.821637] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:26:18.011539] SGDOptimizer > Initial loss [239.9180450439453]\n",
      "\u001b[2K[2018-05-12 23:28:23.600089] SGDOptimizer > Curr loss: 1.049999E+02, n_evals: 999, Avg. time per updt: 0.124321\n",
      "[2018-05-12 23:28:23.640157] SGDOptimizer > Done training. New loss [99.899117] iter: [999]\n",
      "[2018-05-12 23:28:23.641906] apply_controller > Starting run\n",
      "[2018-05-12 23:28:23.643563] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:28:23.895804] apply_controller > Done. Stopping robot. Value of run [28.953686]\n",
      "[2018-05-12 23:28:23.897092] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:28:23.898261] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:28:23.902340] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-12 23:28:23.903952] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:28:23.920541] target_dyn_opt > Initial loss [-7.275663027646898]\n",
      "\u001b[2K[2018-05-12 23:28:43.570088] target_dyn_opt > Curr loss: -1.275662E+01 [1836: -1.316406E+01], n_evals: 1999, Avg. time per updt: 0.008307\n",
      "[2018-05-12 23:28:43.586605] target_dyn_opt > Done training. New loss [-12.649531] iter: [2000]\n",
      "[2018-05-12 23:28:43.589403] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:28:43.590966] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_23.zip\n",
      "[2018-05-12 23:28:44.581908] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_23.zip\n",
      "[2018-05-12 23:28:44.619717] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_23.zip\n",
      "[2018-05-12 23:28:48.112737] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-12 23:28:48.117450] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:28:48.288201] SGDOptimizer > Initial loss [90.03854370117188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 23:30:53.565697] SGDOptimizer > Curr loss: 9.519038E+01, n_evals: 999, Avg. time per updt: 0.123999\n",
      "[2018-05-12 23:30:53.604947] SGDOptimizer > Done training. New loss [117.856613] iter: [999]\n",
      "[2018-05-12 23:30:53.606570] apply_controller > Starting run\n",
      "[2018-05-12 23:30:53.608567] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:30:53.798344] apply_controller > Done. Stopping robot. Value of run [29.897913]\n",
      "[2018-05-12 23:30:53.799702] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:30:53.801033] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:30:53.805966] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-12 23:30:53.807345] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:30:53.823760] target_dyn_opt > Initial loss [-9.387204790115357]\n",
      "\u001b[2K[2018-05-12 23:31:13.036648] target_dyn_opt > Curr loss: -1.269185E+01 [1375: -1.332868E+01], n_evals: 1999, Avg. time per updt: 0.008134\n",
      "[2018-05-12 23:31:13.051518] target_dyn_opt > Done training. New loss [-12.661619] iter: [2000]\n",
      "[2018-05-12 23:31:13.054439] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:31:13.055860] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_24.zip\n",
      "[2018-05-12 23:31:14.099879] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_24.zip\n",
      "[2018-05-12 23:31:14.140454] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_24.zip\n",
      "[2018-05-12 23:31:17.635636] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-12 23:31:17.640177] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:31:17.799989] SGDOptimizer > Initial loss [108.65565490722656]\n",
      "\u001b[2K[2018-05-12 23:33:23.136944] SGDOptimizer > Curr loss: 9.274043E+01, n_evals: 999, Avg. time per updt: 0.124065\n",
      "[2018-05-12 23:33:23.175929] SGDOptimizer > Done training. New loss [84.852882] iter: [999]\n",
      "[2018-05-12 23:33:23.177880] apply_controller > Starting run\n",
      "[2018-05-12 23:33:23.179396] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:33:23.359138] apply_controller > Done. Stopping robot. Value of run [29.698536]\n",
      "[2018-05-12 23:33:23.360359] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:33:23.361657] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:33:23.365364] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-12 23:33:23.366788] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:33:23.381410] target_dyn_opt > Initial loss [-8.33017053915588]\n",
      "\u001b[2K[2018-05-12 23:33:42.998924] target_dyn_opt > Curr loss: -1.327119E+01 [1335: -1.352183E+01], n_evals: 1999, Avg. time per updt: 0.008317\n",
      "[2018-05-12 23:33:43.013599] target_dyn_opt > Done training. New loss [-12.928748] iter: [2000]\n",
      "[2018-05-12 23:33:43.016414] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:33:43.017955] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_25.zip\n",
      "[2018-05-12 23:33:44.098626] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_25.zip\n",
      "[2018-05-12 23:33:44.137601] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_25.zip\n",
      "[2018-05-12 23:33:47.631510] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-12 23:33:47.636311] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:33:47.793114] SGDOptimizer > Initial loss [119.49091339111328]\n",
      "\u001b[2K[2018-05-12 23:35:51.423846] SGDOptimizer > Curr loss: 9.567482E+01, n_evals: 999, Avg. time per updt: 0.122344\n",
      "[2018-05-12 23:35:51.462304] SGDOptimizer > Done training. New loss [82.185951] iter: [999]\n",
      "[2018-05-12 23:35:51.464095] apply_controller > Starting run\n",
      "[2018-05-12 23:35:51.465329] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:35:51.675041] apply_controller > Done. Stopping robot. Value of run [27.419346]\n",
      "[2018-05-12 23:35:51.676471] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:35:51.677818] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:35:51.681929] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-12 23:35:51.683460] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:35:51.698009] target_dyn_opt > Initial loss [-1.132159356565463]\n",
      "\u001b[2K[2018-05-12 23:36:11.257728] target_dyn_opt > Curr loss: -1.288078E+01 [1362: -1.364202E+01], n_evals: 1999, Avg. time per updt: 0.008261\n",
      "[2018-05-12 23:36:11.274240] target_dyn_opt > Done training. New loss [-13.124650] iter: [2000]\n",
      "[2018-05-12 23:36:11.277029] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:36:11.278534] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_26.zip\n",
      "[2018-05-12 23:36:12.406886] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_26.zip\n",
      "[2018-05-12 23:36:12.445117] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_26.zip\n",
      "[2018-05-12 23:36:15.893458] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-12 23:36:15.898309] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:36:16.063633] SGDOptimizer > Initial loss [110.54337310791016]\n",
      "\u001b[2K[2018-05-12 23:39:01.471188] SGDOptimizer > Curr loss: 8.931716E+01, n_evals: 999, Avg. time per updt: 0.164162\n",
      "[2018-05-12 23:39:01.512768] SGDOptimizer > Done training. New loss [89.055153] iter: [999]\n",
      "[2018-05-12 23:39:01.519900] apply_controller > Starting run\n",
      "[2018-05-12 23:39:01.521148] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:39:01.725442] apply_controller > Done. Stopping robot. Value of run [29.896011]\n",
      "[2018-05-12 23:39:01.726769] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:39:01.728080] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:39:01.750318] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-12 23:39:01.751706] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:39:01.814370] target_dyn_opt > Initial loss [-6.367380470257674]\n",
      "\u001b[2K[2018-05-12 23:39:21.964614] target_dyn_opt > Curr loss: -1.319154E+01 [1973: -1.383770E+01], n_evals: 1999, Avg. time per updt: 0.008509\n",
      "[2018-05-12 23:39:21.982092] target_dyn_opt > Done training. New loss [-13.378843] iter: [2000]\n",
      "[2018-05-12 23:39:21.997256] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:39:22.000518] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_27.zip\n",
      "[2018-05-12 23:39:23.207255] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_27.zip\n",
      "[2018-05-12 23:39:23.246718] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_27.zip\n",
      "[2018-05-12 23:39:26.929638] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-12 23:39:26.952828] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:39:27.171050] SGDOptimizer > Initial loss [104.3853759765625]\n",
      "\u001b[2K[2018-05-12 23:41:35.492490] SGDOptimizer > Curr loss: 7.050991E+01, n_evals: 999, Avg. time per updt: 0.126914\n",
      "[2018-05-12 23:41:35.538298] SGDOptimizer > Done training. New loss [79.125313] iter: [999]\n",
      "[2018-05-12 23:41:35.541766] apply_controller > Starting run\n",
      "[2018-05-12 23:41:35.543071] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:41:35.769591] apply_controller > Done. Stopping robot. Value of run [29.869215]\n",
      "[2018-05-12 23:41:35.771172] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:41:35.772960] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:41:35.779253] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-12 23:41:35.781116] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:41:35.818502] target_dyn_opt > Initial loss [-8.811531953168114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[2018-05-12 23:41:55.165306] target_dyn_opt > Curr loss: -1.334860E+01 [1236: -1.393041E+01], n_evals: 1999, Avg. time per updt: 0.008191\n",
      "[2018-05-12 23:41:55.179270] target_dyn_opt > Done training. New loss [-13.495827] iter: [2000]\n",
      "[2018-05-12 23:41:55.181875] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:41:55.184209] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_28.zip\n",
      "[2018-05-12 23:41:56.428823] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_28.zip\n",
      "[2018-05-12 23:41:56.467274] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_28.zip\n",
      "[2018-05-12 23:41:59.976262] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-12 23:41:59.981424] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:42:00.143362] SGDOptimizer > Initial loss [64.0837173461914]\n",
      "\u001b[2K[2018-05-12 23:44:02.166395] SGDOptimizer > Curr loss: 9.318285E+01, n_evals: 999, Avg. time per updt: 0.120749\n",
      "[2018-05-12 23:44:02.203236] SGDOptimizer > Done training. New loss [87.441422] iter: [999]\n",
      "[2018-05-12 23:44:02.204876] apply_controller > Starting run\n",
      "[2018-05-12 23:44:02.206275] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:44:02.406461] apply_controller > Done. Stopping robot. Value of run [29.231693]\n",
      "[2018-05-12 23:44:02.407963] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:44:02.409231] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:44:02.413184] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-12 23:44:02.414539] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:44:02.428481] target_dyn_opt > Initial loss [-5.092661233263454]\n",
      "\u001b[2K[2018-05-12 23:44:22.459592] target_dyn_opt > Curr loss: -1.355164E+01 [1946: -1.407375E+01], n_evals: 1999, Avg. time per updt: 0.008259\n",
      "[2018-05-12 23:44:22.479458] target_dyn_opt > Done training. New loss [-13.451843] iter: [2000]\n",
      "[2018-05-12 23:44:22.482547] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:44:22.488080] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_29.zip\n",
      "[2018-05-12 23:44:23.757382] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_29.zip\n",
      "[2018-05-12 23:44:23.796659] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_29.zip\n",
      "[2018-05-12 23:44:27.329558] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-12 23:44:27.334754] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-12 23:44:27.548241] SGDOptimizer > Initial loss [90.60897064208984]\n",
      "\u001b[2K[2018-05-12 23:46:34.427872] SGDOptimizer > Curr loss: 1.070929E+02, n_evals: 999, Avg. time per updt: 0.125595\n",
      "[2018-05-12 23:46:34.467249] SGDOptimizer > Done training. New loss [89.813080] iter: [999]\n",
      "[2018-05-12 23:46:34.472289] apply_controller > Starting run\n",
      "[2018-05-12 23:46:34.474824] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-12 23:46:34.657095] apply_controller > Done. Stopping robot. Value of run [29.994507]\n",
      "[2018-05-12 23:46:34.658716] target_2x_mass > Stopping robot\n",
      "[2018-05-12 23:46:34.660091] train_dynamics > Training dynamics model\n",
      "[2018-05-12 23:46:34.664332] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-12 23:46:34.665632] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-12 23:46:34.680355] target_dyn_opt > Initial loss [4.67467450777336]\n",
      "\u001b[2K[2018-05-12 23:46:53.462601] target_dyn_opt > Curr loss: -1.397523E+01 [1453: -1.430389E+01], n_evals: 1999, Avg. time per updt: 0.007908\n",
      "[2018-05-12 23:46:53.476676] target_dyn_opt > Done training. New loss [-13.297288] iter: [2000]\n",
      "[2018-05-12 23:46:53.479655] train_dynamics > Done training dynamics model\n",
      "[2018-05-12 23:46:53.481305] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/experience_30.zip\n",
      "[2018-05-12 23:46:54.794787] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/policy_30.zip\n",
      "[2018-05-12 23:46:54.832878] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_006_il_klpq_from_source/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 6 learn starting from source, using klpq imitation loss\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_006_il_klpq_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[0.0, 1.0], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:19:30.180849] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 00:19:30.202610] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 00:19:30.232043] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 00:19:30.245297] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 00:19:30.251267] Experience > Initialising new experience dataset\n",
      "[2018-05-13 00:19:30.252556] Executing uniformly-random controls\n",
      "[2018-05-13 00:19:30.254198] apply_controller > Starting run\n",
      "[2018-05-13 00:19:30.255651] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:19:30.415796] apply_controller > Done. Stopping robot. Value of run [29.996758]\n",
      "[2018-05-13 00:19:30.417256] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:19:30.418614] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:19:30.421288] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-13 00:19:30.422967] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1690>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1690>})\n",
      "[2018-05-13 00:19:30.452175] target_dyn > Initialising loss function\n",
      "[2018-05-13 00:19:30.597555] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-13 00:19:30.869261] target_dyn_opt > No gradient clipping\n",
      "[2018-05-13 00:19:30.870487] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-13 00:19:30.930042] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-13 00:19:31.776468] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-13 00:19:37.924629] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:19:37.934977] target_dyn_opt > Initial loss [1668.0961692684855]\n",
      "\u001b[2K[2018-05-13 00:19:47.396694] target_dyn_opt > Curr loss: 5.157375E+01 [1939: 4.725612E+01], n_evals: 1999, Avg. time per updt: 0.003213\n",
      "[2018-05-13 00:19:47.402573] target_dyn_opt > Done training. New loss [47.956364] iter: [2000]\n",
      "[2018-05-13 00:19:47.635576] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:19:47.674795] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1710>, 'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1710>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7fe7224e1710>})\n",
      "[2018-05-13 00:19:47.841377] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 00:19:47.842794] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 00:19:47.933928] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 00:19:47.935398] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 00:19:48.511287] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 00:19:48.512724] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 00:19:48.599842] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 00:19:48.601102] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 00:19:55.685464] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-13 00:19:56.894242] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-13 00:19:56.903864] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-13 00:19:56.933892] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-13 00:19:59.835165] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-13 00:20:18.459015] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_0.zip\n",
      "[2018-05-13 00:20:18.527268] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_0.zip\n",
      "[2018-05-13 00:20:18.600983] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_0.zip\n",
      "[2018-05-13 00:20:18.695238] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-13 00:20:18.697035] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-13 00:20:18.701958] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:20:18.851509] SGDOptimizer > Initial loss [9.6787748336792]\n",
      "\u001b[2K[2018-05-13 00:21:56.665695] SGDOptimizer > Curr loss: 1.792241E+00, n_evals: 999, Avg. time per updt: 0.096513\n",
      "[2018-05-13 00:21:56.696175] SGDOptimizer > Done training. New loss [12.804716] iter: [999]\n",
      "[2018-05-13 00:21:56.698206] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-13 00:21:56.781455] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-13 00:21:56.926252] NNPolicy > Done compiling\n",
      "[2018-05-13 00:21:56.927736] apply_controller > Starting run\n",
      "[2018-05-13 00:21:56.929908] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:21:57.103197] apply_controller > Done. Stopping robot. Value of run [28.967953]\n",
      "[2018-05-13 00:21:57.104582] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:21:57.105897] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:21:57.108134] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-13 00:21:57.109783] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:21:57.119110] target_dyn_opt > Initial loss [137.52225553021054]\n",
      "\u001b[2K[2018-05-13 00:22:09.738147] target_dyn_opt > Curr loss: 2.104207E+01 [1969: 1.966144E+01], n_evals: 1999, Avg. time per updt: 0.004783\n",
      "[2018-05-13 00:22:09.748039] target_dyn_opt > Done training. New loss [20.975352] iter: [2000]\n",
      "[2018-05-13 00:22:09.750711] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:22:09.752047] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_1.zip\n",
      "[2018-05-13 00:22:09.864166] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_1.zip\n",
      "[2018-05-13 00:22:09.940657] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_1.zip\n",
      "[2018-05-13 00:22:11.583432] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-13 00:22:11.588906] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:22:11.708453] SGDOptimizer > Initial loss [7.058071613311768]\n",
      "\u001b[2K[2018-05-13 00:23:49.488287] SGDOptimizer > Curr loss: 2.422502E+00, n_evals: 999, Avg. time per updt: 0.096492\n",
      "[2018-05-13 00:23:49.515315] SGDOptimizer > Done training. New loss [2.364366] iter: [999]\n",
      "[2018-05-13 00:23:49.517283] apply_controller > Starting run\n",
      "[2018-05-13 00:23:49.518119] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:23:49.711643] apply_controller > Done. Stopping robot. Value of run [27.721008]\n",
      "[2018-05-13 00:23:49.712982] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:23:49.714233] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:23:49.716787] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-13 00:23:49.718386] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:23:49.731210] target_dyn_opt > Initial loss [32.66049417701681]\n",
      "\u001b[2K[2018-05-13 00:24:06.375812] target_dyn_opt > Curr loss: 1.112762E+01 [1992: 1.030857E+01], n_evals: 1999, Avg. time per updt: 0.006732\n",
      "[2018-05-13 00:24:06.389214] target_dyn_opt > Done training. New loss [11.045428] iter: [2000]\n",
      "[2018-05-13 00:24:06.392285] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:24:06.394253] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_2.zip\n",
      "[2018-05-13 00:24:06.550975] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_2.zip\n",
      "[2018-05-13 00:24:06.628600] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_2.zip\n",
      "[2018-05-13 00:24:08.192642] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-13 00:24:08.198413] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:24:08.332710] SGDOptimizer > Initial loss [4.49772834777832]\n",
      "\u001b[2K[2018-05-13 00:25:46.927381] SGDOptimizer > Curr loss: 1.620469E+00, n_evals: 999, Avg. time per updt: 0.097292\n",
      "[2018-05-13 00:25:46.954137] SGDOptimizer > Done training. New loss [1.573426] iter: [999]\n",
      "[2018-05-13 00:25:46.956052] apply_controller > Starting run\n",
      "[2018-05-13 00:25:46.957418] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:25:47.135800] apply_controller > Done. Stopping robot. Value of run [28.030046]\n",
      "[2018-05-13 00:25:47.137056] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:25:47.138637] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:25:47.141278] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-13 00:25:47.142774] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:25:47.157152] target_dyn_opt > Initial loss [11.304829462929147]\n",
      "\u001b[2K[2018-05-13 00:26:05.272477] target_dyn_opt > Curr loss: 4.893393E+00 [1861: 4.187703E+00], n_evals: 1999, Avg. time per updt: 0.007478\n",
      "[2018-05-13 00:26:05.286336] target_dyn_opt > Done training. New loss [4.766901] iter: [2000]\n",
      "[2018-05-13 00:26:05.288989] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:26:05.290398] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_3.zip\n",
      "[2018-05-13 00:26:05.488346] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_3.zip\n",
      "[2018-05-13 00:26:05.563007] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_3.zip\n",
      "[2018-05-13 00:26:07.131704] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-13 00:26:07.137106] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:26:07.262719] SGDOptimizer > Initial loss [1.5623412132263184]\n",
      "\u001b[2K[2018-05-13 00:27:46.609819] SGDOptimizer > Curr loss: 1.574405E+00, n_evals: 999, Avg. time per updt: 0.098065\n",
      "[2018-05-13 00:27:46.639287] SGDOptimizer > Done training. New loss [1.583153] iter: [999]\n",
      "[2018-05-13 00:27:46.640988] apply_controller > Starting run\n",
      "[2018-05-13 00:27:46.642302] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:27:46.828995] apply_controller > Done. Stopping robot. Value of run [27.449129]\n",
      "[2018-05-13 00:27:46.830204] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:27:46.831715] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:27:46.834313] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-13 00:27:46.835664] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:27:46.849554] target_dyn_opt > Initial loss [6.979625049441378]\n",
      "\u001b[2K[2018-05-13 00:28:04.793599] target_dyn_opt > Curr loss: 1.448436E+00 [1702: 6.259268E-01], n_evals: 1999, Avg. time per updt: 0.007421\n",
      "[2018-05-13 00:28:04.808712] target_dyn_opt > Done training. New loss [1.608776] iter: [2000]\n",
      "[2018-05-13 00:28:04.811366] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:28:04.812929] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_4.zip\n",
      "[2018-05-13 00:28:05.053945] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_4.zip\n",
      "[2018-05-13 00:28:05.125814] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_4.zip\n",
      "[2018-05-13 00:28:06.707596] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-13 00:28:06.712882] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:28:06.844210] SGDOptimizer > Initial loss [1.823083758354187]\n",
      "\u001b[2K[2018-05-13 00:29:45.518144] SGDOptimizer > Curr loss: 1.621925E+00, n_evals: 999, Avg. time per updt: 0.097393\n",
      "[2018-05-13 00:29:45.542803] SGDOptimizer > Done training. New loss [1.670343] iter: [999]\n",
      "[2018-05-13 00:29:45.544575] apply_controller > Starting run\n",
      "[2018-05-13 00:29:45.545778] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:29:45.746710] apply_controller > Done. Stopping robot. Value of run [28.572744]\n",
      "[2018-05-13 00:29:45.748210] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:29:45.749604] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:29:45.752397] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-13 00:29:45.753696] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:29:45.766667] target_dyn_opt > Initial loss [2.5094335949819158]\n",
      "\u001b[2K[2018-05-13 00:30:03.746023] target_dyn_opt > Curr loss: -1.340749E+00 [1956: -1.751019E+00], n_evals: 1999, Avg. time per updt: 0.007425\n",
      "[2018-05-13 00:30:03.760820] target_dyn_opt > Done training. New loss [-1.033177] iter: [2000]\n",
      "[2018-05-13 00:30:03.763541] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:30:03.764884] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_5.zip\n",
      "[2018-05-13 00:30:04.041631] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_5.zip\n",
      "[2018-05-13 00:30:04.110480] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_5.zip\n",
      "[2018-05-13 00:30:05.679123] ==== Iteration [6], experience: [180 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:30:05.683855] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:30:05.802176] SGDOptimizer > Initial loss [1.6083914041519165]\n",
      "\u001b[2K[2018-05-13 00:31:42.755441] SGDOptimizer > Curr loss: 2.648129E+00, n_evals: 999, Avg. time per updt: 0.095675\n",
      "[2018-05-13 00:31:42.784443] SGDOptimizer > Done training. New loss [2.694020] iter: [999]\n",
      "[2018-05-13 00:31:42.786105] apply_controller > Starting run\n",
      "[2018-05-13 00:31:42.787425] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:31:42.970216] apply_controller > Done. Stopping robot. Value of run [29.957670]\n",
      "[2018-05-13 00:31:42.971713] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:31:42.972993] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:31:42.975892] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-13 00:31:42.977432] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:31:42.992257] target_dyn_opt > Initial loss [-1.689326590838328]\n",
      "\u001b[2K[2018-05-13 00:32:00.260765] target_dyn_opt > Curr loss: -3.216319E+00 [1703: -3.456996E+00], n_evals: 1999, Avg. time per updt: 0.007156\n",
      "[2018-05-13 00:32:00.273909] target_dyn_opt > Done training. New loss [-2.804201] iter: [2000]\n",
      "[2018-05-13 00:32:00.276366] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:32:00.277907] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_6.zip\n",
      "[2018-05-13 00:32:00.595592] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_6.zip\n",
      "[2018-05-13 00:32:00.658344] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_6.zip\n",
      "[2018-05-13 00:32:02.211333] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-13 00:32:02.216179] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:32:02.335212] SGDOptimizer > Initial loss [2.74564266204834]\n",
      "\u001b[2K[2018-05-13 00:33:37.736316] SGDOptimizer > Curr loss: 2.807437E+00, n_evals: 999, Avg. time per updt: 0.094078\n",
      "[2018-05-13 00:33:37.759728] SGDOptimizer > Done training. New loss [2.668743] iter: [999]\n",
      "[2018-05-13 00:33:37.761338] apply_controller > Starting run\n",
      "[2018-05-13 00:33:37.762781] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:33:37.950959] apply_controller > Done. Stopping robot. Value of run [29.940977]\n",
      "[2018-05-13 00:33:37.952294] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:33:37.953553] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:33:37.956043] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-13 00:33:37.957485] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:33:37.971690] target_dyn_opt > Initial loss [-2.28966991506529]\n",
      "\u001b[2K[2018-05-13 00:33:55.979404] target_dyn_opt > Curr loss: -3.914676E+00 [1952: -4.624666E+00], n_evals: 1999, Avg. time per updt: 0.007467\n",
      "[2018-05-13 00:33:55.994124] target_dyn_opt > Done training. New loss [-4.347691] iter: [2000]\n",
      "[2018-05-13 00:33:55.996716] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:33:55.998100] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_7.zip\n",
      "[2018-05-13 00:33:56.350901] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_7.zip\n",
      "[2018-05-13 00:33:56.410452] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_7.zip\n",
      "[2018-05-13 00:33:57.980895] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-13 00:33:57.986048] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:33:58.123167] SGDOptimizer > Initial loss [2.625319242477417]\n",
      "\u001b[2K[2018-05-13 00:35:33.286428] SGDOptimizer > Curr loss: 1.712246E+00, n_evals: 999, Avg. time per updt: 0.093896\n",
      "[2018-05-13 00:35:33.311805] SGDOptimizer > Done training. New loss [1.777866] iter: [999]\n",
      "[2018-05-13 00:35:33.313671] apply_controller > Starting run\n",
      "[2018-05-13 00:35:33.316985] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:35:33.490050] apply_controller > Done. Stopping robot. Value of run [29.655203]\n",
      "[2018-05-13 00:35:33.491390] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:35:33.492625] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:35:33.494761] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-13 00:35:33.495601] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:35:33.509677] target_dyn_opt > Initial loss [-3.495552849099468]\n",
      "\u001b[2K[2018-05-13 00:35:51.198769] target_dyn_opt > Curr loss: -5.102539E+00 [1673: -5.672503E+00], n_evals: 1999, Avg. time per updt: 0.007324\n",
      "[2018-05-13 00:35:51.211891] target_dyn_opt > Done training. New loss [-5.147041] iter: [2000]\n",
      "[2018-05-13 00:35:51.214757] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:35:51.216249] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_8.zip\n",
      "[2018-05-13 00:35:51.607769] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_8.zip\n",
      "[2018-05-13 00:35:51.671333] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_8.zip\n",
      "[2018-05-13 00:35:53.237589] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-13 00:35:53.242038] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:35:53.360136] SGDOptimizer > Initial loss [2.359952211380005]\n",
      "\u001b[2K[2018-05-13 00:37:30.941414] SGDOptimizer > Curr loss: 2.769513E+00, n_evals: 999, Avg. time per updt: 0.096254\n",
      "[2018-05-13 00:37:30.967063] SGDOptimizer > Done training. New loss [2.640408] iter: [999]\n",
      "[2018-05-13 00:37:30.968987] apply_controller > Starting run\n",
      "[2018-05-13 00:37:30.969927] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:37:31.155876] apply_controller > Done. Stopping robot. Value of run [29.391138]\n",
      "[2018-05-13 00:37:31.157110] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:37:31.158383] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:37:31.161202] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-13 00:37:31.162557] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:37:31.177935] target_dyn_opt > Initial loss [-4.897630899656436]\n",
      "\u001b[2K[2018-05-13 00:37:48.634569] target_dyn_opt > Curr loss: -6.034478E+00 [1992: -6.642722E+00], n_evals: 1999, Avg. time per updt: 0.007245\n",
      "[2018-05-13 00:37:48.649159] target_dyn_opt > Done training. New loss [-6.150313] iter: [2000]\n",
      "[2018-05-13 00:37:48.651854] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:37:48.653639] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_9.zip\n",
      "[2018-05-13 00:37:49.090896] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_9.zip\n",
      "[2018-05-13 00:37:49.151833] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_9.zip\n",
      "[2018-05-13 00:37:50.711060] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-13 00:37:50.715824] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:37:50.847538] SGDOptimizer > Initial loss [2.641284704208374]\n",
      "\u001b[2K[2018-05-13 00:39:26.197080] SGDOptimizer > Curr loss: 2.480869E+00, n_evals: 999, Avg. time per updt: 0.094061\n",
      "[2018-05-13 00:39:26.220323] SGDOptimizer > Done training. New loss [2.413901] iter: [999]\n",
      "[2018-05-13 00:39:26.222297] apply_controller > Starting run\n",
      "[2018-05-13 00:39:26.223342] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:39:26.400819] apply_controller > Done. Stopping robot. Value of run [26.856541]\n",
      "[2018-05-13 00:39:26.402146] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:39:26.403473] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:39:26.406914] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-13 00:39:26.408273] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:39:26.420667] target_dyn_opt > Initial loss [-4.522779218712384]\n",
      "\u001b[2K[2018-05-13 00:39:43.527187] target_dyn_opt > Curr loss: -7.090064E+00 [1527: -7.330358E+00], n_evals: 1999, Avg. time per updt: 0.007080\n",
      "[2018-05-13 00:39:43.541082] target_dyn_opt > Done training. New loss [-6.791544] iter: [2000]\n",
      "[2018-05-13 00:39:43.543784] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:39:43.545193] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_10.zip\n",
      "[2018-05-13 00:39:44.022469] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_10.zip\n",
      "[2018-05-13 00:39:44.083364] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_10.zip\n",
      "[2018-05-13 00:39:45.640216] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-13 00:39:45.645298] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:39:45.760290] SGDOptimizer > Initial loss [2.922274112701416]\n",
      "\u001b[2K[2018-05-13 00:41:20.574107] SGDOptimizer > Curr loss: 2.159552E+00, n_evals: 999, Avg. time per updt: 0.093519\n",
      "[2018-05-13 00:41:20.600043] SGDOptimizer > Done training. New loss [2.144335] iter: [999]\n",
      "[2018-05-13 00:41:20.601754] apply_controller > Starting run\n",
      "[2018-05-13 00:41:20.603061] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:41:20.787544] apply_controller > Done. Stopping robot. Value of run [29.708805]\n",
      "[2018-05-13 00:41:20.788896] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:41:20.790095] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:41:20.792916] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-13 00:41:20.794387] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:41:20.810219] target_dyn_opt > Initial loss [-6.220866101708306]\n",
      "\u001b[2K[2018-05-13 00:41:38.966047] target_dyn_opt > Curr loss: -7.559171E+00 [1977: -7.899380E+00], n_evals: 1999, Avg. time per updt: 0.007548\n",
      "[2018-05-13 00:41:38.981273] target_dyn_opt > Done training. New loss [-7.392804] iter: [2000]\n",
      "[2018-05-13 00:41:38.984441] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:41:38.985970] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_11.zip\n",
      "[2018-05-13 00:41:39.558471] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_11.zip\n",
      "[2018-05-13 00:41:39.621296] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_11.zip\n",
      "[2018-05-13 00:41:41.250752] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-13 00:41:41.255386] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:41:41.387920] SGDOptimizer > Initial loss [2.275750160217285]\n",
      "\u001b[2K[2018-05-13 00:43:18.916357] SGDOptimizer > Curr loss: 1.751811E+00, n_evals: 999, Avg. time per updt: 0.096209\n",
      "[2018-05-13 00:43:18.942163] SGDOptimizer > Done training. New loss [1.994902] iter: [999]\n",
      "[2018-05-13 00:43:18.943941] apply_controller > Starting run\n",
      "[2018-05-13 00:43:18.945248] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:43:19.127724] apply_controller > Done. Stopping robot. Value of run [29.966524]\n",
      "[2018-05-13 00:43:19.128938] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:43:19.130245] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:43:19.133372] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-13 00:43:19.134598] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:43:19.148099] target_dyn_opt > Initial loss [-6.949987601716101]\n",
      "\u001b[2K[2018-05-13 00:43:36.851090] target_dyn_opt > Curr loss: -8.202743E+00 [1880: -8.400313E+00], n_evals: 1999, Avg. time per updt: 0.007388\n",
      "[2018-05-13 00:43:36.863476] target_dyn_opt > Done training. New loss [-8.048818] iter: [2000]\n",
      "[2018-05-13 00:43:36.866019] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:43:36.867730] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_12.zip\n",
      "[2018-05-13 00:43:37.426860] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_12.zip\n",
      "[2018-05-13 00:43:37.487466] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_12.zip\n",
      "[2018-05-13 00:43:39.053963] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-13 00:43:39.058668] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:43:39.186496] SGDOptimizer > Initial loss [1.791322946548462]\n",
      "\u001b[2K[2018-05-13 00:45:17.335454] SGDOptimizer > Curr loss: 2.646130E+00, n_evals: 999, Avg. time per updt: 0.096840\n",
      "[2018-05-13 00:45:17.365860] SGDOptimizer > Done training. New loss [3.053359] iter: [999]\n",
      "[2018-05-13 00:45:17.367709] apply_controller > Starting run\n",
      "[2018-05-13 00:45:17.368492] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:45:17.553701] apply_controller > Done. Stopping robot. Value of run [28.846540]\n",
      "[2018-05-13 00:45:17.554930] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:45:17.556239] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:45:17.559466] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-13 00:45:17.561267] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:45:17.574794] target_dyn_opt > Initial loss [-7.58064195928462]\n",
      "\u001b[2K[2018-05-13 00:45:35.869795] target_dyn_opt > Curr loss: -8.316954E+00 [1680: -9.076531E+00], n_evals: 1999, Avg. time per updt: 0.007628\n",
      "[2018-05-13 00:45:35.884498] target_dyn_opt > Done training. New loss [-8.610087] iter: [2000]\n",
      "[2018-05-13 00:45:35.887363] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:45:35.890644] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_13.zip\n",
      "[2018-05-13 00:45:36.508741] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_13.zip\n",
      "[2018-05-13 00:45:36.575769] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_13.zip\n",
      "[2018-05-13 00:45:39.432182] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-13 00:45:39.436324] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:45:39.586070] SGDOptimizer > Initial loss [3.1287617683410645]\n",
      "\u001b[2K[2018-05-13 00:47:22.413804] SGDOptimizer > Curr loss: 2.337498E+00, n_evals: 999, Avg. time per updt: 0.101515\n",
      "[2018-05-13 00:47:22.440616] SGDOptimizer > Done training. New loss [2.402007] iter: [999]\n",
      "[2018-05-13 00:47:22.442766] apply_controller > Starting run\n",
      "[2018-05-13 00:47:22.444105] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:47:22.618336] apply_controller > Done. Stopping robot. Value of run [29.619572]\n",
      "[2018-05-13 00:47:22.619571] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:47:22.620783] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:47:22.624766] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-13 00:47:22.626345] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:47:22.639432] target_dyn_opt > Initial loss [-8.04329657981108]\n",
      "\u001b[2K[2018-05-13 00:47:41.104282] target_dyn_opt > Curr loss: -9.051158E+00 [1821: -9.388475E+00], n_evals: 1999, Avg. time per updt: 0.007678\n",
      "[2018-05-13 00:47:41.119479] target_dyn_opt > Done training. New loss [-8.715290] iter: [2000]\n",
      "[2018-05-13 00:47:41.122142] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:47:41.123772] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_14.zip\n",
      "[2018-05-13 00:47:41.772537] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_14.zip\n",
      "[2018-05-13 00:47:41.836491] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:47:43.413566] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-13 00:47:43.418573] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:47:43.561048] SGDOptimizer > Initial loss [2.1772866249084473]\n",
      "\u001b[2K[2018-05-13 00:49:24.399609] SGDOptimizer > Curr loss: 2.284377E+00, n_evals: 999, Avg. time per updt: 0.099508\n",
      "[2018-05-13 00:49:24.424572] SGDOptimizer > Done training. New loss [2.028311] iter: [999]\n",
      "[2018-05-13 00:49:24.426454] apply_controller > Starting run\n",
      "[2018-05-13 00:49:24.427769] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:49:24.607096] apply_controller > Done. Stopping robot. Value of run [29.970339]\n",
      "[2018-05-13 00:49:24.608581] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:49:24.610003] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:49:24.613409] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-13 00:49:24.615146] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:49:24.628249] target_dyn_opt > Initial loss [-6.706347629716941]\n",
      "\u001b[2K[2018-05-13 00:49:42.442987] target_dyn_opt > Curr loss: -9.242090E+00 [1675: -9.845241E+00], n_evals: 1999, Avg. time per updt: 0.007403\n",
      "[2018-05-13 00:49:42.455784] target_dyn_opt > Done training. New loss [-9.360852] iter: [2000]\n",
      "[2018-05-13 00:49:42.458469] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:49:42.460059] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_15.zip\n",
      "[2018-05-13 00:49:43.165255] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_15.zip\n",
      "[2018-05-13 00:49:43.228149] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_15.zip\n",
      "[2018-05-13 00:49:44.823873] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-13 00:49:44.829469] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:49:44.951184] SGDOptimizer > Initial loss [1.778171181678772]\n",
      "\u001b[2K[2018-05-13 00:51:27.117078] SGDOptimizer > Curr loss: 1.751494E+00, n_evals: 999, Avg. time per updt: 0.100838\n",
      "[2018-05-13 00:51:27.144240] SGDOptimizer > Done training. New loss [1.672554] iter: [999]\n",
      "[2018-05-13 00:51:27.145963] apply_controller > Starting run\n",
      "[2018-05-13 00:51:27.147222] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:51:27.328627] apply_controller > Done. Stopping robot. Value of run [29.169067]\n",
      "[2018-05-13 00:51:27.330153] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:51:27.331093] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:51:27.334945] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-13 00:51:27.336335] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:51:27.351414] target_dyn_opt > Initial loss [-8.51203563319742]\n",
      "\u001b[2K[2018-05-13 00:51:45.381800] target_dyn_opt > Curr loss: -9.506059E+00 [1966: -1.027979E+01], n_evals: 1999, Avg. time per updt: 0.007544\n",
      "[2018-05-13 00:51:45.396476] target_dyn_opt > Done training. New loss [-9.745215] iter: [2000]\n",
      "[2018-05-13 00:51:45.399227] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:51:45.400731] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_16.zip\n",
      "[2018-05-13 00:51:46.130329] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_16.zip\n",
      "[2018-05-13 00:51:46.192732] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_16.zip\n",
      "[2018-05-13 00:51:47.772633] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-13 00:51:47.777735] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:51:47.908011] SGDOptimizer > Initial loss [1.619802474975586]\n",
      "\u001b[2K[2018-05-13 00:53:31.827672] SGDOptimizer > Curr loss: 1.665674E+00, n_evals: 999, Avg. time per updt: 0.102593\n",
      "[2018-05-13 00:53:31.853056] SGDOptimizer > Done training. New loss [1.599903] iter: [999]\n",
      "[2018-05-13 00:53:31.854853] apply_controller > Starting run\n",
      "[2018-05-13 00:53:31.856126] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:53:32.096875] apply_controller > Done. Stopping robot. Value of run [25.271250]\n",
      "[2018-05-13 00:53:32.098277] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:53:32.100779] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:53:32.105294] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-13 00:53:32.106843] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:53:32.122084] target_dyn_opt > Initial loss [-8.991177130561907]\n",
      "\u001b[2K[2018-05-13 00:53:51.572449] target_dyn_opt > Curr loss: -1.012950E+01 [1671: -1.056963E+01], n_evals: 1999, Avg. time per updt: 0.008105\n",
      "[2018-05-13 00:53:51.585144] target_dyn_opt > Done training. New loss [-10.191939] iter: [2000]\n",
      "[2018-05-13 00:53:51.587824] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:53:51.589255] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_17.zip\n",
      "[2018-05-13 00:53:52.364736] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_17.zip\n",
      "[2018-05-13 00:53:52.426460] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_17.zip\n",
      "[2018-05-13 00:53:54.005679] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-13 00:53:54.010884] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:53:54.153053] SGDOptimizer > Initial loss [1.7834770679473877]\n",
      "\u001b[2K[2018-05-13 00:55:37.056362] SGDOptimizer > Curr loss: 1.804789E+00, n_evals: 999, Avg. time per updt: 0.101590\n",
      "[2018-05-13 00:55:37.083731] SGDOptimizer > Done training. New loss [2.185993] iter: [999]\n",
      "[2018-05-13 00:55:37.085386] apply_controller > Starting run\n",
      "[2018-05-13 00:55:37.086789] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:55:37.269184] apply_controller > Done. Stopping robot. Value of run [27.152229]\n",
      "[2018-05-13 00:55:37.270516] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:55:37.271801] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:55:37.275111] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-13 00:55:37.276782] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:55:37.289946] target_dyn_opt > Initial loss [-8.302087328638443]\n",
      "\u001b[2K[2018-05-13 00:55:55.310875] target_dyn_opt > Curr loss: -1.028955E+01 [1410: -1.088217E+01], n_evals: 1999, Avg. time per updt: 0.007503\n",
      "[2018-05-13 00:55:55.324343] target_dyn_opt > Done training. New loss [-10.181610] iter: [2000]\n",
      "[2018-05-13 00:55:55.326936] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:55:55.328575] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_18.zip\n",
      "[2018-05-13 00:55:56.198569] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_18.zip\n",
      "[2018-05-13 00:55:56.263302] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_18.zip\n",
      "[2018-05-13 00:55:57.940556] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-13 00:55:57.945880] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:55:58.086962] SGDOptimizer > Initial loss [2.633300542831421]\n",
      "\u001b[2K[2018-05-13 00:57:42.127611] SGDOptimizer > Curr loss: 1.725778E+00, n_evals: 999, Avg. time per updt: 0.102714\n",
      "[2018-05-13 00:57:42.157927] SGDOptimizer > Done training. New loss [1.667370] iter: [999]\n",
      "[2018-05-13 00:57:42.159742] apply_controller > Starting run\n",
      "[2018-05-13 00:57:42.161267] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:57:42.337791] apply_controller > Done. Stopping robot. Value of run [25.517134]\n",
      "[2018-05-13 00:57:42.339368] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:57:42.340664] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:57:42.344039] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 00:57:42.345425] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:57:42.360013] target_dyn_opt > Initial loss [-8.616694450121502]\n",
      "\u001b[2K[2018-05-13 00:58:01.400663] target_dyn_opt > Curr loss: -1.080140E+01 [903: -1.104414E+01], n_evals: 1999, Avg. time per updt: 0.007909\n",
      "[2018-05-13 00:58:01.413465] target_dyn_opt > Done training. New loss [-10.741351] iter: [2000]\n",
      "[2018-05-13 00:58:01.416055] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 00:58:01.417377] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_19.zip\n",
      "[2018-05-13 00:58:02.281756] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_19.zip\n",
      "[2018-05-13 00:58:02.344475] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_19.zip\n",
      "[2018-05-13 00:58:03.950455] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-13 00:58:03.955600] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 00:58:04.104029] SGDOptimizer > Initial loss [1.7032243013381958]\n",
      "\u001b[2K[2018-05-13 00:59:46.923245] SGDOptimizer > Curr loss: 1.608208E+00, n_evals: 999, Avg. time per updt: 0.101514\n",
      "[2018-05-13 00:59:46.950329] SGDOptimizer > Done training. New loss [1.431128] iter: [999]\n",
      "[2018-05-13 00:59:46.952208] apply_controller > Starting run\n",
      "[2018-05-13 00:59:46.953411] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 00:59:47.125728] apply_controller > Done. Stopping robot. Value of run [29.009747]\n",
      "[2018-05-13 00:59:47.127061] target_2x_mass > Stopping robot\n",
      "[2018-05-13 00:59:47.130379] train_dynamics > Training dynamics model\n",
      "[2018-05-13 00:59:47.134387] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-13 00:59:47.135791] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 00:59:47.150307] target_dyn_opt > Initial loss [-9.3551850788699]\n",
      "\u001b[2K[2018-05-13 01:00:05.182704] target_dyn_opt > Curr loss: -1.101057E+01 [1980: -1.147463E+01], n_evals: 1999, Avg. time per updt: 0.007508\n",
      "[2018-05-13 01:00:05.198996] target_dyn_opt > Done training. New loss [-10.577543] iter: [2000]\n",
      "[2018-05-13 01:00:05.201611] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:00:05.203080] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/experience_20.zip\n",
      "[2018-05-13 01:00:06.106963] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/policy_20.zip\n",
      "[2018-05-13 01:00:06.172715] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_007_taskplusil_klqp_from_scratch2/dynamics_20.zip\n",
      "[2018-05-13 01:00:09.029234] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-13 01:00:09.033755] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:00:09.185541] SGDOptimizer > Initial loss [1.5321753025054932]\n",
      "\u001b[2K[2018-05-13 01:00:50.707833] SGDOptimizer > Curr loss: 1.636103E+00, n_evals: 386, Avg. time per updt: 0.106144"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bcc07d50890d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolopt_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mminimize_cb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimize_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_iteration_cb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_iteration_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     debug_plot=2, render=False)\n\u001b[0m",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/shell/experiment_utils.pyc\u001b[0m in \u001b[0;36mrun_pilco_experiment\u001b[0;34m(env, cost, exp_setup, params, loss_kwargs, polopt_kwargs, extra_inps, step_cb, minimize_cb, learning_iteration_cb, max_dataset_size, render, debug_plot)\u001b[0m\n\u001b[1;32m    276\u001b[0m         polopt.minimize(*minimize_args,\n\u001b[1;32m    277\u001b[0m                         \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimize_cb_internal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                         return_best=return_best)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# 3. apply controller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/workspace/kusanagi/kusanagi/ghost/optimizers/sgd_optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;31m# evaluate current policy and update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;31m# the returned loss corresponds to the parameters BEFORE the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/juancamilog/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.14-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/theano/tensor/slinalg.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_structure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'upper_triangular'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             rval = scipy.linalg.solve_triangular(\n\u001b[0;32m--> 253\u001b[0;31m                 A, b, lower=False)\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/scipy/linalg/basic.pyc\u001b[0m in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, debug, check_finite)\u001b[0m\n\u001b[1;32m    334\u001b[0m                       'versions of SciPy.', DeprecationWarning)\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/scipy/_lib/_util.pyc\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masked arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juancamilog/miniconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \"\"\"\n\u001b[1;32m   1230\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m         raise ValueError(\n\u001b[1;32m   1233\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiment 7 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_007_taskplusil_klqp_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-4], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:00:56.715649] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 01:00:56.739815] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 01:00:56.768915] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 01:00:56.782095] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 01:00:56.787540] Experience > Initialising new experience dataset\n",
      "[2018-05-13 01:00:56.788790] Executing uniformly-random controls\n",
      "[2018-05-13 01:00:56.790099] apply_controller > Starting run\n",
      "[2018-05-13 01:00:56.791566] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:00:56.956335] apply_controller > Done. Stopping robot. Value of run [29.986658]\n",
      "[2018-05-13 01:00:56.957905] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:00:56.959419] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:00:56.962179] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-13 01:00:56.963801] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'target_dyn_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe6f4c06310>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': True, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe6f4c06310>})\n",
      "('DenseLogNormalDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'target_dyn_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'p': True, 'num_units': 8, 'W': <lasagne.init.GlorotNormal object at 0x7fe6f4c06310>})\n",
      "[2018-05-13 01:00:56.995389] target_dyn > Initialising loss function\n",
      "[2018-05-13 01:00:57.144982] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-13 01:00:57.420714] target_dyn_opt > No gradient clipping\n",
      "[2018-05-13 01:00:57.421956] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-13 01:00:57.479761] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-13 01:00:58.302173] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-13 01:01:02.865446] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:01:02.873014] target_dyn_opt > Initial loss [3552.576484579449]\n",
      "\u001b[2K[2018-05-13 01:01:12.541464] target_dyn_opt > Curr loss: 5.301017E+01 [1970: 4.821090E+01], n_evals: 1999, Avg. time per updt: 0.003314\n",
      "[2018-05-13 01:01:12.548710] target_dyn_opt > Done training. New loss [52.194531] iter: [2000]\n",
      "[2018-05-13 01:01:12.822513] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:01:12.861431] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': <lasagne.init.GlorotNormal object at 0x7fe70ef11250>, 'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'p': 0.1, 'num_units': 200, 'W': <lasagne.init.GlorotNormal object at 0x7fe70ef11250>})\n",
      "('DenseDropoutLayer', {'b': <lasagne.init.Uniform object at 0x7fe79791b5d0>, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'p': 0.1, 'num_units': 1, 'W': <lasagne.init.GlorotNormal object at 0x7fe70ef11250>})\n",
      "[2018-05-13 01:01:13.067839] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 01:01:13.069404] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 01:01:13.161682] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 01:01:13.162932] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 01:01:13.760940] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 01:01:13.762400] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 01:01:13.850717] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 01:01:13.851965] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 01:01:18.341544] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-13 01:01:21.129467] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-13 01:01:21.139369] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-13 01:01:21.169613] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-13 01:01:24.133972] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-13 01:01:40.325660] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_0.zip\n",
      "[2018-05-13 01:01:40.391147] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_0.zip\n",
      "[2018-05-13 01:01:40.465458] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_0.zip\n",
      "[2018-05-13 01:01:40.562172] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-13 01:01:40.563457] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-13 01:01:40.568162] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:01:40.705890] SGDOptimizer > Initial loss [7.373046398162842]\n",
      "\u001b[2K[2018-05-13 01:03:17.649958] SGDOptimizer > Curr loss: 1.111843E+00, n_evals: 999, Avg. time per updt: 0.095656\n",
      "[2018-05-13 01:03:17.678725] SGDOptimizer > Done training. New loss [1.223581] iter: [999]\n",
      "[2018-05-13 01:03:17.680615] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-13 01:03:17.762579] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-13 01:03:17.915345] NNPolicy > Done compiling\n",
      "[2018-05-13 01:03:17.917041] apply_controller > Starting run\n",
      "[2018-05-13 01:03:17.918200] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:03:18.071656] apply_controller > Done. Stopping robot. Value of run [29.994276]\n",
      "[2018-05-13 01:03:18.073087] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:03:18.074374] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:03:18.076610] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-13 01:03:18.077898] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:03:18.087371] target_dyn_opt > Initial loss [132.50352635352414]\n",
      "\u001b[2K[2018-05-13 01:03:30.551298] target_dyn_opt > Curr loss: 2.142717E+01 [1857: 1.898543E+01], n_evals: 1999, Avg. time per updt: 0.004730\n",
      "[2018-05-13 01:03:30.560129] target_dyn_opt > Done training. New loss [21.989043] iter: [2000]\n",
      "[2018-05-13 01:03:30.562822] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:03:30.564250] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_1.zip\n",
      "[2018-05-13 01:03:30.681010] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_1.zip\n",
      "[2018-05-13 01:03:30.758144] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_1.zip\n",
      "[2018-05-13 01:03:34.537630] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-13 01:03:34.542479] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:03:34.671144] SGDOptimizer > Initial loss [2.60505747795105]\n",
      "\u001b[2K[2018-05-13 01:05:13.952377] SGDOptimizer > Curr loss: 1.417671E+00, n_evals: 999, Avg. time per updt: 0.097966\n",
      "[2018-05-13 01:05:13.978237] SGDOptimizer > Done training. New loss [1.438771] iter: [999]\n",
      "[2018-05-13 01:05:13.980247] apply_controller > Starting run\n",
      "[2018-05-13 01:05:13.981770] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:05:14.148543] apply_controller > Done. Stopping robot. Value of run [29.989487]\n",
      "[2018-05-13 01:05:14.150132] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:05:14.151462] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:05:14.154253] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-13 01:05:14.155576] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:05:14.167948] target_dyn_opt > Initial loss [54.259394543179866]\n",
      "\u001b[2K[2018-05-13 01:05:31.070652] target_dyn_opt > Curr loss: 1.089662E+01 [1970: 9.455608E+00], n_evals: 1999, Avg. time per updt: 0.006878\n",
      "[2018-05-13 01:05:31.084249] target_dyn_opt > Done training. New loss [10.961369] iter: [2000]\n",
      "[2018-05-13 01:05:31.087133] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:05:31.088564] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_2.zip\n",
      "[2018-05-13 01:05:31.248399] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_2.zip\n",
      "[2018-05-13 01:05:31.323896] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_2.zip\n",
      "[2018-05-13 01:05:33.283536] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-13 01:05:33.288638] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:05:33.437957] SGDOptimizer > Initial loss [1.4470138549804688]\n",
      "\u001b[2K[2018-05-13 01:07:18.778691] SGDOptimizer > Curr loss: 1.128861E+00, n_evals: 999, Avg. time per updt: 0.103978\n",
      "[2018-05-13 01:07:18.804416] SGDOptimizer > Done training. New loss [1.123435] iter: [999]\n",
      "[2018-05-13 01:07:18.806306] apply_controller > Starting run\n",
      "[2018-05-13 01:07:18.807098] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:07:19.002780] apply_controller > Done. Stopping robot. Value of run [24.322218]\n",
      "[2018-05-13 01:07:19.004117] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:07:19.007416] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:07:19.009627] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-13 01:07:19.010685] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:07:19.024389] target_dyn_opt > Initial loss [53.258928574412934]\n",
      "\u001b[2K[2018-05-13 01:07:37.370392] target_dyn_opt > Curr loss: 6.564760E+00 [1877: 5.450348E+00], n_evals: 1999, Avg. time per updt: 0.007616\n",
      "[2018-05-13 01:07:37.383455] target_dyn_opt > Done training. New loss [6.619805] iter: [2000]\n",
      "[2018-05-13 01:07:37.386465] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:07:37.387973] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_3.zip\n",
      "[2018-05-13 01:07:37.587050] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_3.zip\n",
      "[2018-05-13 01:07:37.661662] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_3.zip\n",
      "[2018-05-13 01:07:39.553356] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-13 01:07:39.558148] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:07:39.685053] SGDOptimizer > Initial loss [1.0800288915634155]\n",
      "\u001b[2K[2018-05-13 01:09:16.178322] SGDOptimizer > Curr loss: 1.078452E+00, n_evals: 999, Avg. time per updt: 0.095194\n",
      "[2018-05-13 01:09:16.205194] SGDOptimizer > Done training. New loss [1.117745] iter: [999]\n",
      "[2018-05-13 01:09:16.207059] apply_controller > Starting run\n",
      "[2018-05-13 01:09:16.208403] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:09:16.426127] apply_controller > Done. Stopping robot. Value of run [28.165884]\n",
      "[2018-05-13 01:09:16.427341] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:09:16.428650] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:09:16.431280] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-13 01:09:16.432535] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:09:16.445585] target_dyn_opt > Initial loss [20.969135038557077]\n",
      "\u001b[2K[2018-05-13 01:09:34.287148] target_dyn_opt > Curr loss: 2.826884E+00 [1842: 2.036049E+00], n_evals: 1999, Avg. time per updt: 0.007381\n",
      "[2018-05-13 01:09:34.299598] target_dyn_opt > Done training. New loss [3.354496] iter: [2000]\n",
      "[2018-05-13 01:09:34.302556] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:09:34.304333] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_4.zip\n",
      "[2018-05-13 01:09:34.550231] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_4.zip\n",
      "[2018-05-13 01:09:34.626020] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_4.zip\n",
      "[2018-05-13 01:09:36.505346] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-13 01:09:36.510176] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:09:36.631445] SGDOptimizer > Initial loss [1.122911810874939]\n",
      "\u001b[2K[2018-05-13 01:11:13.492753] SGDOptimizer > Curr loss: 1.045771E+00, n_evals: 999, Avg. time per updt: 0.095552\n",
      "[2018-05-13 01:11:13.524679] SGDOptimizer > Done training. New loss [1.070741] iter: [999]\n",
      "[2018-05-13 01:11:13.528761] apply_controller > Starting run\n",
      "[2018-05-13 01:11:13.530176] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:11:13.768740] apply_controller > Done. Stopping robot. Value of run [28.731321]\n",
      "[2018-05-13 01:11:13.770310] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:11:13.771962] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:11:13.774945] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-13 01:11:13.776259] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:11:13.789108] target_dyn_opt > Initial loss [11.73824309682689]\n",
      "\u001b[2K[2018-05-13 01:11:31.733972] target_dyn_opt > Curr loss: 8.610143E-01 [1895: 5.632725E-04], n_evals: 1999, Avg. time per updt: 0.007413\n",
      "[2018-05-13 01:11:31.748829] target_dyn_opt > Done training. New loss [0.410547] iter: [2000]\n",
      "[2018-05-13 01:11:31.751442] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:11:31.752914] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_5.zip\n",
      "[2018-05-13 01:11:32.044283] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_5.zip\n",
      "[2018-05-13 01:11:32.120658] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_5.zip\n",
      "[2018-05-13 01:11:34.018938] ==== Iteration [6], experience: [180 steps] ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:11:34.023441] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:11:34.157871] SGDOptimizer > Initial loss [1.167551040649414]\n",
      "\u001b[2K[2018-05-13 01:13:09.535985] SGDOptimizer > Curr loss: 1.054263E+00, n_evals: 999, Avg. time per updt: 0.094081\n",
      "[2018-05-13 01:13:09.566345] SGDOptimizer > Done training. New loss [1.054760] iter: [999]\n",
      "[2018-05-13 01:13:09.568308] apply_controller > Starting run\n",
      "[2018-05-13 01:13:09.569517] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:13:09.774016] apply_controller > Done. Stopping robot. Value of run [23.127647]\n",
      "[2018-05-13 01:13:09.775330] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:13:09.776814] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:13:09.779719] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-13 01:13:09.780952] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:13:09.795403] target_dyn_opt > Initial loss [3.8809792004775696]\n",
      "\u001b[2K[2018-05-13 01:13:27.528498] target_dyn_opt > Curr loss: -7.598633E-01 [1314: -1.852819E+00], n_evals: 1999, Avg. time per updt: 0.007379\n",
      "[2018-05-13 01:13:27.543067] target_dyn_opt > Done training. New loss [-2.162245] iter: [2000]\n",
      "[2018-05-13 01:13:27.545606] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:13:27.547081] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_6.zip\n",
      "[2018-05-13 01:13:27.876989] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_6.zip\n",
      "[2018-05-13 01:13:27.952761] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_6.zip\n",
      "[2018-05-13 01:13:29.859893] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-13 01:13:29.864860] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:13:29.987375] SGDOptimizer > Initial loss [1.0824276208877563]\n",
      "\u001b[2K[2018-05-13 01:15:04.720097] SGDOptimizer > Curr loss: 1.092985E+00, n_evals: 999, Avg. time per updt: 0.093442\n",
      "[2018-05-13 01:15:04.747823] SGDOptimizer > Done training. New loss [1.098831] iter: [999]\n",
      "[2018-05-13 01:15:04.749513] apply_controller > Starting run\n",
      "[2018-05-13 01:15:04.750957] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:15:04.958923] apply_controller > Done. Stopping robot. Value of run [26.737808]\n",
      "[2018-05-13 01:15:04.960430] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:15:04.961720] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:15:04.964675] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-13 01:15:04.965921] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:15:04.980735] target_dyn_opt > Initial loss [2.910128881817619]\n",
      "\u001b[2K[2018-05-13 01:15:22.432502] target_dyn_opt > Curr loss: -2.792293E+00 [1901: -3.196305E+00], n_evals: 1999, Avg. time per updt: 0.007231\n",
      "[2018-05-13 01:15:22.447288] target_dyn_opt > Done training. New loss [-2.458681] iter: [2000]\n",
      "[2018-05-13 01:15:22.449954] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:15:22.451641] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_7.zip\n",
      "[2018-05-13 01:15:22.825588] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_7.zip\n",
      "[2018-05-13 01:15:22.901223] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_7.zip\n",
      "[2018-05-13 01:15:24.807370] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-13 01:15:24.812233] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:15:24.948508] SGDOptimizer > Initial loss [1.0686570405960083]\n",
      "\u001b[2K[2018-05-13 01:17:01.452766] SGDOptimizer > Curr loss: 1.026333E+00, n_evals: 999, Avg. time per updt: 0.095226\n",
      "[2018-05-13 01:17:01.480395] SGDOptimizer > Done training. New loss [1.027406] iter: [999]\n",
      "[2018-05-13 01:17:01.484443] apply_controller > Starting run\n",
      "[2018-05-13 01:17:01.485883] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:17:01.683564] apply_controller > Done. Stopping robot. Value of run [23.433002]\n",
      "[2018-05-13 01:17:01.684809] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:17:01.686759] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:17:01.689635] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-13 01:17:01.691115] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:17:01.706540] target_dyn_opt > Initial loss [-0.04352209333087753]\n",
      "\u001b[2K[2018-05-13 01:17:19.842667] target_dyn_opt > Curr loss: -3.886092E+00 [1935: -4.257192E+00], n_evals: 1999, Avg. time per updt: 0.007525\n",
      "[2018-05-13 01:17:19.855714] target_dyn_opt > Done training. New loss [-3.816968] iter: [2000]\n",
      "[2018-05-13 01:17:19.858651] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:17:19.860165] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_8.zip\n",
      "[2018-05-13 01:17:20.297198] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_8.zip\n",
      "[2018-05-13 01:17:20.373799] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_8.zip\n",
      "[2018-05-13 01:17:22.289913] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-13 01:17:22.294869] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:17:22.421262] SGDOptimizer > Initial loss [1.0325332880020142]\n",
      "\u001b[2K[2018-05-13 01:18:59.060297] SGDOptimizer > Curr loss: 1.021240E+00, n_evals: 999, Avg. time per updt: 0.095361\n",
      "[2018-05-13 01:18:59.086269] SGDOptimizer > Done training. New loss [1.021732] iter: [999]\n",
      "[2018-05-13 01:18:59.087956] apply_controller > Starting run\n",
      "[2018-05-13 01:18:59.088851] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:18:59.307371] apply_controller > Done. Stopping robot. Value of run [27.877789]\n",
      "[2018-05-13 01:18:59.308710] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:18:59.309706] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:18:59.313289] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-13 01:18:59.314547] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:18:59.329448] target_dyn_opt > Initial loss [-2.488565471036167]\n",
      "\u001b[2K[2018-05-13 01:19:16.980733] target_dyn_opt > Curr loss: -4.794379E+00 [1589: -5.227826E+00], n_evals: 1999, Avg. time per updt: 0.007314\n",
      "[2018-05-13 01:19:16.993237] target_dyn_opt > Done training. New loss [-4.486458] iter: [2000]\n",
      "[2018-05-13 01:19:16.995965] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:19:16.997758] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_9.zip\n",
      "[2018-05-13 01:19:17.446823] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_9.zip\n",
      "[2018-05-13 01:19:17.523697] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_9.zip\n",
      "[2018-05-13 01:19:19.423058] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-13 01:19:19.428224] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:19:19.551048] SGDOptimizer > Initial loss [1.051794171333313]\n",
      "\u001b[2K[2018-05-13 01:20:56.302144] SGDOptimizer > Curr loss: 1.071845E+00, n_evals: 999, Avg. time per updt: 0.095467\n",
      "[2018-05-13 01:20:56.327791] SGDOptimizer > Done training. New loss [1.063796] iter: [999]\n",
      "[2018-05-13 01:20:56.329832] apply_controller > Starting run\n",
      "[2018-05-13 01:20:56.331041] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:20:56.530042] apply_controller > Done. Stopping robot. Value of run [28.422153]\n",
      "[2018-05-13 01:20:56.531396] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:20:56.534821] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:20:56.537926] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-13 01:20:56.539177] target_dyn_opt > Optimizing parameters via mini batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:20:56.552925] target_dyn_opt > Initial loss [-2.7549199911307394]\n",
      "\u001b[2K[2018-05-13 01:21:13.877555] target_dyn_opt > Curr loss: -5.660141E+00 [1880: -5.917906E+00], n_evals: 1999, Avg. time per updt: 0.007183\n",
      "[2018-05-13 01:21:13.890939] target_dyn_opt > Done training. New loss [-5.191447] iter: [2000]\n",
      "[2018-05-13 01:21:13.893499] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:21:13.894877] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_10.zip\n",
      "[2018-05-13 01:21:14.398341] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_10.zip\n",
      "[2018-05-13 01:21:14.474276] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_10.zip\n",
      "[2018-05-13 01:21:16.362011] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-13 01:21:16.367029] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:21:16.508868] SGDOptimizer > Initial loss [1.0607895851135254]\n",
      "\u001b[2K[2018-05-13 01:22:52.853996] SGDOptimizer > Curr loss: 1.170861E+00, n_evals: 999, Avg. time per updt: 0.095065\n",
      "[2018-05-13 01:22:52.879790] SGDOptimizer > Done training. New loss [1.179689] iter: [999]\n",
      "[2018-05-13 01:22:52.881867] apply_controller > Starting run\n",
      "[2018-05-13 01:22:52.883196] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:22:53.123071] apply_controller > Done. Stopping robot. Value of run [27.670807]\n",
      "[2018-05-13 01:22:53.124303] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:22:53.126686] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:22:53.129723] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-13 01:22:53.131033] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:22:53.146910] target_dyn_opt > Initial loss [-0.20899131249679215]\n",
      "\u001b[2K[2018-05-13 01:23:10.785533] target_dyn_opt > Curr loss: -6.195137E+00 [1846: -6.618653E+00], n_evals: 1999, Avg. time per updt: 0.007329\n",
      "[2018-05-13 01:23:10.797905] target_dyn_opt > Done training. New loss [-6.190832] iter: [2000]\n",
      "[2018-05-13 01:23:10.800467] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:23:10.801857] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_11.zip\n",
      "[2018-05-13 01:23:11.361359] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_11.zip\n",
      "[2018-05-13 01:23:11.442085] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_11.zip\n",
      "[2018-05-13 01:23:15.316296] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-13 01:23:15.321201] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:23:15.455433] SGDOptimizer > Initial loss [1.2411609888076782]\n",
      "\u001b[2K[2018-05-13 01:24:53.687559] SGDOptimizer > Curr loss: 1.045620E+00, n_evals: 999, Avg. time per updt: 0.096950\n",
      "[2018-05-13 01:24:53.713310] SGDOptimizer > Done training. New loss [1.054519] iter: [999]\n",
      "[2018-05-13 01:24:53.715223] apply_controller > Starting run\n",
      "[2018-05-13 01:24:53.716832] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:24:53.965131] apply_controller > Done. Stopping robot. Value of run [28.110491]\n",
      "[2018-05-13 01:24:53.966471] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:24:53.967755] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:24:53.971522] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-13 01:24:53.972957] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:24:53.988149] target_dyn_opt > Initial loss [16.79294313352051]\n",
      "\u001b[2K[2018-05-13 01:25:11.560639] target_dyn_opt > Curr loss: -5.727395E+00 [1577: -6.790198E+00], n_evals: 1999, Avg. time per updt: 0.007286\n",
      "[2018-05-13 01:25:11.573467] target_dyn_opt > Done training. New loss [-6.183743] iter: [2000]\n",
      "[2018-05-13 01:25:11.576279] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:25:11.577770] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_12.zip\n",
      "[2018-05-13 01:25:12.146606] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_12.zip\n",
      "[2018-05-13 01:25:12.224169] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_12.zip\n",
      "[2018-05-13 01:25:14.132130] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-13 01:25:14.137315] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:25:14.275371] SGDOptimizer > Initial loss [1.05214262008667]\n",
      "\u001b[2K[2018-05-13 01:26:57.801147] SGDOptimizer > Curr loss: 1.100134E+00, n_evals: 999, Avg. time per updt: 0.102239\n",
      "[2018-05-13 01:26:57.829946] SGDOptimizer > Done training. New loss [1.036780] iter: [999]\n",
      "[2018-05-13 01:26:57.831516] apply_controller > Starting run\n",
      "[2018-05-13 01:26:57.832722] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:26:58.063002] apply_controller > Done. Stopping robot. Value of run [28.129253]\n",
      "[2018-05-13 01:26:58.064217] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:26:58.065511] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:26:58.068825] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-13 01:26:58.070296] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:26:58.083968] target_dyn_opt > Initial loss [-3.3622918516544287]\n",
      "\u001b[2K[2018-05-13 01:27:16.279508] target_dyn_opt > Curr loss: -6.399345E+00 [1779: -7.343700E+00], n_evals: 1999, Avg. time per updt: 0.007623\n",
      "[2018-05-13 01:27:16.295352] target_dyn_opt > Done training. New loss [-6.997156] iter: [2000]\n",
      "[2018-05-13 01:27:16.297956] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:27:16.299284] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_13.zip\n",
      "[2018-05-13 01:27:16.924086] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_13.zip\n",
      "[2018-05-13 01:27:17.001080] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_13.zip\n",
      "[2018-05-13 01:27:18.906282] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-13 01:27:18.911073] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:27:19.080111] SGDOptimizer > Initial loss [1.0185761451721191]\n",
      "\u001b[2K[2018-05-13 01:29:19.099734] SGDOptimizer > Curr loss: 1.152865E+00, n_evals: 999, Avg. time per updt: 0.118732\n",
      "[2018-05-13 01:29:19.143135] SGDOptimizer > Done training. New loss [1.137523] iter: [999]\n",
      "[2018-05-13 01:29:19.145021] apply_controller > Starting run\n",
      "[2018-05-13 01:29:19.146787] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:29:19.412842] apply_controller > Done. Stopping robot. Value of run [27.045425]\n",
      "[2018-05-13 01:29:19.414068] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:29:19.415134] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:29:19.418866] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-13 01:29:19.420171] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:29:19.435212] target_dyn_opt > Initial loss [-5.439532444805934]\n",
      "\u001b[2K[2018-05-13 01:29:38.065426] target_dyn_opt > Curr loss: -7.207632E+00 [1571: -7.953404E+00], n_evals: 1999, Avg. time per updt: 0.007827\n",
      "[2018-05-13 01:29:38.078544] target_dyn_opt > Done training. New loss [-7.591778] iter: [2000]\n",
      "[2018-05-13 01:29:38.081110] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:29:38.082956] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_14.zip\n",
      "[2018-05-13 01:29:38.739267] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_14.zip\n",
      "[2018-05-13 01:29:38.816381] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:29:40.714788] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-13 01:29:40.720672] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:29:40.869563] SGDOptimizer > Initial loss [1.1475088596343994]\n",
      "\u001b[2K[2018-05-13 01:31:21.466747] SGDOptimizer > Curr loss: 1.028686E+00, n_evals: 999, Avg. time per updt: 0.099308\n",
      "[2018-05-13 01:31:21.496747] SGDOptimizer > Done training. New loss [1.107759] iter: [999]\n",
      "[2018-05-13 01:31:21.498414] apply_controller > Starting run\n",
      "[2018-05-13 01:31:21.499722] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:31:21.701235] apply_controller > Done. Stopping robot. Value of run [25.096731]\n",
      "[2018-05-13 01:31:21.702580] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:31:21.703928] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:31:21.707730] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-13 01:31:21.709173] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:31:21.722487] target_dyn_opt > Initial loss [-6.167387062330441]\n",
      "\u001b[2K[2018-05-13 01:31:39.138585] target_dyn_opt > Curr loss: -7.932148E+00 [1491: -8.353820E+00], n_evals: 1999, Avg. time per updt: 0.007246\n",
      "[2018-05-13 01:31:39.151046] target_dyn_opt > Done training. New loss [-7.637194] iter: [2000]\n",
      "[2018-05-13 01:31:39.153834] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:31:39.155233] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_15.zip\n",
      "[2018-05-13 01:31:39.847327] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_15.zip\n",
      "[2018-05-13 01:31:39.925084] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_15.zip\n",
      "[2018-05-13 01:31:41.824253] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-13 01:31:41.829246] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:31:41.963705] SGDOptimizer > Initial loss [1.0306934118270874]\n",
      "\u001b[2K[2018-05-13 01:33:23.430828] SGDOptimizer > Curr loss: 1.034204E+00, n_evals: 999, Avg. time per updt: 0.100162\n",
      "[2018-05-13 01:33:23.459646] SGDOptimizer > Done training. New loss [1.095144] iter: [999]\n",
      "[2018-05-13 01:33:23.461816] apply_controller > Starting run\n",
      "[2018-05-13 01:33:23.463308] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:33:23.681192] apply_controller > Done. Stopping robot. Value of run [26.790056]\n",
      "[2018-05-13 01:33:23.682821] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:33:23.684083] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:33:23.688613] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-13 01:33:23.690276] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:33:23.705551] target_dyn_opt > Initial loss [-1.2278935668676425]\n",
      "\u001b[2K[2018-05-13 01:33:41.561876] target_dyn_opt > Curr loss: -7.440407E+00 [1836: -8.723308E+00], n_evals: 1999, Avg. time per updt: 0.007450\n",
      "[2018-05-13 01:33:41.575274] target_dyn_opt > Done training. New loss [-8.273687] iter: [2000]\n",
      "[2018-05-13 01:33:41.578144] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:33:41.579606] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_16.zip\n",
      "[2018-05-13 01:33:42.319025] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_16.zip\n",
      "[2018-05-13 01:33:42.400323] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_16.zip\n",
      "[2018-05-13 01:33:44.301690] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-13 01:33:44.306712] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:33:44.458242] SGDOptimizer > Initial loss [1.0352956056594849]\n",
      "\u001b[2K[2018-05-13 01:35:26.436733] SGDOptimizer > Curr loss: 1.052563E+00, n_evals: 999, Avg. time per updt: 0.100676\n",
      "[2018-05-13 01:35:26.464854] SGDOptimizer > Done training. New loss [1.066391] iter: [999]\n",
      "[2018-05-13 01:35:26.466605] apply_controller > Starting run\n",
      "[2018-05-13 01:35:26.467870] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:35:26.728405] apply_controller > Done. Stopping robot. Value of run [29.813782]\n",
      "[2018-05-13 01:35:26.730030] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:35:26.731327] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:35:26.736066] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-13 01:35:26.737438] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:35:26.751795] target_dyn_opt > Initial loss [-3.786046260960714]\n",
      "\u001b[2K[2018-05-13 01:35:44.648593] target_dyn_opt > Curr loss: -8.199726E+00 [1990: -9.145930E+00], n_evals: 1999, Avg. time per updt: 0.007479\n",
      "[2018-05-13 01:35:44.661600] target_dyn_opt > Done training. New loss [-8.240294] iter: [2000]\n",
      "[2018-05-13 01:35:44.664146] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:35:44.665453] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_17.zip\n",
      "[2018-05-13 01:35:45.448899] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_17.zip\n",
      "[2018-05-13 01:35:45.527749] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_17.zip\n",
      "[2018-05-13 01:35:47.434122] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-13 01:35:47.438945] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:35:47.575558] SGDOptimizer > Initial loss [1.1036953926086426]\n",
      "\u001b[2K[2018-05-13 01:37:31.383945] SGDOptimizer > Curr loss: 1.051944E+00, n_evals: 999, Avg. time per updt: 0.102507\n",
      "[2018-05-13 01:37:31.412717] SGDOptimizer > Done training. New loss [1.054623] iter: [999]\n",
      "[2018-05-13 01:37:31.414433] apply_controller > Starting run\n",
      "[2018-05-13 01:37:31.415877] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:37:31.595831] apply_controller > Done. Stopping robot. Value of run [27.440174]\n",
      "[2018-05-13 01:37:31.597060] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:37:31.598323] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:37:31.601785] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-13 01:37:31.603336] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:37:31.616933] target_dyn_opt > Initial loss [-6.315038445586518]\n",
      "\u001b[2K[2018-05-13 01:37:49.324668] target_dyn_opt > Curr loss: -8.568480E+00 [1469: -9.358501E+00], n_evals: 1999, Avg. time per updt: 0.007375\n",
      "[2018-05-13 01:37:49.337665] target_dyn_opt > Done training. New loss [-9.060033] iter: [2000]\n",
      "[2018-05-13 01:37:49.340309] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:37:49.341739] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_18.zip\n",
      "[2018-05-13 01:37:50.171107] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_18.zip\n",
      "[2018-05-13 01:37:50.255119] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_18.zip\n",
      "[2018-05-13 01:37:52.173379] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-13 01:37:52.179053] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:37:52.330086] SGDOptimizer > Initial loss [1.0473061800003052]\n",
      "\u001b[2K[2018-05-13 01:39:36.748534] SGDOptimizer > Curr loss: 1.073338E+00, n_evals: 999, Avg. time per updt: 0.103091\n",
      "[2018-05-13 01:39:36.776744] SGDOptimizer > Done training. New loss [1.051260] iter: [999]\n",
      "[2018-05-13 01:39:36.778963] apply_controller > Starting run\n",
      "[2018-05-13 01:39:36.780260] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:39:36.992562] apply_controller > Done. Stopping robot. Value of run [26.591396]\n",
      "[2018-05-13 01:39:36.993784] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:39:36.995203] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:39:36.999453] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:39:37.000914] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:39:37.014627] target_dyn_opt > Initial loss [-7.4378865450620655]\n",
      "\u001b[2K[2018-05-13 01:39:54.764564] target_dyn_opt > Curr loss: -9.145403E+00 [1357: -9.838453E+00], n_evals: 1999, Avg. time per updt: 0.007406\n",
      "[2018-05-13 01:39:54.779703] target_dyn_opt > Done training. New loss [-8.824719] iter: [2000]\n",
      "[2018-05-13 01:39:54.782203] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:39:54.783584] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_19.zip\n",
      "[2018-05-13 01:39:55.647273] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_19.zip\n",
      "[2018-05-13 01:39:55.726431] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_19.zip\n",
      "[2018-05-13 01:39:57.647582] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-13 01:39:57.652524] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:39:57.793340] SGDOptimizer > Initial loss [1.0521601438522339]\n",
      "\u001b[2K[2018-05-13 01:41:43.225356] SGDOptimizer > Curr loss: 1.060428E+00, n_evals: 999, Avg. time per updt: 0.104113\n",
      "[2018-05-13 01:41:43.254574] SGDOptimizer > Done training. New loss [1.057363] iter: [999]\n",
      "[2018-05-13 01:41:43.256239] apply_controller > Starting run\n",
      "[2018-05-13 01:41:43.257421] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:41:43.451361] apply_controller > Done. Stopping robot. Value of run [26.527235]\n",
      "[2018-05-13 01:41:43.452903] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:41:43.454223] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:41:43.459296] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-13 01:41:43.460659] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:41:43.474045] target_dyn_opt > Initial loss [-8.283811452500338]\n",
      "\u001b[2K[2018-05-13 01:42:01.550238] target_dyn_opt > Curr loss: -9.662315E+00 [1811: -1.025057E+01], n_evals: 1999, Avg. time per updt: 0.007556\n",
      "[2018-05-13 01:42:01.563210] target_dyn_opt > Done training. New loss [-9.816819] iter: [2000]\n",
      "[2018-05-13 01:42:01.566333] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:42:01.568024] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_20.zip\n",
      "[2018-05-13 01:42:02.480284] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_20.zip\n",
      "[2018-05-13 01:42:02.562398] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_20.zip\n",
      "[2018-05-13 01:42:04.490148] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-13 01:42:04.495852] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:42:04.638177] SGDOptimizer > Initial loss [2.9890449047088623]\n",
      "\u001b[2K[2018-05-13 01:43:50.860284] SGDOptimizer > Curr loss: 1.065415E+00, n_evals: 999, Avg. time per updt: 0.104929\n",
      "[2018-05-13 01:43:50.893146] SGDOptimizer > Done training. New loss [1.056498] iter: [999]\n",
      "[2018-05-13 01:43:50.895071] apply_controller > Starting run\n",
      "[2018-05-13 01:43:50.896339] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:43:51.106115] apply_controller > Done. Stopping robot. Value of run [27.940092]\n",
      "[2018-05-13 01:43:51.107635] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:43:51.108980] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:43:51.113824] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-13 01:43:51.115276] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:43:51.129008] target_dyn_opt > Initial loss [-9.258903016304147]\n",
      "\u001b[2K[2018-05-13 01:44:09.190730] target_dyn_opt > Curr loss: -9.930257E+00 [1783: -1.048546E+01], n_evals: 1999, Avg. time per updt: 0.007564\n",
      "[2018-05-13 01:44:09.204009] target_dyn_opt > Done training. New loss [-10.165120] iter: [2000]\n",
      "[2018-05-13 01:44:09.206818] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:44:09.208208] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_21.zip\n",
      "[2018-05-13 01:44:10.165194] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_21.zip\n",
      "[2018-05-13 01:44:10.245315] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_21.zip\n",
      "[2018-05-13 01:44:12.165764] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-13 01:44:12.170668] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:44:12.316402] SGDOptimizer > Initial loss [1.074601411819458]\n",
      "\u001b[2K[2018-05-13 01:46:01.765040] SGDOptimizer > Curr loss: 1.012277E+00, n_evals: 999, Avg. time per updt: 0.108162\n",
      "[2018-05-13 01:46:01.794586] SGDOptimizer > Done training. New loss [1.025890] iter: [999]\n",
      "[2018-05-13 01:46:01.796230] apply_controller > Starting run\n",
      "[2018-05-13 01:46:01.797049] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:46:02.008808] apply_controller > Done. Stopping robot. Value of run [20.902147]\n",
      "[2018-05-13 01:46:02.010135] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:46:02.011048] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:46:02.015628] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-13 01:46:02.016995] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:46:02.031126] target_dyn_opt > Initial loss [-8.493271422439786]\n",
      "\u001b[2K[2018-05-13 01:46:19.981120] target_dyn_opt > Curr loss: -9.964762E+00 [1712: -1.069149E+01], n_evals: 1999, Avg. time per updt: 0.007491\n",
      "[2018-05-13 01:46:19.995909] target_dyn_opt > Done training. New loss [-10.045472] iter: [2000]\n",
      "[2018-05-13 01:46:19.998481] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:46:20.000080] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_22.zip\n",
      "[2018-05-13 01:46:20.994259] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_22.zip\n",
      "[2018-05-13 01:46:21.075236] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_22.zip\n",
      "[2018-05-13 01:46:22.998364] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-13 01:46:23.003310] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:46:23.140368] SGDOptimizer > Initial loss [1.0327167510986328]\n",
      "\u001b[2K[2018-05-13 01:48:10.534782] SGDOptimizer > Curr loss: 1.070595E+00, n_evals: 999, Avg. time per updt: 0.106098\n",
      "[2018-05-13 01:48:10.564460] SGDOptimizer > Done training. New loss [1.067551] iter: [999]\n",
      "[2018-05-13 01:48:10.566062] apply_controller > Starting run\n",
      "[2018-05-13 01:48:10.567561] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:48:10.819961] apply_controller > Done. Stopping robot. Value of run [24.845325]\n",
      "[2018-05-13 01:48:10.821495] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:48:10.822783] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:48:10.828442] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-13 01:48:10.829804] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:48:10.847444] target_dyn_opt > Initial loss [-5.674295612707221]\n",
      "\u001b[2K[2018-05-13 01:48:28.835557] target_dyn_opt > Curr loss: -1.017697E+01 [1469: -1.083211E+01], n_evals: 1999, Avg. time per updt: 0.007516\n",
      "[2018-05-13 01:48:28.849260] target_dyn_opt > Done training. New loss [-10.316551] iter: [2000]\n",
      "[2018-05-13 01:48:28.851897] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:48:28.853226] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_23.zip\n",
      "[2018-05-13 01:48:29.885136] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_23.zip\n",
      "[2018-05-13 01:48:29.964436] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_23.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:48:31.890786] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-13 01:48:31.896557] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:48:32.042561] SGDOptimizer > Initial loss [1.0677735805511475]\n",
      "\u001b[2K[2018-05-13 01:50:18.508482] SGDOptimizer > Curr loss: 1.100039E+00, n_evals: 999, Avg. time per updt: 0.105183\n",
      "[2018-05-13 01:50:18.537798] SGDOptimizer > Done training. New loss [1.070559] iter: [999]\n",
      "[2018-05-13 01:50:18.539464] apply_controller > Starting run\n",
      "[2018-05-13 01:50:18.540750] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:50:18.793354] apply_controller > Done. Stopping robot. Value of run [28.138481]\n",
      "[2018-05-13 01:50:18.794660] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:50:18.796051] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:50:18.800273] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-13 01:50:18.801937] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:50:18.816058] target_dyn_opt > Initial loss [-8.173879604791772]\n",
      "\u001b[2K[2018-05-13 01:50:37.017462] target_dyn_opt > Curr loss: -1.067054E+01 [1756: -1.120731E+01], n_evals: 1999, Avg. time per updt: 0.007623\n",
      "[2018-05-13 01:50:37.032392] target_dyn_opt > Done training. New loss [-10.306437] iter: [2000]\n",
      "[2018-05-13 01:50:37.034920] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:50:37.036564] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_24.zip\n",
      "[2018-05-13 01:50:38.129134] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_24.zip\n",
      "[2018-05-13 01:50:38.213391] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_24.zip\n",
      "[2018-05-13 01:50:40.150983] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-13 01:50:40.155891] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:50:40.290009] SGDOptimizer > Initial loss [1.083405613899231]\n",
      "\u001b[2K[2018-05-13 01:52:27.515062] SGDOptimizer > Curr loss: 1.161424E+00, n_evals: 999, Avg. time per updt: 0.105944\n",
      "[2018-05-13 01:52:27.544868] SGDOptimizer > Done training. New loss [1.202925] iter: [999]\n",
      "[2018-05-13 01:52:27.546539] apply_controller > Starting run\n",
      "[2018-05-13 01:52:27.547729] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:52:27.743008] apply_controller > Done. Stopping robot. Value of run [29.443176]\n",
      "[2018-05-13 01:52:27.744345] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:52:27.746640] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:52:27.751135] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-13 01:52:27.752477] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:52:27.766064] target_dyn_opt > Initial loss [-8.493859639060275]\n",
      "\u001b[2K[2018-05-13 01:52:45.793561] target_dyn_opt > Curr loss: -1.091308E+01 [820: -1.130075E+01], n_evals: 1999, Avg. time per updt: 0.007561\n",
      "[2018-05-13 01:52:45.808310] target_dyn_opt > Done training. New loss [-10.733873] iter: [2000]\n",
      "[2018-05-13 01:52:45.811201] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:52:45.812822] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_25.zip\n",
      "[2018-05-13 01:52:46.931904] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_25.zip\n",
      "[2018-05-13 01:52:47.013556] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_25.zip\n",
      "[2018-05-13 01:52:48.937899] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-13 01:52:48.942922] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:52:49.091148] SGDOptimizer > Initial loss [1.138769268989563]\n",
      "\u001b[2K[2018-05-13 01:54:37.310144] SGDOptimizer > Curr loss: 1.156041E+00, n_evals: 999, Avg. time per updt: 0.106923\n",
      "[2018-05-13 01:54:37.340257] SGDOptimizer > Done training. New loss [1.124496] iter: [999]\n",
      "[2018-05-13 01:54:37.342062] apply_controller > Starting run\n",
      "[2018-05-13 01:54:37.343371] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:54:37.595587] apply_controller > Done. Stopping robot. Value of run [27.528708]\n",
      "[2018-05-13 01:54:37.596818] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:54:37.598172] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:54:37.603048] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-13 01:54:37.604991] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:54:37.618848] target_dyn_opt > Initial loss [-7.100718458683859]\n",
      "\u001b[2K[2018-05-13 01:54:55.867048] target_dyn_opt > Curr loss: -1.141104E+01 [1540: -1.154137E+01], n_evals: 1999, Avg. time per updt: 0.007649\n",
      "[2018-05-13 01:54:55.880817] target_dyn_opt > Done training. New loss [-10.859129] iter: [2000]\n",
      "[2018-05-13 01:54:55.883570] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:54:55.884915] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_26.zip\n",
      "[2018-05-13 01:54:57.045616] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_26.zip\n",
      "[2018-05-13 01:54:57.128379] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_26.zip\n",
      "[2018-05-13 01:54:59.031159] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-13 01:54:59.036252] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:54:59.175304] SGDOptimizer > Initial loss [1.128998041152954]\n",
      "\u001b[2K[2018-05-13 01:56:45.988920] SGDOptimizer > Curr loss: 9.963270E-01, n_evals: 999, Avg. time per updt: 0.105526\n",
      "[2018-05-13 01:56:46.019009] SGDOptimizer > Done training. New loss [1.015843] iter: [999]\n",
      "[2018-05-13 01:56:46.020706] apply_controller > Starting run\n",
      "[2018-05-13 01:56:46.022136] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:56:46.227756] apply_controller > Done. Stopping robot. Value of run [29.163649]\n",
      "[2018-05-13 01:56:46.229325] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:56:46.230634] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:56:46.235321] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-13 01:56:46.236571] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:56:46.250479] target_dyn_opt > Initial loss [-7.86114071456376]\n",
      "\u001b[2K[2018-05-13 01:57:04.044096] target_dyn_opt > Curr loss: -1.125421E+01 [1127: -1.175272E+01], n_evals: 1999, Avg. time per updt: 0.007436\n",
      "[2018-05-13 01:57:04.059609] target_dyn_opt > Done training. New loss [-11.145979] iter: [2000]\n",
      "[2018-05-13 01:57:04.062260] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:57:04.063602] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_27.zip\n",
      "[2018-05-13 01:57:05.277679] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_27.zip\n",
      "[2018-05-13 01:57:05.360116] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_27.zip\n",
      "[2018-05-13 01:57:07.293798] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-13 01:57:07.298762] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:57:07.437707] SGDOptimizer > Initial loss [1.0076115131378174]\n",
      "\u001b[2K[2018-05-13 01:58:55.619180] SGDOptimizer > Curr loss: 1.104610E+00, n_evals: 999, Avg. time per updt: 0.106890\n",
      "[2018-05-13 01:58:55.653608] SGDOptimizer > Done training. New loss [1.025050] iter: [999]\n",
      "[2018-05-13 01:58:55.655266] apply_controller > Starting run\n",
      "[2018-05-13 01:58:55.656444] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 01:58:55.863045] apply_controller > Done. Stopping robot. Value of run [26.258123]\n",
      "[2018-05-13 01:58:55.864533] target_2x_mass > Stopping robot\n",
      "[2018-05-13 01:58:55.865790] train_dynamics > Training dynamics model\n",
      "[2018-05-13 01:58:55.870504] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 01:58:55.871890] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 01:58:55.887725] target_dyn_opt > Initial loss [-8.980866091784343]\n",
      "\u001b[2K[2018-05-13 01:59:14.138615] target_dyn_opt > Curr loss: -1.133806E+01 [1625: -1.187059E+01], n_evals: 1999, Avg. time per updt: 0.007655\n",
      "[2018-05-13 01:59:14.151751] target_dyn_opt > Done training. New loss [-11.293425] iter: [2000]\n",
      "[2018-05-13 01:59:14.154488] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 01:59:14.155845] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_28.zip\n",
      "[2018-05-13 01:59:15.406967] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_28.zip\n",
      "[2018-05-13 01:59:15.487327] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_28.zip\n",
      "[2018-05-13 01:59:17.410780] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-13 01:59:17.415672] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 01:59:17.572055] SGDOptimizer > Initial loss [1.0133603811264038]\n",
      "\u001b[2K[2018-05-13 02:01:04.569128] SGDOptimizer > Curr loss: 1.046914E+00, n_evals: 999, Avg. time per updt: 0.105700\n",
      "[2018-05-13 02:01:04.598582] SGDOptimizer > Done training. New loss [1.039328] iter: [999]\n",
      "[2018-05-13 02:01:04.600350] apply_controller > Starting run\n",
      "[2018-05-13 02:01:04.601652] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:01:04.820954] apply_controller > Done. Stopping robot. Value of run [26.156248]\n",
      "[2018-05-13 02:01:04.822294] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:01:04.823664] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:01:04.828391] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-13 02:01:04.829718] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:01:04.843220] target_dyn_opt > Initial loss [-9.119021017455506]\n",
      "\u001b[2K[2018-05-13 02:01:22.839171] target_dyn_opt > Curr loss: -1.112602E+01 [1776: -1.212177E+01], n_evals: 1999, Avg. time per updt: 0.007541\n",
      "[2018-05-13 02:01:22.855124] target_dyn_opt > Done training. New loss [-11.827685] iter: [2000]\n",
      "[2018-05-13 02:01:22.857895] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:01:22.859623] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_29.zip\n",
      "[2018-05-13 02:01:24.163142] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_29.zip\n",
      "[2018-05-13 02:01:24.245325] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_29.zip\n",
      "[2018-05-13 02:01:26.194422] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-13 02:01:26.199473] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:01:26.347181] SGDOptimizer > Initial loss [1.0401564836502075]\n",
      "\u001b[2K[2018-05-13 02:03:14.731238] SGDOptimizer > Curr loss: 1.025107E+00, n_evals: 999, Avg. time per updt: 0.107090\n",
      "[2018-05-13 02:03:14.761658] SGDOptimizer > Done training. New loss [1.065243] iter: [999]\n",
      "[2018-05-13 02:03:14.763455] apply_controller > Starting run\n",
      "[2018-05-13 02:03:14.764684] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:03:14.967178] apply_controller > Done. Stopping robot. Value of run [27.289711]\n",
      "[2018-05-13 02:03:14.968745] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:03:14.969949] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:03:14.974525] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-13 02:03:14.975890] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:03:14.989571] target_dyn_opt > Initial loss [-9.114489179365627]\n",
      "\u001b[2K[2018-05-13 02:03:33.286017] target_dyn_opt > Curr loss: -1.162657E+01 [1915: -1.227606E+01], n_evals: 1999, Avg. time per updt: 0.007676\n",
      "[2018-05-13 02:03:33.301470] target_dyn_opt > Done training. New loss [-11.908146] iter: [2000]\n",
      "[2018-05-13 02:03:33.304218] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:03:33.305599] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/experience_30.zip\n",
      "[2018-05-13 02:03:34.629544] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/policy_30.zip\n",
      "[2018-05-13 02:03:34.711695] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_008_taskplusil_klpq_from_scratch/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 8 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_008_taskplusil_klpq_from_scratch')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 1                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=False)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=False)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:03:36.903388] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 02:03:36.926568] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 02:03:36.957673] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 02:03:36.982129] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 02:03:37.013903] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 02:03:37.026479] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 02:03:37.032512] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 02:03:37.045324] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7fe79839cb90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7fe798322050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 02:03:37.055336] Experience > Initialising new experience dataset\n",
      "[2018-05-13 02:03:37.056661] Executing uniformly-random controls\n",
      "[2018-05-13 02:03:37.058041] apply_controller > Starting run\n",
      "[2018-05-13 02:03:37.059328] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:03:37.231675] apply_controller > Done. Stopping robot. Value of run [29.946793]\n",
      "[2018-05-13 02:03:37.233267] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:03:37.234678] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:03:37.237393] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-13 02:03:37.238746] target_dyn > Initialising loss function\n",
      "[2018-05-13 02:03:37.395754] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-13 02:03:37.707918] target_dyn_opt > No gradient clipping\n",
      "[2018-05-13 02:03:37.709469] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-13 02:03:37.770810] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-13 02:03:38.638751] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-13 02:03:45.337024] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:03:45.344474] target_dyn_opt > Initial loss [5568.10225295815]\n",
      "\u001b[2K[2018-05-13 02:03:55.460623] target_dyn_opt > Curr loss: 4.084856E+01 [1903: 4.045460E+01], n_evals: 1999, Avg. time per updt: 0.003542\n",
      "[2018-05-13 02:03:55.468914] target_dyn_opt > Done training. New loss [40.666625] iter: [2000]\n",
      "[2018-05-13 02:03:55.701018] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:03:55.888724] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 02:03:55.890149] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 02:03:55.974624] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 02:03:55.976148] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 02:03:56.550502] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 02:03:56.551753] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 02:03:56.633231] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 02:03:56.634498] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 02:04:00.039953] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-13 02:04:02.936855] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-13 02:04:02.946067] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-13 02:04:02.977927] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-13 02:04:05.910260] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-13 02:04:24.511051] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_0.zip\n",
      "[2018-05-13 02:04:24.614094] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_0.zip\n",
      "[2018-05-13 02:04:24.723334] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_0.zip\n",
      "[2018-05-13 02:04:24.898154] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-13 02:04:24.899592] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-13 02:04:24.905150] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:04:25.152970] SGDOptimizer > Initial loss [81.18294525146484]\n",
      "\u001b[2K[2018-05-13 02:06:22.202647] SGDOptimizer > Curr loss: 1.036700E+01, n_evals: 999, Avg. time per updt: 0.115757\n",
      "[2018-05-13 02:06:22.236157] SGDOptimizer > Done training. New loss [13.787875] iter: [999]\n",
      "[2018-05-13 02:06:22.237951] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-13 02:06:22.315054] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-13 02:06:22.451666] NNPolicy > Done compiling\n",
      "[2018-05-13 02:06:22.453043] apply_controller > Starting run\n",
      "[2018-05-13 02:06:22.454795] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:06:22.638159] apply_controller > Done. Stopping robot. Value of run [26.587360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:06:22.639399] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:06:22.640740] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:06:22.642787] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-13 02:06:22.644441] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:06:22.655862] target_dyn_opt > Initial loss [99.72602818032792]\n",
      "\u001b[2K[2018-05-13 02:06:35.776619] target_dyn_opt > Curr loss: 1.479556E+01 [1970: 1.431731E+01], n_evals: 1999, Avg. time per updt: 0.005063\n",
      "[2018-05-13 02:06:35.787017] target_dyn_opt > Done training. New loss [14.485334] iter: [2000]\n",
      "[2018-05-13 02:06:35.789621] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:06:35.791100] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_1.zip\n",
      "[2018-05-13 02:06:35.934660] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_1.zip\n",
      "[2018-05-13 02:06:36.040668] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_1.zip\n",
      "[2018-05-13 02:06:38.296201] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-13 02:06:38.301849] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:06:38.454049] SGDOptimizer > Initial loss [11.4335298538208]\n",
      "\u001b[2K[2018-05-13 02:08:28.306940] SGDOptimizer > Curr loss: 1.028012E+01, n_evals: 999, Avg. time per updt: 0.108562\n",
      "[2018-05-13 02:08:28.342550] SGDOptimizer > Done training. New loss [13.418921] iter: [999]\n",
      "[2018-05-13 02:08:28.344157] apply_controller > Starting run\n",
      "[2018-05-13 02:08:28.345367] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:08:28.512569] apply_controller > Done. Stopping robot. Value of run [29.790586]\n",
      "[2018-05-13 02:08:28.513818] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:08:28.515120] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:08:28.517885] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-13 02:08:28.519555] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:08:28.532479] target_dyn_opt > Initial loss [35.451014093969064]\n",
      "\u001b[2K[2018-05-13 02:08:45.519680] target_dyn_opt > Curr loss: 4.974197E+00 [1988: 4.535111E+00], n_evals: 1999, Avg. time per updt: 0.006982\n",
      "[2018-05-13 02:08:45.532477] target_dyn_opt > Done training. New loss [4.654918] iter: [2000]\n",
      "[2018-05-13 02:08:45.535319] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:08:45.536698] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_2.zip\n",
      "[2018-05-13 02:08:45.728142] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_2.zip\n",
      "[2018-05-13 02:08:45.834453] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_2.zip\n",
      "[2018-05-13 02:08:48.094241] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-13 02:08:48.099556] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:08:48.250063] SGDOptimizer > Initial loss [15.525157928466797]\n",
      "\u001b[2K[2018-05-13 02:10:40.575331] SGDOptimizer > Curr loss: 8.557113E+00, n_evals: 999, Avg. time per updt: 0.111064\n",
      "[2018-05-13 02:10:40.608214] SGDOptimizer > Done training. New loss [11.240355] iter: [999]\n",
      "[2018-05-13 02:10:40.610025] apply_controller > Starting run\n",
      "[2018-05-13 02:10:40.611340] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:10:40.789160] apply_controller > Done. Stopping robot. Value of run [28.578548]\n",
      "[2018-05-13 02:10:40.790504] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:10:40.791937] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:10:40.794332] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-13 02:10:40.795580] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:10:40.810310] target_dyn_opt > Initial loss [15.25367333739996]\n",
      "\u001b[2K[2018-05-13 02:10:59.053175] target_dyn_opt > Curr loss: -3.225120E-01 [1902: -8.499050E-01], n_evals: 1999, Avg. time per updt: 0.007620\n",
      "[2018-05-13 02:10:59.067035] target_dyn_opt > Done training. New loss [-0.701278] iter: [2000]\n",
      "[2018-05-13 02:10:59.069853] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:10:59.071362] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_3.zip\n",
      "[2018-05-13 02:10:59.308645] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_3.zip\n",
      "[2018-05-13 02:10:59.417810] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_3.zip\n",
      "[2018-05-13 02:11:01.694138] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-13 02:11:01.698911] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:11:01.848097] SGDOptimizer > Initial loss [8.356673240661621]\n",
      "\u001b[2K[2018-05-13 02:12:43.676748] SGDOptimizer > Curr loss: 7.073955E+00, n_evals: 999, Avg. time per updt: 0.100537\n",
      "[2018-05-13 02:12:43.703723] SGDOptimizer > Done training. New loss [6.642366] iter: [999]\n",
      "[2018-05-13 02:12:43.705778] apply_controller > Starting run\n",
      "[2018-05-13 02:12:43.707283] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:12:43.881998] apply_controller > Done. Stopping robot. Value of run [29.858629]\n",
      "[2018-05-13 02:12:43.883323] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:12:43.884617] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:12:43.887020] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-13 02:12:43.888268] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:12:43.902318] target_dyn_opt > Initial loss [6.889652078727195]\n",
      "\u001b[2K[2018-05-13 02:13:02.504875] target_dyn_opt > Curr loss: -3.616646E+00 [1851: -3.972354E+00], n_evals: 1999, Avg. time per updt: 0.007766\n",
      "[2018-05-13 02:13:02.518360] target_dyn_opt > Done training. New loss [-3.502838] iter: [2000]\n",
      "[2018-05-13 02:13:02.520819] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:13:02.522316] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_4.zip\n",
      "[2018-05-13 02:13:02.800057] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_4.zip\n",
      "[2018-05-13 02:13:02.905497] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_4.zip\n",
      "[2018-05-13 02:13:05.164908] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-13 02:13:05.169745] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:13:05.306372] SGDOptimizer > Initial loss [7.890126705169678]\n",
      "\u001b[2K[2018-05-13 02:14:48.731723] SGDOptimizer > Curr loss: 1.401317E+01, n_evals: 999, Avg. time per updt: 0.102117\n",
      "[2018-05-13 02:14:48.759573] SGDOptimizer > Done training. New loss [13.985003] iter: [999]\n",
      "[2018-05-13 02:14:48.761302] apply_controller > Starting run\n",
      "[2018-05-13 02:14:48.762694] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:14:48.934814] apply_controller > Done. Stopping robot. Value of run [29.904633]\n",
      "[2018-05-13 02:14:48.936129] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:14:48.937353] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:14:48.939852] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-13 02:14:48.941206] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:14:48.955016] target_dyn_opt > Initial loss [6.391766591661279]\n",
      "\u001b[2K[2018-05-13 02:15:07.123161] target_dyn_opt > Curr loss: -5.473175E+00 [1871: -5.869643E+00], n_evals: 1999, Avg. time per updt: 0.007586\n",
      "[2018-05-13 02:15:07.138997] target_dyn_opt > Done training. New loss [-5.317136] iter: [2000]\n",
      "[2018-05-13 02:15:07.141627] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:15:07.143083] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_5.zip\n",
      "[2018-05-13 02:15:07.457826] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:15:07.563417] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_5.zip\n",
      "[2018-05-13 02:15:09.845913] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-13 02:15:09.851050] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:15:10.011215] SGDOptimizer > Initial loss [13.905003547668457]\n",
      "\u001b[2K[2018-05-13 02:17:14.361346] SGDOptimizer > Curr loss: 1.262811E+01, n_evals: 999, Avg. time per updt: 0.123079\n",
      "[2018-05-13 02:17:14.401666] SGDOptimizer > Done training. New loss [11.802900] iter: [999]\n",
      "[2018-05-13 02:17:14.403380] apply_controller > Starting run\n",
      "[2018-05-13 02:17:14.404239] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:17:14.569234] apply_controller > Done. Stopping robot. Value of run [29.954182]\n",
      "[2018-05-13 02:17:14.570603] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:17:14.571648] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:17:14.574355] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-13 02:17:14.575352] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:17:14.590395] target_dyn_opt > Initial loss [-1.4037004778244224]\n",
      "\u001b[2K[2018-05-13 02:17:33.316329] target_dyn_opt > Curr loss: -6.885013E+00 [1780: -7.338647E+00], n_evals: 1999, Avg. time per updt: 0.007859\n",
      "[2018-05-13 02:17:33.332705] target_dyn_opt > Done training. New loss [-7.267406] iter: [2000]\n",
      "[2018-05-13 02:17:33.335399] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:17:33.337822] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_6.zip\n",
      "[2018-05-13 02:17:33.745109] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_6.zip\n",
      "[2018-05-13 02:17:33.849656] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_6.zip\n",
      "[2018-05-13 02:17:36.117790] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-13 02:17:36.123098] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:17:36.257442] SGDOptimizer > Initial loss [14.631119728088379]\n",
      "\u001b[2K[2018-05-13 02:19:14.633622] SGDOptimizer > Curr loss: 1.623541E+01, n_evals: 999, Avg. time per updt: 0.097083\n",
      "[2018-05-13 02:19:14.660512] SGDOptimizer > Done training. New loss [16.584749] iter: [999]\n",
      "[2018-05-13 02:19:14.662078] apply_controller > Starting run\n",
      "[2018-05-13 02:19:14.663369] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:19:14.847070] apply_controller > Done. Stopping robot. Value of run [29.945147]\n",
      "[2018-05-13 02:19:14.848408] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:19:14.849596] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:19:14.852115] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-13 02:19:14.853391] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:19:14.867273] target_dyn_opt > Initial loss [-1.7208220333117863]\n",
      "\u001b[2K[2018-05-13 02:19:32.566588] target_dyn_opt > Curr loss: -7.734219E+00 [1732: -8.455099E+00], n_evals: 1999, Avg. time per updt: 0.007388\n",
      "[2018-05-13 02:19:32.579656] target_dyn_opt > Done training. New loss [-7.908427] iter: [2000]\n",
      "[2018-05-13 02:19:32.582245] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:19:32.583581] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_7.zip\n",
      "[2018-05-13 02:19:32.978685] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_7.zip\n",
      "[2018-05-13 02:19:33.083514] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_7.zip\n",
      "[2018-05-13 02:19:35.335396] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-13 02:19:35.340376] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:19:35.468028] SGDOptimizer > Initial loss [13.90153694152832]\n",
      "\u001b[2K[2018-05-13 02:21:17.462689] SGDOptimizer > Curr loss: 1.294911E+01, n_evals: 999, Avg. time per updt: 0.100705\n",
      "[2018-05-13 02:21:17.490107] SGDOptimizer > Done training. New loss [12.135264] iter: [999]\n",
      "[2018-05-13 02:21:17.491678] apply_controller > Starting run\n",
      "[2018-05-13 02:21:17.492959] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:21:17.667238] apply_controller > Done. Stopping robot. Value of run [29.742645]\n",
      "[2018-05-13 02:21:17.668747] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:21:17.670080] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:21:17.673257] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-13 02:21:17.674571] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:21:17.690588] target_dyn_opt > Initial loss [3.1626976211180633]\n",
      "\u001b[2K[2018-05-13 02:21:35.707009] target_dyn_opt > Curr loss: -8.884283E+00 [1598: -9.230457E+00], n_evals: 1999, Avg. time per updt: 0.007530\n",
      "[2018-05-13 02:21:35.720284] target_dyn_opt > Done training. New loss [-8.679915] iter: [2000]\n",
      "[2018-05-13 02:21:35.723122] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:21:35.724779] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_8.zip\n",
      "[2018-05-13 02:21:36.162273] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_8.zip\n",
      "[2018-05-13 02:21:36.265782] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_8.zip\n",
      "[2018-05-13 02:21:38.519923] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-13 02:21:38.524234] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:21:38.664419] SGDOptimizer > Initial loss [15.094633102416992]\n",
      "\u001b[2K[2018-05-13 02:23:30.806956] SGDOptimizer > Curr loss: 1.173439E+01, n_evals: 999, Avg. time per updt: 0.110844\n",
      "[2018-05-13 02:23:30.839041] SGDOptimizer > Done training. New loss [12.930125] iter: [999]\n",
      "[2018-05-13 02:23:30.840710] apply_controller > Starting run\n",
      "[2018-05-13 02:23:30.842157] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:23:31.028137] apply_controller > Done. Stopping robot. Value of run [29.893452]\n",
      "[2018-05-13 02:23:31.029341] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:23:31.030829] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:23:31.034004] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-13 02:23:31.035263] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:23:31.052323] target_dyn_opt > Initial loss [4.254737147586099]\n",
      "\u001b[2K[2018-05-13 02:23:49.775099] target_dyn_opt > Curr loss: -9.628063E+00 [1658: -9.943349E+00], n_evals: 1999, Avg. time per updt: 0.007857\n",
      "[2018-05-13 02:23:49.788645] target_dyn_opt > Done training. New loss [-9.336703] iter: [2000]\n",
      "[2018-05-13 02:23:49.791150] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:23:49.792557] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_9.zip\n",
      "[2018-05-13 02:23:50.269654] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_9.zip\n",
      "[2018-05-13 02:23:50.374411] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_9.zip\n",
      "[2018-05-13 02:23:52.653508] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-13 02:23:52.658448] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:23:52.820708] SGDOptimizer > Initial loss [11.315679550170898]\n",
      "\u001b[2K[2018-05-13 02:25:58.917906] SGDOptimizer > Curr loss: 7.565314E+00, n_evals: 999, Avg. time per updt: 0.124833\n",
      "[2018-05-13 02:25:58.958148] SGDOptimizer > Done training. New loss [8.060495] iter: [999]\n",
      "[2018-05-13 02:25:58.959838] apply_controller > Starting run\n",
      "[2018-05-13 02:25:58.961431] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:25:59.144137] apply_controller > Done. Stopping robot. Value of run [27.951101]\n",
      "[2018-05-13 02:25:59.145358] target_2x_mass > Stopping robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:25:59.146637] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:25:59.149789] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-13 02:25:59.151275] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:25:59.167647] target_dyn_opt > Initial loss [1.7783040894796853]\n",
      "\u001b[2K[2018-05-13 02:26:17.814538] target_dyn_opt > Curr loss: -9.717578E+00 [1697: -1.052650E+01], n_evals: 1999, Avg. time per updt: 0.007849\n",
      "[2018-05-13 02:26:17.830262] target_dyn_opt > Done training. New loss [-9.912127] iter: [2000]\n",
      "[2018-05-13 02:26:17.832899] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:26:17.834328] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_10.zip\n",
      "[2018-05-13 02:26:18.356811] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_10.zip\n",
      "[2018-05-13 02:26:18.463105] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_10.zip\n",
      "[2018-05-13 02:26:20.749694] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-13 02:26:20.755184] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:26:20.933040] SGDOptimizer > Initial loss [11.10164737701416]\n",
      "\u001b[2K[2018-05-13 02:28:29.843351] SGDOptimizer > Curr loss: 1.678301E+01, n_evals: 999, Avg. time per updt: 0.127642\n",
      "[2018-05-13 02:28:29.883624] SGDOptimizer > Done training. New loss [11.866898] iter: [999]\n",
      "[2018-05-13 02:28:29.885215] apply_controller > Starting run\n",
      "[2018-05-13 02:28:29.886708] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:28:30.062714] apply_controller > Done. Stopping robot. Value of run [28.980627]\n",
      "[2018-05-13 02:28:30.064679] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:28:30.066341] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:28:30.069499] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-13 02:28:30.070915] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:28:30.087920] target_dyn_opt > Initial loss [-4.916567062852026]\n",
      "\u001b[2K[2018-05-13 02:28:48.372902] target_dyn_opt > Curr loss: -1.086644E+01 [1862: -1.100912E+01], n_evals: 1999, Avg. time per updt: 0.007682\n",
      "[2018-05-13 02:28:48.386837] target_dyn_opt > Done training. New loss [-10.311645] iter: [2000]\n",
      "[2018-05-13 02:28:48.389647] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:28:48.391058] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_11.zip\n",
      "[2018-05-13 02:28:48.952023] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_11.zip\n",
      "[2018-05-13 02:28:49.058763] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_11.zip\n",
      "[2018-05-13 02:28:51.334282] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-13 02:28:51.339296] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:28:51.496479] SGDOptimizer > Initial loss [11.195140838623047]\n",
      "\u001b[2K[2018-05-13 02:30:51.758339] SGDOptimizer > Curr loss: 1.145468E+01, n_evals: 999, Avg. time per updt: 0.119002\n",
      "[2018-05-13 02:30:51.794242] SGDOptimizer > Done training. New loss [10.340618] iter: [999]\n",
      "[2018-05-13 02:30:51.795825] apply_controller > Starting run\n",
      "[2018-05-13 02:30:51.797114] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:30:51.976418] apply_controller > Done. Stopping robot. Value of run [27.191542]\n",
      "[2018-05-13 02:30:51.977852] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:30:51.979139] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:30:51.981969] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-13 02:30:51.983319] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:30:52.001330] target_dyn_opt > Initial loss [12.522482904657444]\n",
      "\u001b[2K[2018-05-13 02:31:10.745168] target_dyn_opt > Curr loss: -1.072469E+01 [1831: -1.128386E+01], n_evals: 1999, Avg. time per updt: 0.007889\n",
      "[2018-05-13 02:31:10.760062] target_dyn_opt > Done training. New loss [-10.739549] iter: [2000]\n",
      "[2018-05-13 02:31:10.762565] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:31:10.763790] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_12.zip\n",
      "[2018-05-13 02:31:11.411288] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_12.zip\n",
      "[2018-05-13 02:31:11.517419] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_12.zip\n",
      "[2018-05-13 02:31:13.800245] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-13 02:31:13.805191] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:31:13.954546] SGDOptimizer > Initial loss [7.18685245513916]\n",
      "\u001b[2K[2018-05-13 02:33:02.463564] SGDOptimizer > Curr loss: 1.252229E+01, n_evals: 999, Avg. time per updt: 0.107201\n",
      "[2018-05-13 02:33:02.495178] SGDOptimizer > Done training. New loss [9.924040] iter: [999]\n",
      "[2018-05-13 02:33:02.496953] apply_controller > Starting run\n",
      "[2018-05-13 02:33:02.498464] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:33:02.676801] apply_controller > Done. Stopping robot. Value of run [29.201084]\n",
      "[2018-05-13 02:33:02.678281] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:33:02.679725] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:33:02.683740] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-13 02:33:02.685198] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:33:02.702289] target_dyn_opt > Initial loss [-5.915189545583255]\n",
      "\u001b[2K[2018-05-13 02:33:20.998523] target_dyn_opt > Curr loss: -1.171215E+01 [1805: -1.185754E+01], n_evals: 1999, Avg. time per updt: 0.007678\n",
      "[2018-05-13 02:33:21.013957] target_dyn_opt > Done training. New loss [-11.185009] iter: [2000]\n",
      "[2018-05-13 02:33:21.016865] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:33:21.018681] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_13.zip\n",
      "[2018-05-13 02:33:21.670252] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_13.zip\n",
      "[2018-05-13 02:33:21.775950] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_13.zip\n",
      "[2018-05-13 02:33:24.065090] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-13 02:33:24.070664] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:33:24.213562] SGDOptimizer > Initial loss [9.20335865020752]\n",
      "\u001b[2K[2018-05-13 02:35:14.206061] SGDOptimizer > Curr loss: 9.015030E+00, n_evals: 999, Avg. time per updt: 0.108698\n",
      "[2018-05-13 02:35:14.236429] SGDOptimizer > Done training. New loss [10.143766] iter: [999]\n",
      "[2018-05-13 02:35:14.238096] apply_controller > Starting run\n",
      "[2018-05-13 02:35:14.239414] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:35:14.409467] apply_controller > Done. Stopping robot. Value of run [29.199059]\n",
      "[2018-05-13 02:35:14.410818] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:35:14.412176] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:35:14.415539] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-13 02:35:14.417488] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:35:14.432102] target_dyn_opt > Initial loss [-4.959348128307825]\n",
      "\u001b[2K[2018-05-13 02:35:32.654080] target_dyn_opt > Curr loss: -1.154854E+01 [1949: -1.201388E+01], n_evals: 1999, Avg. time per updt: 0.007654\n",
      "[2018-05-13 02:35:32.667627] target_dyn_opt > Done training. New loss [-11.330843] iter: [2000]\n",
      "[2018-05-13 02:35:32.670408] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:35:32.672117] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_14.zip\n",
      "[2018-05-13 02:35:33.353536] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:35:33.459636] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_14.zip\n",
      "[2018-05-13 02:35:35.742015] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-13 02:35:35.747278] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:35:35.895080] SGDOptimizer > Initial loss [9.228636741638184]\n",
      "\u001b[2K[2018-05-13 02:37:30.957785] SGDOptimizer > Curr loss: 1.190965E+01, n_evals: 999, Avg. time per updt: 0.113755\n",
      "[2018-05-13 02:37:30.989836] SGDOptimizer > Done training. New loss [12.381735] iter: [999]\n",
      "[2018-05-13 02:37:30.991492] apply_controller > Starting run\n",
      "[2018-05-13 02:37:30.992817] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:37:31.164462] apply_controller > Done. Stopping robot. Value of run [29.918121]\n",
      "[2018-05-13 02:37:31.166052] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:37:31.167365] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:37:31.170796] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-13 02:37:31.172039] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:37:31.186777] target_dyn_opt > Initial loss [-4.746639820650733]\n",
      "\u001b[2K[2018-05-13 02:37:49.773627] target_dyn_opt > Curr loss: -1.178309E+01 [1443: -1.237646E+01], n_evals: 1999, Avg. time per updt: 0.007825\n",
      "[2018-05-13 02:37:49.788701] target_dyn_opt > Done training. New loss [-11.491076] iter: [2000]\n",
      "[2018-05-13 02:37:49.791492] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:37:49.792913] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_15.zip\n",
      "[2018-05-13 02:37:50.522964] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_15.zip\n",
      "[2018-05-13 02:37:50.630066] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_15.zip\n",
      "[2018-05-13 02:37:52.929398] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-13 02:37:52.934642] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:37:53.101136] SGDOptimizer > Initial loss [14.222352027893066]\n",
      "\u001b[2K[2018-05-13 02:40:05.486687] SGDOptimizer > Curr loss: 1.467147E+01, n_evals: 999, Avg. time per updt: 0.131135\n",
      "[2018-05-13 02:40:05.528091] SGDOptimizer > Done training. New loss [16.449011] iter: [999]\n",
      "[2018-05-13 02:40:05.529773] apply_controller > Starting run\n",
      "[2018-05-13 02:40:05.531060] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:40:05.723370] apply_controller > Done. Stopping robot. Value of run [26.831116]\n",
      "[2018-05-13 02:40:05.724598] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:40:05.726037] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:40:05.729409] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-13 02:40:05.730792] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:40:05.745869] target_dyn_opt > Initial loss [-7.3897959470265295]\n",
      "\u001b[2K[2018-05-13 02:40:24.885847] target_dyn_opt > Curr loss: -1.196172E+01 [1851: -1.269531E+01], n_evals: 1999, Avg. time per updt: 0.008106\n",
      "[2018-05-13 02:40:24.900989] target_dyn_opt > Done training. New loss [-12.431940] iter: [2000]\n",
      "[2018-05-13 02:40:24.903777] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:40:24.905130] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_16.zip\n",
      "[2018-05-13 02:40:25.682501] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_16.zip\n",
      "[2018-05-13 02:40:25.791293] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_16.zip\n",
      "[2018-05-13 02:40:28.124149] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-13 02:40:28.129164] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:40:28.303618] SGDOptimizer > Initial loss [14.857303619384766]\n",
      "\u001b[2K[2018-05-13 02:42:42.416568] SGDOptimizer > Curr loss: 1.032373E+01, n_evals: 999, Avg. time per updt: 0.132843\n",
      "[2018-05-13 02:42:42.460032] SGDOptimizer > Done training. New loss [10.238872] iter: [999]\n",
      "[2018-05-13 02:42:42.461701] apply_controller > Starting run\n",
      "[2018-05-13 02:42:42.463453] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:42:42.639472] apply_controller > Done. Stopping robot. Value of run [29.428755]\n",
      "[2018-05-13 02:42:42.641125] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:42:42.642345] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:42:42.645805] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-13 02:42:42.647176] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:42:42.662533] target_dyn_opt > Initial loss [-6.89727059805987]\n",
      "\u001b[2K[2018-05-13 02:43:00.974397] target_dyn_opt > Curr loss: -1.272743E+01 [1968: -1.292928E+01], n_evals: 1999, Avg. time per updt: 0.007694\n",
      "[2018-05-13 02:43:00.988514] target_dyn_opt > Done training. New loss [-12.576276] iter: [2000]\n",
      "[2018-05-13 02:43:00.991157] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:43:00.993034] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_17.zip\n",
      "[2018-05-13 02:43:01.821165] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_17.zip\n",
      "[2018-05-13 02:43:01.929474] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_17.zip\n",
      "[2018-05-13 02:43:04.217009] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-13 02:43:04.222041] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:43:04.379364] SGDOptimizer > Initial loss [8.973072052001953]\n",
      "\u001b[2K[2018-05-13 02:44:56.150267] SGDOptimizer > Curr loss: 1.713324E+01, n_evals: 999, Avg. time per updt: 0.110493\n",
      "[2018-05-13 02:44:56.181820] SGDOptimizer > Done training. New loss [16.495609] iter: [999]\n",
      "[2018-05-13 02:44:56.183431] apply_controller > Starting run\n",
      "[2018-05-13 02:44:56.184738] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:44:56.359418] apply_controller > Done. Stopping robot. Value of run [29.845461]\n",
      "[2018-05-13 02:44:56.360746] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:44:56.362031] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:44:56.365590] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-13 02:44:56.367290] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:44:56.381429] target_dyn_opt > Initial loss [-7.57214329441749]\n",
      "\u001b[2K[2018-05-13 02:45:14.981944] target_dyn_opt > Curr loss: -1.258865E+01 [1843: -1.328263E+01], n_evals: 1999, Avg. time per updt: 0.007845\n",
      "[2018-05-13 02:45:14.998372] target_dyn_opt > Done training. New loss [-12.674802] iter: [2000]\n",
      "[2018-05-13 02:45:15.001067] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:45:15.002626] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_18.zip\n",
      "[2018-05-13 02:45:15.862952] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_18.zip\n",
      "[2018-05-13 02:45:15.971297] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_18.zip\n",
      "[2018-05-13 02:45:18.277067] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-13 02:45:18.282351] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:45:18.458853] SGDOptimizer > Initial loss [19.931177139282227]\n",
      "\u001b[2K[2018-05-13 02:47:29.723672] SGDOptimizer > Curr loss: 1.268808E+01, n_evals: 999, Avg. time per updt: 0.129989\n",
      "[2018-05-13 02:47:29.765675] SGDOptimizer > Done training. New loss [12.457440] iter: [999]\n",
      "[2018-05-13 02:47:29.767462] apply_controller > Starting run\n",
      "[2018-05-13 02:47:29.768882] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:47:30.010574] apply_controller > Done. Stopping robot. Value of run [26.872883]\n",
      "[2018-05-13 02:47:30.011921] target_2x_mass > Stopping robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:47:30.013383] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:47:30.018113] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-13 02:47:30.019708] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:47:30.035698] target_dyn_opt > Initial loss [-0.6191536333026555]\n",
      "\u001b[2K[2018-05-13 02:47:49.202387] target_dyn_opt > Curr loss: -1.317009E+01 [1620: -1.335932E+01], n_evals: 1999, Avg. time per updt: 0.008116\n",
      "[2018-05-13 02:47:49.216027] target_dyn_opt > Done training. New loss [-12.980149] iter: [2000]\n",
      "[2018-05-13 02:47:49.218791] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:47:49.220187] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_19.zip\n",
      "[2018-05-13 02:47:50.116493] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_19.zip\n",
      "[2018-05-13 02:47:50.226545] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_19.zip\n",
      "[2018-05-13 02:47:52.522972] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-13 02:47:52.528022] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:47:52.669679] SGDOptimizer > Initial loss [14.735199928283691]\n",
      "\u001b[2K[2018-05-13 02:49:44.799536] SGDOptimizer > Curr loss: 1.229997E+01, n_evals: 999, Avg. time per updt: 0.110847\n",
      "[2018-05-13 02:49:44.831489] SGDOptimizer > Done training. New loss [12.123354] iter: [999]\n",
      "[2018-05-13 02:49:44.833083] apply_controller > Starting run\n",
      "[2018-05-13 02:49:44.834376] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:49:45.014056] apply_controller > Done. Stopping robot. Value of run [29.968292]\n",
      "[2018-05-13 02:49:45.015274] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:49:45.016859] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:49:45.020902] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-13 02:49:45.022322] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:49:45.038465] target_dyn_opt > Initial loss [-3.0666935653326353]\n",
      "\u001b[2K[2018-05-13 02:50:03.231781] target_dyn_opt > Curr loss: -1.316393E+01 [1850: -1.370274E+01], n_evals: 1999, Avg. time per updt: 0.007644\n",
      "[2018-05-13 02:50:03.245278] target_dyn_opt > Done training. New loss [-13.300550] iter: [2000]\n",
      "[2018-05-13 02:50:03.248158] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:50:03.249659] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_20.zip\n",
      "[2018-05-13 02:50:04.185694] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_20.zip\n",
      "[2018-05-13 02:50:04.292715] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_20.zip\n",
      "[2018-05-13 02:50:06.575868] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-13 02:50:06.581475] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:50:06.726863] SGDOptimizer > Initial loss [11.59915828704834]\n",
      "\u001b[2K[2018-05-13 02:51:57.439993] SGDOptimizer > Curr loss: 1.356614E+01, n_evals: 999, Avg. time per updt: 0.109416\n",
      "[2018-05-13 02:51:57.472145] SGDOptimizer > Done training. New loss [14.945777] iter: [999]\n",
      "[2018-05-13 02:51:57.474405] apply_controller > Starting run\n",
      "[2018-05-13 02:51:57.475639] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:51:57.724637] apply_controller > Done. Stopping robot. Value of run [29.903624]\n",
      "[2018-05-13 02:51:57.726166] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:51:57.727622] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:51:57.732552] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-13 02:51:57.734279] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:51:57.751076] target_dyn_opt > Initial loss [-5.488629302821563]\n",
      "\u001b[2K[2018-05-13 02:52:15.896974] target_dyn_opt > Curr loss: -1.329488E+01 [1492: -1.384521E+01], n_evals: 1999, Avg. time per updt: 0.007620\n",
      "[2018-05-13 02:52:15.910343] target_dyn_opt > Done training. New loss [-13.514270] iter: [2000]\n",
      "[2018-05-13 02:52:15.913181] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:52:15.914592] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_21.zip\n",
      "[2018-05-13 02:52:16.894915] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_21.zip\n",
      "[2018-05-13 02:52:17.003037] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_21.zip\n",
      "[2018-05-13 02:52:19.290473] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-13 02:52:19.296200] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:52:19.435050] SGDOptimizer > Initial loss [13.562926292419434]\n",
      "\u001b[2K[2018-05-13 02:54:11.187836] SGDOptimizer > Curr loss: 1.392106E+01, n_evals: 999, Avg. time per updt: 0.110473\n",
      "[2018-05-13 02:54:11.222397] SGDOptimizer > Done training. New loss [10.670218] iter: [999]\n",
      "[2018-05-13 02:54:11.224078] apply_controller > Starting run\n",
      "[2018-05-13 02:54:11.225437] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:54:11.421993] apply_controller > Done. Stopping robot. Value of run [29.975624]\n",
      "[2018-05-13 02:54:11.423680] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:54:11.424905] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:54:11.429189] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-13 02:54:11.430443] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:54:11.446790] target_dyn_opt > Initial loss [23.917032329396328]\n",
      "\u001b[2K[2018-05-13 02:54:30.130860] target_dyn_opt > Curr loss: -1.347716E+01 [1968: -1.396818E+01], n_evals: 1999, Avg. time per updt: 0.007874\n",
      "[2018-05-13 02:54:30.145159] target_dyn_opt > Done training. New loss [-13.271728] iter: [2000]\n",
      "[2018-05-13 02:54:30.147926] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:54:30.149442] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_22.zip\n",
      "[2018-05-13 02:54:31.172779] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_22.zip\n",
      "[2018-05-13 02:54:31.281661] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_22.zip\n",
      "[2018-05-13 02:54:33.557049] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-13 02:54:33.562660] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:54:33.729568] SGDOptimizer > Initial loss [10.670767784118652]\n",
      "\u001b[2K[2018-05-13 02:56:31.098428] SGDOptimizer > Curr loss: 1.374258E+01, n_evals: 999, Avg. time per updt: 0.116093\n",
      "[2018-05-13 02:56:31.132078] SGDOptimizer > Done training. New loss [14.694958] iter: [999]\n",
      "[2018-05-13 02:56:31.133876] apply_controller > Starting run\n",
      "[2018-05-13 02:56:31.135167] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:56:31.322293] apply_controller > Done. Stopping robot. Value of run [29.942741]\n",
      "[2018-05-13 02:56:31.323861] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:56:31.325081] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:56:31.329639] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-13 02:56:31.330883] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:56:31.346217] target_dyn_opt > Initial loss [-9.006580753658694]\n",
      "\u001b[2K[2018-05-13 02:56:50.136700] target_dyn_opt > Curr loss: -1.330391E+01 [1456: -1.425023E+01], n_evals: 1999, Avg. time per updt: 0.007937\n",
      "[2018-05-13 02:56:50.151493] target_dyn_opt > Done training. New loss [-13.701574] iter: [2000]\n",
      "[2018-05-13 02:56:50.154350] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:56:50.155851] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_23.zip\n",
      "[2018-05-13 02:56:51.213113] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_23.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 02:56:51.322519] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_23.zip\n",
      "[2018-05-13 02:56:53.623256] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-13 02:56:53.628990] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:56:53.811266] SGDOptimizer > Initial loss [11.75406551361084]\n",
      "\u001b[2K[2018-05-13 02:59:06.853847] SGDOptimizer > Curr loss: 1.607053E+01, n_evals: 999, Avg. time per updt: 0.131792\n",
      "[2018-05-13 02:59:06.896371] SGDOptimizer > Done training. New loss [16.514425] iter: [999]\n",
      "[2018-05-13 02:59:06.898053] apply_controller > Starting run\n",
      "[2018-05-13 02:59:06.899574] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 02:59:07.102420] apply_controller > Done. Stopping robot. Value of run [25.759817]\n",
      "[2018-05-13 02:59:07.103756] target_2x_mass > Stopping robot\n",
      "[2018-05-13 02:59:07.105080] train_dynamics > Training dynamics model\n",
      "[2018-05-13 02:59:07.110182] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-13 02:59:07.111440] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 02:59:07.126910] target_dyn_opt > Initial loss [43.846264384450585]\n",
      "\u001b[2K[2018-05-13 02:59:26.021525] target_dyn_opt > Curr loss: -1.348318E+01 [1974: -1.418375E+01], n_evals: 1999, Avg. time per updt: 0.007988\n",
      "[2018-05-13 02:59:26.037873] target_dyn_opt > Done training. New loss [-13.031391] iter: [2000]\n",
      "[2018-05-13 02:59:26.040487] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 02:59:26.041901] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_24.zip\n",
      "[2018-05-13 02:59:27.164544] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_24.zip\n",
      "[2018-05-13 02:59:27.275635] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_24.zip\n",
      "[2018-05-13 02:59:29.588345] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-13 02:59:29.593685] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 02:59:29.778899] SGDOptimizer > Initial loss [20.712495803833008]\n",
      "\u001b[2K[2018-05-13 03:01:45.190655] SGDOptimizer > Curr loss: 1.265796E+01, n_evals: 999, Avg. time per updt: 0.134148\n",
      "[2018-05-13 03:01:45.233210] SGDOptimizer > Done training. New loss [12.727325] iter: [999]\n",
      "[2018-05-13 03:01:45.235211] apply_controller > Starting run\n",
      "[2018-05-13 03:01:45.236406] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:01:45.418217] apply_controller > Done. Stopping robot. Value of run [28.439215]\n",
      "[2018-05-13 03:01:45.419435] target_2x_mass > Stopping robot\n",
      "[2018-05-13 03:01:45.420737] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:01:45.425089] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-13 03:01:45.426492] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:01:45.442305] target_dyn_opt > Initial loss [-4.694019987823476]\n",
      "\u001b[2K[2018-05-13 03:02:04.311029] target_dyn_opt > Curr loss: -1.415189E+01 [1974: -1.440729E+01], n_evals: 1999, Avg. time per updt: 0.007970\n",
      "[2018-05-13 03:02:04.324463] target_dyn_opt > Done training. New loss [-13.573847] iter: [2000]\n",
      "[2018-05-13 03:02:04.327229] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:02:04.328558] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_25.zip\n",
      "[2018-05-13 03:02:05.475221] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_25.zip\n",
      "[2018-05-13 03:02:05.586326] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_25.zip\n",
      "[2018-05-13 03:02:07.880691] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-13 03:02:07.885770] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 03:02:08.028947] SGDOptimizer > Initial loss [12.244437217712402]\n",
      "\u001b[2K[2018-05-13 03:04:02.028350] SGDOptimizer > Curr loss: 1.043169E+01, n_evals: 999, Avg. time per updt: 0.112711\n",
      "[2018-05-13 03:04:02.060549] SGDOptimizer > Done training. New loss [10.985537] iter: [999]\n",
      "[2018-05-13 03:04:02.062116] apply_controller > Starting run\n",
      "[2018-05-13 03:04:02.063325] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:04:02.242877] apply_controller > Done. Stopping robot. Value of run [29.308914]\n",
      "[2018-05-13 03:04:02.244228] target_2x_mass > Stopping robot\n",
      "[2018-05-13 03:04:02.245733] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:04:02.250003] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-13 03:04:02.251431] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:04:02.266544] target_dyn_opt > Initial loss [-9.20414076454338]\n",
      "\u001b[2K[2018-05-13 03:04:20.651807] target_dyn_opt > Curr loss: -1.373459E+01 [1620: -1.450230E+01], n_evals: 1999, Avg. time per updt: 0.007715\n",
      "[2018-05-13 03:04:20.668550] target_dyn_opt > Done training. New loss [-14.081186] iter: [2000]\n",
      "[2018-05-13 03:04:20.671210] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:04:20.672679] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_26.zip\n",
      "[2018-05-13 03:04:21.859239] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_26.zip\n",
      "[2018-05-13 03:04:21.969352] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_26.zip\n",
      "[2018-05-13 03:04:24.260721] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-13 03:04:24.265699] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 03:04:24.410320] SGDOptimizer > Initial loss [10.218685150146484]\n",
      "\u001b[2K[2018-05-13 03:06:19.746251] SGDOptimizer > Curr loss: 9.759749E+00, n_evals: 999, Avg. time per updt: 0.114070\n",
      "[2018-05-13 03:06:19.778994] SGDOptimizer > Done training. New loss [9.573220] iter: [999]\n",
      "[2018-05-13 03:06:19.780562] apply_controller > Starting run\n",
      "[2018-05-13 03:06:19.781840] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:06:19.957673] apply_controller > Done. Stopping robot. Value of run [25.602497]\n",
      "[2018-05-13 03:06:19.959000] target_2x_mass > Stopping robot\n",
      "[2018-05-13 03:06:19.960291] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:06:19.965133] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-13 03:06:19.966409] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:06:19.983066] target_dyn_opt > Initial loss [-4.177402260048049]\n",
      "\u001b[2K[2018-05-13 03:06:38.276637] target_dyn_opt > Curr loss: -1.369111E+01 [1794: -1.474784E+01], n_evals: 1999, Avg. time per updt: 0.007695\n",
      "[2018-05-13 03:06:38.290818] target_dyn_opt > Done training. New loss [-14.088111] iter: [2000]\n",
      "[2018-05-13 03:06:38.293962] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:06:38.295621] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_27.zip\n",
      "[2018-05-13 03:06:39.539949] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_27.zip\n",
      "[2018-05-13 03:06:39.653891] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_27.zip\n",
      "[2018-05-13 03:06:41.963502] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-13 03:06:41.968491] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 03:06:42.126646] SGDOptimizer > Initial loss [12.656943321228027]\n",
      "\u001b[2K[2018-05-13 03:08:40.111088] SGDOptimizer > Curr loss: 3.642731E+01, n_evals: 999, Avg. time per updt: 0.116694\n",
      "[2018-05-13 03:08:40.146882] SGDOptimizer > Done training. New loss [39.649273] iter: [999]\n",
      "[2018-05-13 03:08:40.148659] apply_controller > Starting run\n",
      "[2018-05-13 03:08:40.150006] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:08:40.336612] apply_controller > Done. Stopping robot. Value of run [26.602074]\n",
      "[2018-05-13 03:08:40.337829] target_2x_mass > Stopping robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 03:08:40.340408] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:08:40.352196] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-13 03:08:40.353735] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:08:40.368548] target_dyn_opt > Initial loss [0.30490078873640014]\n",
      "\u001b[2K[2018-05-13 03:08:59.171728] target_dyn_opt > Curr loss: -1.364790E+01 [1857: -1.505479E+01], n_evals: 1999, Avg. time per updt: 0.007929\n",
      "[2018-05-13 03:08:59.186476] target_dyn_opt > Done training. New loss [-13.974410] iter: [2000]\n",
      "[2018-05-13 03:08:59.189134] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:08:59.190613] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_28.zip\n",
      "[2018-05-13 03:09:00.469477] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_28.zip\n",
      "[2018-05-13 03:09:00.582215] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_28.zip\n",
      "[2018-05-13 03:09:02.896530] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-13 03:09:02.901565] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 03:09:03.074250] SGDOptimizer > Initial loss [34.872257232666016]\n",
      "\u001b[2K[2018-05-13 03:11:13.402976] SGDOptimizer > Curr loss: 4.151625E+01, n_evals: 999, Avg. time per updt: 0.129047\n",
      "[2018-05-13 03:11:13.443449] SGDOptimizer > Done training. New loss [41.027790] iter: [999]\n",
      "[2018-05-13 03:11:13.445162] apply_controller > Starting run\n",
      "[2018-05-13 03:11:13.446645] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:11:13.647718] apply_controller > Done. Stopping robot. Value of run [25.375677]\n",
      "[2018-05-13 03:11:13.649182] target_2x_mass > Stopping robot\n",
      "[2018-05-13 03:11:13.650460] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:11:13.655302] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-13 03:11:13.656712] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:11:13.672037] target_dyn_opt > Initial loss [14.26135353905031]\n",
      "\u001b[2K[2018-05-13 03:11:32.697342] target_dyn_opt > Curr loss: -1.420063E+01 [1638: -1.472582E+01], n_evals: 1999, Avg. time per updt: 0.008061\n",
      "[2018-05-13 03:11:32.712924] target_dyn_opt > Done training. New loss [-14.018077] iter: [2000]\n",
      "[2018-05-13 03:11:32.717043] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:11:32.718848] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_29.zip\n",
      "[2018-05-13 03:11:34.026867] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_29.zip\n",
      "[2018-05-13 03:11:34.144461] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_29.zip\n",
      "[2018-05-13 03:11:36.455187] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-13 03:11:36.460235] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 03:11:36.636471] SGDOptimizer > Initial loss [34.769569396972656]\n",
      "\u001b[2K[2018-05-13 03:13:51.794377] SGDOptimizer > Curr loss: 9.248446E+00, n_evals: 999, Avg. time per updt: 0.133886\n",
      "[2018-05-13 03:13:51.836744] SGDOptimizer > Done training. New loss [8.671390] iter: [999]\n",
      "[2018-05-13 03:13:51.838379] apply_controller > Starting run\n",
      "[2018-05-13 03:13:51.839662] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 03:13:52.024260] apply_controller > Done. Stopping robot. Value of run [23.722769]\n",
      "[2018-05-13 03:13:52.025938] target_2x_mass > Stopping robot\n",
      "[2018-05-13 03:13:52.027161] train_dynamics > Training dynamics model\n",
      "[2018-05-13 03:13:52.032409] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-13 03:13:52.033774] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 03:13:52.049578] target_dyn_opt > Initial loss [-3.7975561620130955]\n",
      "\u001b[2K[2018-05-13 03:14:10.620732] target_dyn_opt > Curr loss: -1.420358E+01 [682: -1.479163E+01], n_evals: 1999, Avg. time per updt: 0.007818\n",
      "[2018-05-13 03:14:10.633863] target_dyn_opt > Done training. New loss [-14.618777] iter: [2000]\n",
      "[2018-05-13 03:14:10.636634] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 03:14:10.638020] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/experience_30.zip\n",
      "[2018-05-13 03:14:11.997949] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/policy_30.zip\n",
      "[2018-05-13 03:14:12.110951] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_009_taskplusil_klqp_from_source/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 9 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_009_taskplusil_klqp_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-3], loss_type=utils.ImitationLossType.KLQP)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 09:45:18.416468] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 09:45:18.440944] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f40e52cb050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 09:45:18.471365] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-13 09:45:18.493369] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f40e52cb050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-13 09:45:18.522110] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 09:45:18.535352] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f40e52cb050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 09:45:18.539965] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-13 09:45:18.553667] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f40e52c3b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f40e52cb050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-13 09:45:18.558255] Experience > Initialising new experience dataset\n",
      "[2018-05-13 09:45:18.559686] Executing uniformly-random controls\n",
      "[2018-05-13 09:45:18.561052] apply_controller > Starting run\n",
      "[2018-05-13 09:45:18.562282] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:45:18.726999] apply_controller > Done. Stopping robot. Value of run [29.994606]\n",
      "[2018-05-13 09:45:18.728230] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:45:18.729604] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:45:18.732234] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-13 09:45:18.733565] target_dyn > Initialising loss function\n",
      "[2018-05-13 09:45:18.879564] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-13 09:45:19.187741] target_dyn_opt > No gradient clipping\n",
      "[2018-05-13 09:45:19.188989] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-13 09:45:19.250534] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-13 09:45:20.141036] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-13 09:45:25.108130] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:45:25.114841] target_dyn_opt > Initial loss [7107.761660217211]\n",
      "\u001b[2K[2018-05-13 09:45:35.439779] target_dyn_opt > Curr loss: 4.329536E+01 [1921: 4.197228E+01], n_evals: 1999, Avg. time per updt: 0.003544\n",
      "[2018-05-13 09:45:35.447036] target_dyn_opt > Done training. New loss [44.969221] iter: [2000]\n",
      "[2018-05-13 09:45:35.673372] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:45:35.865285] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 09:45:35.866727] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 09:45:35.948715] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 09:45:35.950697] mc_pilco.rollout > Moment-matching [state: True, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 09:45:36.505327] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-13 09:45:36.506579] mc_pilco.rollout > CRNs will be resampled every 500 rollouts\n",
      "[2018-05-13 09:45:36.590490] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-13 09:45:36.591728] mc_pilco.rollout > Moment-matching [state: False, cost:True], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-13 09:45:41.483029] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-13 09:45:42.739468] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-13 09:45:42.749694] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-13 09:45:42.781296] SGDOptimizer > Compiling function for loss\n",
      "[2018-05-13 09:45:45.942432] SGDOptimizer > Compiling parameter updates\n",
      "[2018-05-13 09:46:04.277349] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_0.zip\n",
      "[2018-05-13 09:46:04.375236] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_0.zip\n",
      "[2018-05-13 09:46:04.473498] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_0.zip\n",
      "[2018-05-13 09:46:04.612546] experiment_utils > using common random numbers for dyn and pol\n",
      "[2018-05-13 09:46:04.614101] ==== Iteration [1], experience: [30 steps] ====\n",
      "[2018-05-13 09:46:04.618362] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:46:04.771301] SGDOptimizer > Initial loss [1.0011314153671265]\n",
      "\u001b[2K[2018-05-13 09:47:57.882914] SGDOptimizer > Curr loss: 8.181612E-01, n_evals: 999, Avg. time per updt: 0.111719\n",
      "[2018-05-13 09:47:57.911918] SGDOptimizer > Done training. New loss [0.890490] iter: [999]\n",
      "[2018-05-13 09:47:57.913702] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-13 09:47:57.991828] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-13 09:47:58.144957] NNPolicy > Done compiling\n",
      "[2018-05-13 09:47:58.146554] apply_controller > Starting run\n",
      "[2018-05-13 09:47:58.147755] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:47:58.337684] apply_controller > Done. Stopping robot. Value of run [26.919832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 09:47:58.339273] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:47:58.340557] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:47:58.342465] train_dynamics > Dataset size:: Inputs: [ (58, 6) ], Targets: [ (58, 4) ] \n",
      "[2018-05-13 09:47:58.343724] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:47:58.353838] target_dyn_opt > Initial loss [176.71504588733458]\n",
      "\u001b[2K[2018-05-13 09:48:11.148741] target_dyn_opt > Curr loss: 1.603806E+01 [1984: 1.563805E+01], n_evals: 1999, Avg. time per updt: 0.004894\n",
      "[2018-05-13 09:48:11.158999] target_dyn_opt > Done training. New loss [15.988953] iter: [2000]\n",
      "[2018-05-13 09:48:11.161598] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:48:11.163007] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_1.zip\n",
      "[2018-05-13 09:48:11.305424] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_1.zip\n",
      "[2018-05-13 09:48:11.404667] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_1.zip\n",
      "[2018-05-13 09:48:13.492786] ==== Iteration [2], experience: [60 steps] ====\n",
      "[2018-05-13 09:48:13.497754] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:48:13.636966] SGDOptimizer > Initial loss [0.9525135159492493]\n",
      "\u001b[2K[2018-05-13 09:50:12.604182] SGDOptimizer > Curr loss: 9.215142E-01, n_evals: 999, Avg. time per updt: 0.117560\n",
      "[2018-05-13 09:50:12.630607] SGDOptimizer > Done training. New loss [0.922749] iter: [999]\n",
      "[2018-05-13 09:50:12.632299] apply_controller > Starting run\n",
      "[2018-05-13 09:50:12.633485] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:50:12.830517] apply_controller > Done. Stopping robot. Value of run [26.945299]\n",
      "[2018-05-13 09:50:12.831749] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:50:12.833205] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:50:12.835295] train_dynamics > Dataset size:: Inputs: [ (87, 6) ], Targets: [ (87, 4) ] \n",
      "[2018-05-13 09:50:12.836535] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:50:12.848749] target_dyn_opt > Initial loss [45.4419816790641]\n",
      "\u001b[2K[2018-05-13 09:50:29.369163] target_dyn_opt > Curr loss: 6.309267E+00 [1921: 6.041127E+00], n_evals: 1999, Avg. time per updt: 0.006704\n",
      "[2018-05-13 09:50:29.380930] target_dyn_opt > Done training. New loss [6.143954] iter: [2000]\n",
      "[2018-05-13 09:50:29.383707] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:50:29.385171] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_2.zip\n",
      "[2018-05-13 09:50:29.573651] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_2.zip\n",
      "[2018-05-13 09:50:29.677044] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_2.zip\n",
      "[2018-05-13 09:50:31.643893] ==== Iteration [3], experience: [90 steps] ====\n",
      "[2018-05-13 09:50:31.649419] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:50:31.795225] SGDOptimizer > Initial loss [0.9225912094116211]\n",
      "\u001b[2K[2018-05-13 09:52:11.206211] SGDOptimizer > Curr loss: 8.562676E-01, n_evals: 999, Avg. time per updt: 0.098123\n",
      "[2018-05-13 09:52:11.236121] SGDOptimizer > Done training. New loss [0.833939] iter: [999]\n",
      "[2018-05-13 09:52:11.238082] apply_controller > Starting run\n",
      "[2018-05-13 09:52:11.239456] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:52:11.416315] apply_controller > Done. Stopping robot. Value of run [27.718155]\n",
      "[2018-05-13 09:52:11.417555] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:52:11.418854] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:52:11.421652] train_dynamics > Dataset size:: Inputs: [ (116, 6) ], Targets: [ (116, 4) ] \n",
      "[2018-05-13 09:52:11.422953] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:52:11.438512] target_dyn_opt > Initial loss [9.798439795087123]\n",
      "\u001b[2K[2018-05-13 09:52:29.424854] target_dyn_opt > Curr loss: 8.442862E-01 [1954: 4.744334E-01], n_evals: 1999, Avg. time per updt: 0.007447\n",
      "[2018-05-13 09:52:29.438550] target_dyn_opt > Done training. New loss [0.874937] iter: [2000]\n",
      "[2018-05-13 09:52:29.441155] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:52:29.442796] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_3.zip\n",
      "[2018-05-13 09:52:29.678082] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_3.zip\n",
      "[2018-05-13 09:52:29.779749] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_3.zip\n",
      "[2018-05-13 09:52:31.706832] ==== Iteration [4], experience: [120 steps] ====\n",
      "[2018-05-13 09:52:31.711696] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:52:31.838837] SGDOptimizer > Initial loss [0.9264665246009827]\n",
      "\u001b[2K[2018-05-13 09:54:10.425326] SGDOptimizer > Curr loss: 8.667809E-01, n_evals: 999, Avg. time per updt: 0.097280\n",
      "[2018-05-13 09:54:10.451032] SGDOptimizer > Done training. New loss [0.863885] iter: [999]\n",
      "[2018-05-13 09:54:10.452808] apply_controller > Starting run\n",
      "[2018-05-13 09:54:10.454120] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:54:10.629766] apply_controller > Done. Stopping robot. Value of run [26.719683]\n",
      "[2018-05-13 09:54:10.630983] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:54:10.632481] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:54:10.634785] train_dynamics > Dataset size:: Inputs: [ (145, 6) ], Targets: [ (145, 4) ] \n",
      "[2018-05-13 09:54:10.636016] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:54:10.651071] target_dyn_opt > Initial loss [8.055043770321484]\n",
      "\u001b[2K[2018-05-13 09:54:28.658225] target_dyn_opt > Curr loss: -2.492884E+00 [1945: -2.663509E+00], n_evals: 1999, Avg. time per updt: 0.007438\n",
      "[2018-05-13 09:54:28.671727] target_dyn_opt > Done training. New loss [-2.340780] iter: [2000]\n",
      "[2018-05-13 09:54:28.674506] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:54:28.675960] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_4.zip\n",
      "[2018-05-13 09:54:28.946086] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_4.zip\n",
      "[2018-05-13 09:54:29.047134] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_4.zip\n",
      "[2018-05-13 09:54:30.990039] ==== Iteration [5], experience: [150 steps] ====\n",
      "[2018-05-13 09:54:30.994843] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:54:31.132559] SGDOptimizer > Initial loss [0.8667079210281372]\n",
      "\u001b[2K[2018-05-13 09:56:07.436165] SGDOptimizer > Curr loss: 8.784366E-01, n_evals: 999, Avg. time per updt: 0.094995\n",
      "[2018-05-13 09:56:07.465813] SGDOptimizer > Done training. New loss [0.868767] iter: [999]\n",
      "[2018-05-13 09:56:07.467833] apply_controller > Starting run\n",
      "[2018-05-13 09:56:07.468775] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:56:07.655868] apply_controller > Done. Stopping robot. Value of run [23.333555]\n",
      "[2018-05-13 09:56:07.657217] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:56:07.658281] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:56:07.660943] train_dynamics > Dataset size:: Inputs: [ (174, 6) ], Targets: [ (174, 4) ] \n",
      "[2018-05-13 09:56:07.662958] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:56:07.676407] target_dyn_opt > Initial loss [15.869614332571796]\n",
      "\u001b[2K[2018-05-13 09:56:26.039640] target_dyn_opt > Curr loss: -4.559182E+00 [1953: -4.736077E+00], n_evals: 1999, Avg. time per updt: 0.007608\n",
      "[2018-05-13 09:56:26.053589] target_dyn_opt > Done training. New loss [-3.934262] iter: [2000]\n",
      "[2018-05-13 09:56:26.056163] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:56:26.057476] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 09:56:26.371022] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_5.zip\n",
      "[2018-05-13 09:56:26.472094] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_5.zip\n",
      "[2018-05-13 09:56:28.409091] ==== Iteration [6], experience: [180 steps] ====\n",
      "[2018-05-13 09:56:28.414099] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:56:28.565375] SGDOptimizer > Initial loss [0.9112875461578369]\n",
      "\u001b[2K[2018-05-13 09:58:04.290138] SGDOptimizer > Curr loss: 7.850891E-01, n_evals: 999, Avg. time per updt: 0.094420\n",
      "[2018-05-13 09:58:04.317262] SGDOptimizer > Done training. New loss [0.757923] iter: [999]\n",
      "[2018-05-13 09:58:04.319105] apply_controller > Starting run\n",
      "[2018-05-13 09:58:04.320638] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:58:04.520581] apply_controller > Done. Stopping robot. Value of run [22.754665]\n",
      "[2018-05-13 09:58:04.521949] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:58:04.523392] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:58:04.526262] train_dynamics > Dataset size:: Inputs: [ (203, 6) ], Targets: [ (203, 4) ] \n",
      "[2018-05-13 09:58:04.527794] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:58:04.541470] target_dyn_opt > Initial loss [5.022512465421789]\n",
      "\u001b[2K[2018-05-13 09:58:22.050356] target_dyn_opt > Curr loss: -5.341547E+00 [1735: -6.217438E+00], n_evals: 1999, Avg. time per updt: 0.007266\n",
      "[2018-05-13 09:58:22.062796] target_dyn_opt > Done training. New loss [-5.935802] iter: [2000]\n",
      "[2018-05-13 09:58:22.065652] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 09:58:22.067231] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_6.zip\n",
      "[2018-05-13 09:58:22.422444] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_6.zip\n",
      "[2018-05-13 09:58:22.524155] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_6.zip\n",
      "[2018-05-13 09:58:24.454429] ==== Iteration [7], experience: [210 steps] ====\n",
      "[2018-05-13 09:58:24.459594] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 09:58:24.579930] SGDOptimizer > Initial loss [0.8931645154953003]\n",
      "\u001b[2K[2018-05-13 09:59:59.384399] SGDOptimizer > Curr loss: 8.999938E-01, n_evals: 999, Avg. time per updt: 0.093491\n",
      "[2018-05-13 09:59:59.412727] SGDOptimizer > Done training. New loss [0.905584] iter: [999]\n",
      "[2018-05-13 09:59:59.414505] apply_controller > Starting run\n",
      "[2018-05-13 09:59:59.415846] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 09:59:59.660481] apply_controller > Done. Stopping robot. Value of run [27.034922]\n",
      "[2018-05-13 09:59:59.661992] target_2x_mass > Stopping robot\n",
      "[2018-05-13 09:59:59.663325] train_dynamics > Training dynamics model\n",
      "[2018-05-13 09:59:59.666168] train_dynamics > Dataset size:: Inputs: [ (232, 6) ], Targets: [ (232, 4) ] \n",
      "[2018-05-13 09:59:59.667716] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 09:59:59.683724] target_dyn_opt > Initial loss [-0.939388718584488]\n",
      "\u001b[2K[2018-05-13 10:00:17.276493] target_dyn_opt > Curr loss: -7.289693E+00 [1744: -7.538304E+00], n_evals: 1999, Avg. time per updt: 0.007312\n",
      "[2018-05-13 10:00:17.290893] target_dyn_opt > Done training. New loss [-6.658276] iter: [2000]\n",
      "[2018-05-13 10:00:17.293798] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:00:17.295179] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_7.zip\n",
      "[2018-05-13 10:00:17.692940] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_7.zip\n",
      "[2018-05-13 10:00:17.793978] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_7.zip\n",
      "[2018-05-13 10:00:19.729083] ==== Iteration [8], experience: [240 steps] ====\n",
      "[2018-05-13 10:00:19.733972] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:00:19.877022] SGDOptimizer > Initial loss [0.8998163342475891]\n",
      "\u001b[2K[2018-05-13 10:01:55.745310] SGDOptimizer > Curr loss: 6.495618E-01, n_evals: 999, Avg. time per updt: 0.094583\n",
      "[2018-05-13 10:01:55.772265] SGDOptimizer > Done training. New loss [0.642751] iter: [999]\n",
      "[2018-05-13 10:01:55.774542] apply_controller > Starting run\n",
      "[2018-05-13 10:01:55.775908] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:01:55.950397] apply_controller > Done. Stopping robot. Value of run [16.371456]\n",
      "[2018-05-13 10:01:55.952012] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:01:55.953331] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:01:55.956123] train_dynamics > Dataset size:: Inputs: [ (261, 6) ], Targets: [ (261, 4) ] \n",
      "[2018-05-13 10:01:55.957544] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:01:55.971022] target_dyn_opt > Initial loss [-2.9511987811304143]\n",
      "\u001b[2K[2018-05-13 10:02:13.468409] target_dyn_opt > Curr loss: -7.846043E+00 [1263: -8.426779E+00], n_evals: 1999, Avg. time per updt: 0.007263\n",
      "[2018-05-13 10:02:13.482095] target_dyn_opt > Done training. New loss [-7.908964] iter: [2000]\n",
      "[2018-05-13 10:02:13.484570] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:02:13.485952] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_8.zip\n",
      "[2018-05-13 10:02:13.924607] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_8.zip\n",
      "[2018-05-13 10:02:14.025699] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_8.zip\n",
      "[2018-05-13 10:02:15.965111] ==== Iteration [9], experience: [270 steps] ====\n",
      "[2018-05-13 10:02:15.970138] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:02:16.097812] SGDOptimizer > Initial loss [0.8202219605445862]\n",
      "\u001b[2K[2018-05-13 10:03:53.709998] SGDOptimizer > Curr loss: 7.016770E-01, n_evals: 999, Avg. time per updt: 0.096324\n",
      "[2018-05-13 10:03:53.739285] SGDOptimizer > Done training. New loss [0.643076] iter: [999]\n",
      "[2018-05-13 10:03:53.741045] apply_controller > Starting run\n",
      "[2018-05-13 10:03:53.742351] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:03:53.929879] apply_controller > Done. Stopping robot. Value of run [18.148985]\n",
      "[2018-05-13 10:03:53.931638] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:03:53.933084] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:03:53.935764] train_dynamics > Dataset size:: Inputs: [ (290, 6) ], Targets: [ (290, 4) ] \n",
      "[2018-05-13 10:03:53.937130] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:03:53.951493] target_dyn_opt > Initial loss [-3.1171286100971285]\n",
      "\u001b[2K[2018-05-13 10:04:12.094770] target_dyn_opt > Curr loss: -8.617007E+00 [1144: -9.162482E+00], n_evals: 1999, Avg. time per updt: 0.007563\n",
      "[2018-05-13 10:04:12.109540] target_dyn_opt > Done training. New loss [-8.725244] iter: [2000]\n",
      "[2018-05-13 10:04:12.112520] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:04:12.113895] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_9.zip\n",
      "[2018-05-13 10:04:12.590980] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_9.zip\n",
      "[2018-05-13 10:04:12.693104] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_9.zip\n",
      "[2018-05-13 10:04:14.630480] ==== Iteration [10], experience: [300 steps] ====\n",
      "[2018-05-13 10:04:14.635395] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:04:14.781370] SGDOptimizer > Initial loss [0.8488112092018127]\n",
      "\u001b[2K[2018-05-13 10:05:55.111602] SGDOptimizer > Curr loss: 8.510889E-01, n_evals: 999, Avg. time per updt: 0.099044\n",
      "[2018-05-13 10:05:55.146132] SGDOptimizer > Done training. New loss [0.821184] iter: [999]\n",
      "[2018-05-13 10:05:55.147857] apply_controller > Starting run\n",
      "[2018-05-13 10:05:55.149290] apply_controller > Running for 3.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 10:05:55.412180] apply_controller > Done. Stopping robot. Value of run [22.255943]\n",
      "[2018-05-13 10:05:55.413563] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:05:55.414877] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:05:55.418552] train_dynamics > Dataset size:: Inputs: [ (319, 6) ], Targets: [ (319, 4) ] \n",
      "[2018-05-13 10:05:55.420472] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:05:55.438769] target_dyn_opt > Initial loss [-2.633302568922222]\n",
      "\u001b[2K[2018-05-13 10:06:13.402036] target_dyn_opt > Curr loss: -9.429442E+00 [1737: -9.840206E+00], n_evals: 1999, Avg. time per updt: 0.007506\n",
      "[2018-05-13 10:06:13.415251] target_dyn_opt > Done training. New loss [-9.204387] iter: [2000]\n",
      "[2018-05-13 10:06:13.418096] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:06:13.419633] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_10.zip\n",
      "[2018-05-13 10:06:13.943811] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_10.zip\n",
      "[2018-05-13 10:06:14.047877] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_10.zip\n",
      "[2018-05-13 10:06:16.001797] ==== Iteration [11], experience: [330 steps] ====\n",
      "[2018-05-13 10:06:16.007302] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:06:16.157963] SGDOptimizer > Initial loss [0.871311604976654]\n",
      "\u001b[2K[2018-05-13 10:07:58.842490] SGDOptimizer > Curr loss: 6.118595E-01, n_evals: 999, Avg. time per updt: 0.101368\n",
      "[2018-05-13 10:07:58.871990] SGDOptimizer > Done training. New loss [0.605745] iter: [999]\n",
      "[2018-05-13 10:07:58.873999] apply_controller > Starting run\n",
      "[2018-05-13 10:07:58.875380] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:07:59.068182] apply_controller > Done. Stopping robot. Value of run [19.482048]\n",
      "[2018-05-13 10:07:59.069427] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:07:59.070642] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:07:59.074264] train_dynamics > Dataset size:: Inputs: [ (348, 6) ], Targets: [ (348, 4) ] \n",
      "[2018-05-13 10:07:59.075599] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:07:59.089376] target_dyn_opt > Initial loss [-5.64520074341489]\n",
      "\u001b[2K[2018-05-13 10:08:17.327464] target_dyn_opt > Curr loss: -9.476042E+00 [1125: -1.034310E+01], n_evals: 1999, Avg. time per updt: 0.007630\n",
      "[2018-05-13 10:08:17.343132] target_dyn_opt > Done training. New loss [-10.179755] iter: [2000]\n",
      "[2018-05-13 10:08:17.345708] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:08:17.347074] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_11.zip\n",
      "[2018-05-13 10:08:17.911386] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_11.zip\n",
      "[2018-05-13 10:08:18.013350] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_11.zip\n",
      "[2018-05-13 10:08:19.968160] ==== Iteration [12], experience: [360 steps] ====\n",
      "[2018-05-13 10:08:19.973820] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:08:20.109702] SGDOptimizer > Initial loss [0.7469409704208374]\n",
      "\u001b[2K[2018-05-13 10:10:06.646458] SGDOptimizer > Curr loss: 6.004489E-01, n_evals: 999, Avg. time per updt: 0.105232\n",
      "[2018-05-13 10:10:06.676966] SGDOptimizer > Done training. New loss [0.598247] iter: [999]\n",
      "[2018-05-13 10:10:06.678653] apply_controller > Starting run\n",
      "[2018-05-13 10:10:06.679971] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:10:06.868991] apply_controller > Done. Stopping robot. Value of run [15.868186]\n",
      "[2018-05-13 10:10:06.870533] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:10:06.871754] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:10:06.875609] train_dynamics > Dataset size:: Inputs: [ (377, 6) ], Targets: [ (377, 4) ] \n",
      "[2018-05-13 10:10:06.876975] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:10:06.892148] target_dyn_opt > Initial loss [-5.686720450218539]\n",
      "\u001b[2K[2018-05-13 10:10:24.977280] target_dyn_opt > Curr loss: -1.013536E+01 [1763: -1.089655E+01], n_evals: 1999, Avg. time per updt: 0.007565\n",
      "[2018-05-13 10:10:24.993880] target_dyn_opt > Done training. New loss [-10.456516] iter: [2000]\n",
      "[2018-05-13 10:10:24.996540] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:10:24.998924] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_12.zip\n",
      "[2018-05-13 10:10:25.604465] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_12.zip\n",
      "[2018-05-13 10:10:25.708379] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_12.zip\n",
      "[2018-05-13 10:10:27.664475] ==== Iteration [13], experience: [390 steps] ====\n",
      "[2018-05-13 10:10:27.669884] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:10:27.805964] SGDOptimizer > Initial loss [0.6257623434066772]\n",
      "\u001b[2K[2018-05-13 10:12:14.868682] SGDOptimizer > Curr loss: 5.779437E-01, n_evals: 999, Avg. time per updt: 0.105774\n",
      "[2018-05-13 10:12:14.906573] SGDOptimizer > Done training. New loss [0.584851] iter: [999]\n",
      "[2018-05-13 10:12:14.908402] apply_controller > Starting run\n",
      "[2018-05-13 10:12:14.909728] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:12:15.098784] apply_controller > Done. Stopping robot. Value of run [19.375355]\n",
      "[2018-05-13 10:12:15.100220] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:12:15.101462] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:12:15.104836] train_dynamics > Dataset size:: Inputs: [ (406, 6) ], Targets: [ (406, 4) ] \n",
      "[2018-05-13 10:12:15.106737] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:12:15.120871] target_dyn_opt > Initial loss [-0.26419993853334134]\n",
      "\u001b[2K[2018-05-13 10:12:33.295380] target_dyn_opt > Curr loss: -1.044346E+01 [1897: -1.118703E+01], n_evals: 1999, Avg. time per updt: 0.007612\n",
      "[2018-05-13 10:12:33.308850] target_dyn_opt > Done training. New loss [-10.562952] iter: [2000]\n",
      "[2018-05-13 10:12:33.311351] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:12:33.312771] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_13.zip\n",
      "[2018-05-13 10:12:33.959721] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_13.zip\n",
      "[2018-05-13 10:12:34.064152] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_13.zip\n",
      "[2018-05-13 10:12:36.037337] ==== Iteration [14], experience: [420 steps] ====\n",
      "[2018-05-13 10:12:36.043009] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:12:36.202786] SGDOptimizer > Initial loss [0.6590556502342224]\n",
      "\u001b[2K[2018-05-13 10:14:23.502125] SGDOptimizer > Curr loss: 5.907305E-01, n_evals: 999, Avg. time per updt: 0.105990\n",
      "[2018-05-13 10:14:23.533170] SGDOptimizer > Done training. New loss [0.587964] iter: [999]\n",
      "[2018-05-13 10:14:23.535238] apply_controller > Starting run\n",
      "[2018-05-13 10:14:23.536644] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:14:23.716270] apply_controller > Done. Stopping robot. Value of run [28.141361]\n",
      "[2018-05-13 10:14:23.717508] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:14:23.718758] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:14:23.722675] train_dynamics > Dataset size:: Inputs: [ (435, 6) ], Targets: [ (435, 4) ] \n",
      "[2018-05-13 10:14:23.724077] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:14:23.739833] target_dyn_opt > Initial loss [-1.1100542058889893]\n",
      "\u001b[2K[2018-05-13 10:14:42.001181] target_dyn_opt > Curr loss: -1.113303E+01 [1421: -1.148154E+01], n_evals: 1999, Avg. time per updt: 0.007652\n",
      "[2018-05-13 10:14:42.014423] target_dyn_opt > Done training. New loss [-11.119625] iter: [2000]\n",
      "[2018-05-13 10:14:42.017161] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:14:42.018652] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_14.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 10:14:42.711111] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_14.zip\n",
      "[2018-05-13 10:14:42.820130] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_14.zip\n",
      "[2018-05-13 10:14:44.774098] ==== Iteration [15], experience: [450 steps] ====\n",
      "[2018-05-13 10:14:44.779708] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:14:44.935457] SGDOptimizer > Initial loss [0.7014590501785278]\n",
      "\u001b[2K[2018-05-13 10:16:32.222571] SGDOptimizer > Curr loss: 6.442209E-01, n_evals: 999, Avg. time per updt: 0.105984\n",
      "[2018-05-13 10:16:32.255041] SGDOptimizer > Done training. New loss [0.581761] iter: [999]\n",
      "[2018-05-13 10:16:32.256627] apply_controller > Starting run\n",
      "[2018-05-13 10:16:32.258104] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:16:32.430895] apply_controller > Done. Stopping robot. Value of run [15.190462]\n",
      "[2018-05-13 10:16:32.433262] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:16:32.434722] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:16:32.438643] train_dynamics > Dataset size:: Inputs: [ (464, 6) ], Targets: [ (464, 4) ] \n",
      "[2018-05-13 10:16:32.440005] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:16:32.456117] target_dyn_opt > Initial loss [-6.5385231692986245]\n",
      "\u001b[2K[2018-05-13 10:16:50.694558] target_dyn_opt > Curr loss: -1.150674E+01 [1779: -1.199587E+01], n_evals: 1999, Avg. time per updt: 0.007631\n",
      "[2018-05-13 10:16:50.710137] target_dyn_opt > Done training. New loss [-11.752917] iter: [2000]\n",
      "[2018-05-13 10:16:50.712795] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:16:50.714517] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_15.zip\n",
      "[2018-05-13 10:16:51.447668] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_15.zip\n",
      "[2018-05-13 10:16:51.553421] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_15.zip\n",
      "[2018-05-13 10:16:53.512612] ==== Iteration [16], experience: [480 steps] ====\n",
      "[2018-05-13 10:16:53.518253] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:16:53.662975] SGDOptimizer > Initial loss [0.7273836135864258]\n",
      "\u001b[2K[2018-05-13 10:18:41.593446] SGDOptimizer > Curr loss: 6.075734E-01, n_evals: 999, Avg. time per updt: 0.106644\n",
      "[2018-05-13 10:18:41.631196] SGDOptimizer > Done training. New loss [0.597645] iter: [999]\n",
      "[2018-05-13 10:18:41.633277] apply_controller > Starting run\n",
      "[2018-05-13 10:18:41.634491] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:18:41.854845] apply_controller > Done. Stopping robot. Value of run [16.186529]\n",
      "[2018-05-13 10:18:41.856192] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:18:41.857145] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:18:41.861334] train_dynamics > Dataset size:: Inputs: [ (493, 6) ], Targets: [ (493, 4) ] \n",
      "[2018-05-13 10:18:41.862610] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:18:41.876547] target_dyn_opt > Initial loss [-9.175805174796626]\n",
      "\u001b[2K[2018-05-13 10:18:59.979110] target_dyn_opt > Curr loss: -1.194111E+01 [1909: -1.232877E+01], n_evals: 1999, Avg. time per updt: 0.007575\n",
      "[2018-05-13 10:18:59.993321] target_dyn_opt > Done training. New loss [-11.810501] iter: [2000]\n",
      "[2018-05-13 10:18:59.996064] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:18:59.997635] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_16.zip\n",
      "[2018-05-13 10:19:00.775830] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_16.zip\n",
      "[2018-05-13 10:19:00.884009] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_16.zip\n",
      "[2018-05-13 10:19:02.849379] ==== Iteration [17], experience: [510 steps] ====\n",
      "[2018-05-13 10:19:02.854482] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:19:03.002403] SGDOptimizer > Initial loss [0.6184613704681396]\n",
      "\u001b[2K[2018-05-13 10:20:52.050790] SGDOptimizer > Curr loss: 5.964269E-01, n_evals: 999, Avg. time per updt: 0.107752\n",
      "[2018-05-13 10:20:52.082707] SGDOptimizer > Done training. New loss [0.617458] iter: [999]\n",
      "[2018-05-13 10:20:52.084331] apply_controller > Starting run\n",
      "[2018-05-13 10:20:52.086069] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:20:52.271121] apply_controller > Done. Stopping robot. Value of run [15.421210]\n",
      "[2018-05-13 10:20:52.272472] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:20:52.273769] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:20:52.277239] train_dynamics > Dataset size:: Inputs: [ (522, 6) ], Targets: [ (522, 4) ] \n",
      "[2018-05-13 10:20:52.278600] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:20:52.292756] target_dyn_opt > Initial loss [-9.144461724721609]\n",
      "\u001b[2K[2018-05-13 10:21:10.627376] target_dyn_opt > Curr loss: -1.214701E+01 [1587: -1.255521E+01], n_evals: 1999, Avg. time per updt: 0.007670\n",
      "[2018-05-13 10:21:10.641229] target_dyn_opt > Done training. New loss [-12.034963] iter: [2000]\n",
      "[2018-05-13 10:21:10.643793] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:21:10.645123] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_17.zip\n",
      "[2018-05-13 10:21:11.461208] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_17.zip\n",
      "[2018-05-13 10:21:11.571311] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_17.zip\n",
      "[2018-05-13 10:21:13.583973] ==== Iteration [18], experience: [540 steps] ====\n",
      "[2018-05-13 10:21:13.589889] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:21:13.738958] SGDOptimizer > Initial loss [0.7618904113769531]\n",
      "\u001b[2K[2018-05-13 10:23:03.609166] SGDOptimizer > Curr loss: 5.904720E-01, n_evals: 999, Avg. time per updt: 0.108586\n",
      "[2018-05-13 10:23:03.646513] SGDOptimizer > Done training. New loss [0.595080] iter: [999]\n",
      "[2018-05-13 10:23:03.648374] apply_controller > Starting run\n",
      "[2018-05-13 10:23:03.649705] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:23:03.827978] apply_controller > Done. Stopping robot. Value of run [14.931577]\n",
      "[2018-05-13 10:23:03.829325] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:23:03.830788] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:23:03.834214] train_dynamics > Dataset size:: Inputs: [ (551, 6) ], Targets: [ (551, 4) ] \n",
      "[2018-05-13 10:23:03.835612] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:23:03.849940] target_dyn_opt > Initial loss [-7.897453058544824]\n",
      "\u001b[2K[2018-05-13 10:23:22.226305] target_dyn_opt > Curr loss: -1.218159E+01 [1868: -1.285647E+01], n_evals: 1999, Avg. time per updt: 0.007703\n",
      "[2018-05-13 10:23:22.241720] target_dyn_opt > Done training. New loss [-12.398312] iter: [2000]\n",
      "[2018-05-13 10:23:22.244466] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:23:22.246057] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_18.zip\n",
      "[2018-05-13 10:23:23.106946] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_18.zip\n",
      "[2018-05-13 10:23:23.215180] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_18.zip\n",
      "[2018-05-13 10:23:25.186826] ==== Iteration [19], experience: [570 steps] ====\n",
      "[2018-05-13 10:23:25.192135] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:23:25.354601] SGDOptimizer > Initial loss [0.6105374693870544]\n",
      "\u001b[2K[2018-05-13 10:25:15.013369] SGDOptimizer > Curr loss: 5.661945E-01, n_evals: 999, Avg. time per updt: 0.108363\n",
      "[2018-05-13 10:25:15.044689] SGDOptimizer > Done training. New loss [0.566512] iter: [999]\n",
      "[2018-05-13 10:25:15.046433] apply_controller > Starting run\n",
      "[2018-05-13 10:25:15.048030] apply_controller > Running for 3.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 10:25:15.238270] apply_controller > Done. Stopping robot. Value of run [14.580030]\n",
      "[2018-05-13 10:25:15.239637] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:25:15.240925] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:25:15.244622] train_dynamics > Dataset size:: Inputs: [ (580, 6) ], Targets: [ (580, 4) ] \n",
      "[2018-05-13 10:25:15.246149] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:25:15.259756] target_dyn_opt > Initial loss [-4.248172493227597]\n",
      "\u001b[2K[2018-05-13 10:25:33.506092] target_dyn_opt > Curr loss: -1.256274E+01 [1511: -1.292397E+01], n_evals: 1999, Avg. time per updt: 0.007662\n",
      "[2018-05-13 10:25:33.521792] target_dyn_opt > Done training. New loss [-12.150626] iter: [2000]\n",
      "[2018-05-13 10:25:33.524417] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:25:33.525768] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_19.zip\n",
      "[2018-05-13 10:25:34.423378] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_19.zip\n",
      "[2018-05-13 10:25:34.529541] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_19.zip\n",
      "[2018-05-13 10:25:38.760458] ==== Iteration [20], experience: [600 steps] ====\n",
      "[2018-05-13 10:25:38.765350] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:25:38.934987] SGDOptimizer > Initial loss [0.6032018661499023]\n",
      "\u001b[2K[2018-05-13 10:27:29.748682] SGDOptimizer > Curr loss: 5.722564E-01, n_evals: 999, Avg. time per updt: 0.109528\n",
      "[2018-05-13 10:27:29.781903] SGDOptimizer > Done training. New loss [0.587738] iter: [999]\n",
      "[2018-05-13 10:27:29.783599] apply_controller > Starting run\n",
      "[2018-05-13 10:27:29.784890] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:27:29.972792] apply_controller > Done. Stopping robot. Value of run [15.255263]\n",
      "[2018-05-13 10:27:29.974257] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:27:29.975793] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:27:29.980162] train_dynamics > Dataset size:: Inputs: [ (609, 6) ], Targets: [ (609, 4) ] \n",
      "[2018-05-13 10:27:29.981445] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:27:29.995490] target_dyn_opt > Initial loss [-5.46939594502911]\n",
      "\u001b[2K[2018-05-13 10:27:48.150375] target_dyn_opt > Curr loss: -1.244920E+01 [964: -1.306647E+01], n_evals: 1999, Avg. time per updt: 0.007609\n",
      "[2018-05-13 10:27:48.166204] target_dyn_opt > Done training. New loss [-12.863425] iter: [2000]\n",
      "[2018-05-13 10:27:48.168804] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:27:48.170672] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_20.zip\n",
      "[2018-05-13 10:27:49.123494] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_20.zip\n",
      "[2018-05-13 10:27:49.232155] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_20.zip\n",
      "[2018-05-13 10:27:51.215277] ==== Iteration [21], experience: [630 steps] ====\n",
      "[2018-05-13 10:27:51.220915] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:27:51.394026] SGDOptimizer > Initial loss [0.8279742002487183]\n",
      "\u001b[2K[2018-05-13 10:29:40.981492] SGDOptimizer > Curr loss: 5.739536E-01, n_evals: 999, Avg. time per updt: 0.108281\n",
      "[2018-05-13 10:29:41.013690] SGDOptimizer > Done training. New loss [0.572278] iter: [999]\n",
      "[2018-05-13 10:29:41.015442] apply_controller > Starting run\n",
      "[2018-05-13 10:29:41.016783] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:29:41.194610] apply_controller > Done. Stopping robot. Value of run [14.859592]\n",
      "[2018-05-13 10:29:41.195958] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:29:41.196943] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:29:41.201558] train_dynamics > Dataset size:: Inputs: [ (638, 6) ], Targets: [ (638, 4) ] \n",
      "[2018-05-13 10:29:41.203149] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:29:41.220120] target_dyn_opt > Initial loss [-8.974921285078443]\n",
      "\u001b[2K[2018-05-13 10:29:59.371679] target_dyn_opt > Curr loss: -1.274504E+01 [1698: -1.320800E+01], n_evals: 1999, Avg. time per updt: 0.007594\n",
      "[2018-05-13 10:29:59.387515] target_dyn_opt > Done training. New loss [-12.750760] iter: [2000]\n",
      "[2018-05-13 10:29:59.390225] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:29:59.391761] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_21.zip\n",
      "[2018-05-13 10:30:00.372483] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_21.zip\n",
      "[2018-05-13 10:30:00.478442] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_21.zip\n",
      "[2018-05-13 10:30:02.461998] ==== Iteration [22], experience: [660 steps] ====\n",
      "[2018-05-13 10:30:02.467049] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:30:02.610924] SGDOptimizer > Initial loss [0.5811737775802612]\n",
      "\u001b[2K[2018-05-13 10:31:52.688069] SGDOptimizer > Curr loss: 5.621434E-01, n_evals: 999, Avg. time per updt: 0.108779\n",
      "[2018-05-13 10:31:52.719768] SGDOptimizer > Done training. New loss [0.566834] iter: [999]\n",
      "[2018-05-13 10:31:52.721709] apply_controller > Starting run\n",
      "[2018-05-13 10:31:52.723119] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:31:52.899374] apply_controller > Done. Stopping robot. Value of run [15.386131]\n",
      "[2018-05-13 10:31:52.900880] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:31:52.902293] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:31:52.906479] train_dynamics > Dataset size:: Inputs: [ (667, 6) ], Targets: [ (667, 4) ] \n",
      "[2018-05-13 10:31:52.907904] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:31:52.923797] target_dyn_opt > Initial loss [-9.01411681402212]\n",
      "\u001b[2K[2018-05-13 10:32:11.321011] target_dyn_opt > Curr loss: -1.284867E+01 [1996: -1.345777E+01], n_evals: 1999, Avg. time per updt: 0.007716\n",
      "[2018-05-13 10:32:11.335191] target_dyn_opt > Done training. New loss [-12.890109] iter: [2000]\n",
      "[2018-05-13 10:32:11.338001] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:32:11.339395] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_22.zip\n",
      "[2018-05-13 10:32:12.373905] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_22.zip\n",
      "[2018-05-13 10:32:12.480559] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_22.zip\n",
      "[2018-05-13 10:32:14.451172] ==== Iteration [23], experience: [690 steps] ====\n",
      "[2018-05-13 10:32:14.457112] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:32:14.617202] SGDOptimizer > Initial loss [0.6146482229232788]\n",
      "\u001b[2K[2018-05-13 10:34:06.386928] SGDOptimizer > Curr loss: 5.837988E-01, n_evals: 999, Avg. time per updt: 0.110467\n",
      "[2018-05-13 10:34:06.419709] SGDOptimizer > Done training. New loss [0.578098] iter: [999]\n",
      "[2018-05-13 10:34:06.421523] apply_controller > Starting run\n",
      "[2018-05-13 10:34:06.422757] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:34:06.612615] apply_controller > Done. Stopping robot. Value of run [15.215000]\n",
      "[2018-05-13 10:34:06.613842] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:34:06.615282] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:34:06.619177] train_dynamics > Dataset size:: Inputs: [ (696, 6) ], Targets: [ (696, 4) ] \n",
      "[2018-05-13 10:34:06.620858] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:34:06.637681] target_dyn_opt > Initial loss [-8.725797658936045]\n",
      "\u001b[2K[2018-05-13 10:34:25.085237] target_dyn_opt > Curr loss: -1.321935E+01 [1031: -1.364469E+01], n_evals: 1999, Avg. time per updt: 0.007741\n",
      "[2018-05-13 10:34:25.099659] target_dyn_opt > Done training. New loss [-12.845720] iter: [2000]\n",
      "[2018-05-13 10:34:25.103870] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:34:25.105615] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_23.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 10:34:26.177098] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_23.zip\n",
      "[2018-05-13 10:34:26.284194] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_23.zip\n",
      "[2018-05-13 10:34:28.263013] ==== Iteration [24], experience: [720 steps] ====\n",
      "[2018-05-13 10:34:28.268572] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:34:28.439285] SGDOptimizer > Initial loss [0.6959244608879089]\n",
      "\u001b[2K[2018-05-13 10:36:20.063571] SGDOptimizer > Curr loss: 5.813130E-01, n_evals: 999, Avg. time per updt: 0.110303\n",
      "[2018-05-13 10:36:20.097814] SGDOptimizer > Done training. New loss [0.566720] iter: [999]\n",
      "[2018-05-13 10:36:20.099405] apply_controller > Starting run\n",
      "[2018-05-13 10:36:20.100578] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:36:20.272342] apply_controller > Done. Stopping robot. Value of run [16.387569]\n",
      "[2018-05-13 10:36:20.273576] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:36:20.275236] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:36:20.279562] train_dynamics > Dataset size:: Inputs: [ (725, 6) ], Targets: [ (725, 4) ] \n",
      "[2018-05-13 10:36:20.281148] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:36:20.296655] target_dyn_opt > Initial loss [-2.8693298633345243]\n",
      "\u001b[2K[2018-05-13 10:36:38.604978] target_dyn_opt > Curr loss: -1.322612E+01 [1540: -1.359137E+01], n_evals: 1999, Avg. time per updt: 0.007683\n",
      "[2018-05-13 10:36:38.618444] target_dyn_opt > Done training. New loss [-12.889612] iter: [2000]\n",
      "[2018-05-13 10:36:38.621089] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:36:38.622580] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_24.zip\n",
      "[2018-05-13 10:36:39.727205] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_24.zip\n",
      "[2018-05-13 10:36:39.835582] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_24.zip\n",
      "[2018-05-13 10:36:41.815239] ==== Iteration [25], experience: [750 steps] ====\n",
      "[2018-05-13 10:36:41.820748] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:36:41.970926] SGDOptimizer > Initial loss [0.6873829960823059]\n",
      "\u001b[2K[2018-05-13 10:38:34.541174] SGDOptimizer > Curr loss: 5.752661E-01, n_evals: 999, Avg. time per updt: 0.111278\n",
      "[2018-05-13 10:38:34.574661] SGDOptimizer > Done training. New loss [0.577646] iter: [999]\n",
      "[2018-05-13 10:38:34.576343] apply_controller > Starting run\n",
      "[2018-05-13 10:38:34.577658] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:38:34.765542] apply_controller > Done. Stopping robot. Value of run [21.157692]\n",
      "[2018-05-13 10:38:34.766757] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:38:34.767520] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:38:34.771497] train_dynamics > Dataset size:: Inputs: [ (754, 6) ], Targets: [ (754, 4) ] \n",
      "[2018-05-13 10:38:34.772810] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:38:34.788877] target_dyn_opt > Initial loss [-8.254280674204587]\n",
      "\u001b[2K[2018-05-13 10:38:53.027881] target_dyn_opt > Curr loss: -1.311878E+01 [1743: -1.372966E+01], n_evals: 1999, Avg. time per updt: 0.007639\n",
      "[2018-05-13 10:38:53.042919] target_dyn_opt > Done training. New loss [-13.749023] iter: [2000]\n",
      "[2018-05-13 10:38:53.045416] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:38:53.047061] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_25.zip\n",
      "[2018-05-13 10:38:54.208008] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_25.zip\n",
      "[2018-05-13 10:38:54.318910] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_25.zip\n",
      "[2018-05-13 10:38:56.301368] ==== Iteration [26], experience: [780 steps] ====\n",
      "[2018-05-13 10:38:56.306744] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:38:56.456070] SGDOptimizer > Initial loss [0.627957284450531]\n",
      "\u001b[2K[2018-05-13 10:40:50.551522] SGDOptimizer > Curr loss: 5.992120E-01, n_evals: 999, Avg. time per updt: 0.112807\n",
      "[2018-05-13 10:40:50.586304] SGDOptimizer > Done training. New loss [0.607183] iter: [999]\n",
      "[2018-05-13 10:40:50.588278] apply_controller > Starting run\n",
      "[2018-05-13 10:40:50.589807] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:40:50.765909] apply_controller > Done. Stopping robot. Value of run [16.784985]\n",
      "[2018-05-13 10:40:50.767266] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:40:50.768583] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:40:50.773627] train_dynamics > Dataset size:: Inputs: [ (783, 6) ], Targets: [ (783, 4) ] \n",
      "[2018-05-13 10:40:50.775010] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:40:50.789355] target_dyn_opt > Initial loss [-9.429020962572036]\n",
      "\u001b[2K[2018-05-13 10:41:09.475458] target_dyn_opt > Curr loss: -1.357777E+01 [1149: -1.399960E+01], n_evals: 1999, Avg. time per updt: 0.007857\n",
      "[2018-05-13 10:41:09.489746] target_dyn_opt > Done training. New loss [-13.451515] iter: [2000]\n",
      "[2018-05-13 10:41:09.492332] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:41:09.493793] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_26.zip\n",
      "[2018-05-13 10:41:10.680731] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_26.zip\n",
      "[2018-05-13 10:41:10.786441] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_26.zip\n",
      "[2018-05-13 10:41:12.803141] ==== Iteration [27], experience: [810 steps] ====\n",
      "[2018-05-13 10:41:12.808115] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:41:12.957622] SGDOptimizer > Initial loss [0.7393075823783875]\n",
      "\u001b[2K[2018-05-13 10:43:08.137912] SGDOptimizer > Curr loss: 5.930840E-01, n_evals: 999, Avg. time per updt: 0.113880\n",
      "[2018-05-13 10:43:08.173134] SGDOptimizer > Done training. New loss [0.588858] iter: [999]\n",
      "[2018-05-13 10:43:08.174835] apply_controller > Starting run\n",
      "[2018-05-13 10:43:08.176026] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:43:08.376192] apply_controller > Done. Stopping robot. Value of run [17.070236]\n",
      "[2018-05-13 10:43:08.377523] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:43:08.378959] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:43:08.383731] train_dynamics > Dataset size:: Inputs: [ (812, 6) ], Targets: [ (812, 4) ] \n",
      "[2018-05-13 10:43:08.385137] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:43:08.400455] target_dyn_opt > Initial loss [-5.026422202587128]\n",
      "\u001b[2K[2018-05-13 10:43:27.407879] target_dyn_opt > Curr loss: -1.358448E+01 [660: -1.418816E+01], n_evals: 1999, Avg. time per updt: 0.007993\n",
      "[2018-05-13 10:43:27.421698] target_dyn_opt > Done training. New loss [-13.178822] iter: [2000]\n",
      "[2018-05-13 10:43:27.424362] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:43:27.426055] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_27.zip\n",
      "[2018-05-13 10:43:28.690219] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_27.zip\n",
      "[2018-05-13 10:43:28.798630] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_27.zip\n",
      "[2018-05-13 10:43:30.799407] ==== Iteration [28], experience: [840 steps] ====\n",
      "[2018-05-13 10:43:30.804762] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:43:30.955772] SGDOptimizer > Initial loss [0.6262434720993042]\n",
      "\u001b[2K[2018-05-13 10:45:27.745898] SGDOptimizer > Curr loss: 5.872651E-01, n_evals: 999, Avg. time per updt: 0.115505\n",
      "[2018-05-13 10:45:27.781544] SGDOptimizer > Done training. New loss [0.586408] iter: [999]\n",
      "[2018-05-13 10:45:27.783342] apply_controller > Starting run\n",
      "[2018-05-13 10:45:27.784558] apply_controller > Running for 3.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-13 10:45:27.969125] apply_controller > Done. Stopping robot. Value of run [15.167965]\n",
      "[2018-05-13 10:45:27.970703] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:45:27.971928] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:45:27.978537] train_dynamics > Dataset size:: Inputs: [ (841, 6) ], Targets: [ (841, 4) ] \n",
      "[2018-05-13 10:45:27.979840] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:45:27.994103] target_dyn_opt > Initial loss [-9.81950121373824]\n",
      "\u001b[2K[2018-05-13 10:45:46.555913] target_dyn_opt > Curr loss: -1.369124E+01 [1705: -1.429661E+01], n_evals: 1999, Avg. time per updt: 0.007810\n",
      "[2018-05-13 10:45:46.570532] target_dyn_opt > Done training. New loss [-13.529571] iter: [2000]\n",
      "[2018-05-13 10:45:46.573314] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:45:46.574957] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_28.zip\n",
      "[2018-05-13 10:45:47.850491] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_28.zip\n",
      "[2018-05-13 10:45:47.957846] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_28.zip\n",
      "[2018-05-13 10:45:49.943446] ==== Iteration [29], experience: [870 steps] ====\n",
      "[2018-05-13 10:45:49.949375] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:45:50.104199] SGDOptimizer > Initial loss [0.5936807990074158]\n",
      "\u001b[2K[2018-05-13 10:47:46.465951] SGDOptimizer > Curr loss: 6.099854E-01, n_evals: 999, Avg. time per updt: 0.115063\n",
      "[2018-05-13 10:47:46.501318] SGDOptimizer > Done training. New loss [0.611642] iter: [999]\n",
      "[2018-05-13 10:47:46.503188] apply_controller > Starting run\n",
      "[2018-05-13 10:47:46.504529] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:47:46.676715] apply_controller > Done. Stopping robot. Value of run [14.533818]\n",
      "[2018-05-13 10:47:46.678335] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:47:46.680081] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:47:46.684731] train_dynamics > Dataset size:: Inputs: [ (870, 6) ], Targets: [ (870, 4) ] \n",
      "[2018-05-13 10:47:46.686017] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:47:46.700397] target_dyn_opt > Initial loss [-9.182333165818248]\n",
      "\u001b[2K[2018-05-13 10:48:05.519056] target_dyn_opt > Curr loss: -1.387127E+01 [1792: -1.437617E+01], n_evals: 1999, Avg. time per updt: 0.007914\n",
      "[2018-05-13 10:48:05.532758] target_dyn_opt > Done training. New loss [-13.920240] iter: [2000]\n",
      "[2018-05-13 10:48:05.535352] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:48:05.536749] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_29.zip\n",
      "[2018-05-13 10:48:06.851183] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_29.zip\n",
      "[2018-05-13 10:48:06.959599] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_29.zip\n",
      "[2018-05-13 10:48:08.932237] ==== Iteration [30], experience: [900 steps] ====\n",
      "[2018-05-13 10:48:08.937254] SGDOptimizer > Optimizing parameters\n",
      "[2018-05-13 10:48:09.089516] SGDOptimizer > Initial loss [0.8438469767570496]\n",
      "\u001b[2K[2018-05-13 10:50:06.309346] SGDOptimizer > Curr loss: 5.777464E-01, n_evals: 999, Avg. time per updt: 0.115935\n",
      "[2018-05-13 10:50:06.344326] SGDOptimizer > Done training. New loss [0.579197] iter: [999]\n",
      "[2018-05-13 10:50:06.345930] apply_controller > Starting run\n",
      "[2018-05-13 10:50:06.347146] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-13 10:50:06.523473] apply_controller > Done. Stopping robot. Value of run [23.831322]\n",
      "[2018-05-13 10:50:06.524816] target_2x_mass > Stopping robot\n",
      "[2018-05-13 10:50:06.526109] train_dynamics > Training dynamics model\n",
      "[2018-05-13 10:50:06.530473] train_dynamics > Dataset size:: Inputs: [ (899, 6) ], Targets: [ (899, 4) ] \n",
      "[2018-05-13 10:50:06.532111] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-13 10:50:06.547134] target_dyn_opt > Initial loss [2.4880013926010642]\n",
      "\u001b[2K[2018-05-13 10:50:25.200134] target_dyn_opt > Curr loss: -1.375779E+01 [1352: -1.450362E+01], n_evals: 1999, Avg. time per updt: 0.007830\n",
      "[2018-05-13 10:50:25.215965] target_dyn_opt > Done training. New loss [-13.892355] iter: [2000]\n",
      "[2018-05-13 10:50:25.219134] train_dynamics > Done training dynamics model\n",
      "[2018-05-13 10:50:25.220500] Experience > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/experience_30.zip\n",
      "[2018-05-13 10:50:26.573567] NNPolicy > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/policy_30.zip\n",
      "[2018-05-13 10:50:26.681371] target_dyn > Saving state to /localdata/juan/sim2real_results/target_2x_mass_010_taskplusil_klpq_from_source2/dynamics_30.zip\n"
     ]
    }
   ],
   "source": [
    "# experiment 10 learn starting from source params, using klqp imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_010_taskplusil_klpq_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=True,\n",
    "    noisy_policy_input=True, crn=True, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1e-5], loss_type=utils.ImitationLossType.KLPQ)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-15 00:02:40.615236] source_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-15 00:02:40.639754] source_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-15 00:02:40.877493] target_dyn > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/dynamics_21.zip\n",
      "[2018-05-15 00:02:40.897316] target_dyn > Building network\n",
      "('InputLayer', {'shape': (None, 6), 'name': 'BNN_input'})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc0>b, 'name': 'BNN_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': BNN_fc0>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc0>W, 'logit_posterior_mean': BNN_fc0>logit_posterior_mean, 'logit_posterior_std': BNN_fc0>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_fc1>b, 'name': 'BNN_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': BNN_fc1>noise_samples, 'p': True, 'num_units': 200, 'W': BNN_fc1>W, 'logit_posterior_mean': BNN_fc1>logit_posterior_mean, 'logit_posterior_std': BNN_fc1>logit_posterior_std})\n",
      "('DenseLogNormalDropoutLayer', {'b': BNN_output>b, 'name': 'BNN_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': BNN_output>noise_samples, 'p': True, 'num_units': 8, 'W': BNN_output>W, 'logit_posterior_mean': BNN_output>logit_posterior_mean, 'logit_posterior_std': BNN_output>logit_posterior_std})\n",
      "[2018-05-15 00:02:41.124800] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-15 00:02:41.143750] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-15 00:02:41.265537] NNPolicy > Loading state from /home/juancamilog/.kusanagi/output/cartpole_kl_loss/policy_21.zip\n",
      "[2018-05-15 00:02:41.277619] NNPolicy > Building network\n",
      "('InputLayer', {'shape': (None, 5), 'name': 'NNPolicy_input'})\n",
      "('DenseLayer', {'W': NNPolicy_fc0>W, 'b': NNPolicy_fc0>b, 'name': 'NNPolicy_fc0', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'num_units': 200})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_fc1>b, 'name': 'NNPolicy_fc1', 'nonlinearity': <function rectify at 0x7f7fbc4b6b90>, 'noise_samples': NNPolicy_fc1>noise_samples, 'p': 0.1, 'num_units': 200, 'W': NNPolicy_fc1>W})\n",
      "('DenseDropoutLayer', {'b': NNPolicy_output>b, 'name': 'NNPolicy_output', 'nonlinearity': <function linear at 0x7f7fbc4ba050>, 'noise_samples': NNPolicy_output>noise_samples, 'p': 0.1, 'num_units': 1, 'W': NNPolicy_output>W})\n",
      "[2018-05-15 00:02:41.403942] Experience > Initialising new experience dataset\n",
      "[2018-05-15 00:02:41.405423] Executing initial policy\n",
      "[2018-05-15 00:02:41.407226] NNPolicy > Initialising expression graph for prediction\n",
      "[2018-05-15 00:02:41.486163] NNPolicy > Compiling mean and variance of prediction\n",
      "[2018-05-15 00:02:41.634005] NNPolicy > Done compiling\n",
      "[2018-05-15 00:02:41.635536] apply_controller > Starting run\n",
      "[2018-05-15 00:02:41.636796] apply_controller > Running for 3.000000 seconds\n",
      "[2018-05-15 00:02:41.782560] apply_controller > Done. Stopping robot. Value of run [29.092800]\n",
      "[2018-05-15 00:02:41.783821] target_2x_length > Stopping robot\n",
      "[2018-05-15 00:02:41.785493] train_dynamics > Training dynamics model\n",
      "[2018-05-15 00:02:41.787675] train_dynamics > Dataset size:: Inputs: [ (29, 6) ], Targets: [ (29, 4) ] \n",
      "[2018-05-15 00:02:41.789449] target_dyn > Initialising loss function\n",
      "[2018-05-15 00:02:41.941452] target_dyn_opt > Building computation graph for gradients\n",
      "[2018-05-15 00:02:42.227422] target_dyn_opt > No gradient clipping\n",
      "[2018-05-15 00:02:42.228640] target_dyn_opt > Computing parameter update rules\n",
      "[2018-05-15 00:02:42.296616] target_dyn_opt > Compiling function for loss\n",
      "[2018-05-15 00:02:47.465319] target_dyn_opt > Compiling parameter updates\n",
      "[2018-05-15 00:02:52.308889] target_dyn_opt > Optimizing parameters via mini batches\n",
      "[2018-05-15 00:02:52.317151] target_dyn_opt > Initial loss [442.182629884317]\n",
      "\u001b[2K[2018-05-15 00:03:02.326779] target_dyn_opt > Curr loss: 3.669757E+01 [1996: 3.665940E+01], n_evals: 1999, Avg. time per updt: 0.003447\n",
      "[2018-05-15 00:03:02.334698] target_dyn_opt > Done training. New loss [37.040096] iter: [2000]\n",
      "[2018-05-15 00:03:02.337345] train_dynamics > Done training dynamics model\n",
      "[2018-05-15 00:03:02.447253] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-15 00:03:02.448583] mc_pilco.rollout > CRNs will be resampled every 10 rollouts\n",
      "[2018-05-15 00:03:02.535447] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-15 00:03:02.536783] mc_pilco.rollout > Moment-matching [state: True, cost:False], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-15 00:03:03.157345] mc_pilco.rollout > Using common random numbers for moment matching\n",
      "[2018-05-15 00:03:03.158577] mc_pilco.rollout > CRNs will be resampled every 10 rollouts\n",
      "[2018-05-15 00:03:03.245505] mc_pilco.rollout > Building computation graph for rollout\n",
      "[2018-05-15 00:03:03.247346] mc_pilco.rollout > Moment-matching [state: False, cost:False], State measurement noise [policy: True, cost: False]\n",
      "[2018-05-15 00:03:09.483885] SGDOptimizer > Building computation graph for gradients\n",
      "[2018-05-15 00:03:16.759041] SGDOptimizer > Clipping gradients to norm 1.0\n",
      "[2018-05-15 00:03:16.773439] SGDOptimizer > Computing parameter update rules\n",
      "[2018-05-15 00:03:16.816484] SGDOptimizer > Compiling function for loss\n"
     ]
    }
   ],
   "source": [
    "# experiment 11 learn starting from source params, using mmd imitation loss + task cost\n",
    "output_dir = os.path.join(sim2real_output_dir, target_env.name + '_011_il_mmd_from_source')\n",
    "utils.set_output_dir(utils.unique_path(output_dir))\n",
    "params['n_rnd'] = 0                 # number of random initial trials\n",
    "params['n_opt'] = 30                # learning iterations\n",
    "source_dyn, target_dyn = init_dyn(params, dyn_path, copy_params=True)\n",
    "source_pol, target_pol = init_pol(params, pol_path, copy_params=True)\n",
    "loss_kwargs = dict(\n",
    "    n_samples=n_samples, mm_state=True, mm_cost=False,\n",
    "    noisy_policy_input=True, crn=10, time_varying_cost=True,\n",
    "    extra_shared=extra_shared,\n",
    "    intermediate_outs=False)\n",
    "\n",
    "polopt_kwargs = dict(clip=1.0, polyak_averaging=None)\n",
    "\n",
    "setup_experiment = partial(setup_mc_pilco_experiment, pol=target_pol, dyn=target_dyn)\n",
    "\n",
    "cost = partial(task_plus_il_cost, weights=[1.0, 1.0], loss_type=utils.ImitationLossType.MMD)\n",
    "\n",
    "run_pilco_experiment(\n",
    "    target_env, cost, setup_experiment, params,\n",
    "    loss_kwargs, polopt_kwargs,\n",
    "    minimize_cb=minimize_cb, learning_iteration_cb=learning_iteration_cb,\n",
    "    debug_plot=2, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
